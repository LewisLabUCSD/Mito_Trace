{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e52fe",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# scpileup_dir = \"/data/Mito_Trace/output/clone_pileups_simulation/samePos/donors_2__conditions_3__cells_per_donor_cond_300__clones_in_don_5__positions_100__variants_per_clone_lambda_1__donor_variants_10/seq_error_0.01__don_var_lim_0.8_1.0__clone_var_lim_0.1_0.4__depth_lim_4_10/data/cond0/MT/cellr_True/numread_200/\"\n",
    "# af_f = \"/data/Mito_Trace/output/clone_pileups_simulation/samePos/donors_2__conditions_3__cells_per_donor_cond_300__clones_in_don_5__positions_100__variants_per_clone_lambda_1__donor_variants_10/seq_error_0.01__don_var_lim_0.8_1.0__clone_var_lim_0.1_0.4__depth_lim_4_10/data/cond0/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/af_by_cell.tsv\"\n",
    "# mt_ref_fa = \"/data/Mito_Trace/data/processed/genomes/mtMasked/GRCh38_MT_blacklist_A2_2020/chrM.fasta\"\n",
    "# name = \"cond0\"\n",
    "\n",
    "# #minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/\n",
    "# min_cells=10\n",
    "# min_reads=50\n",
    "# topn=0\n",
    "# het_thresh=0.001 \n",
    "# min_het_cells=10\n",
    "# het_count_thresh=5\n",
    "# bq_thresh=20\n",
    "log=\"\"\n",
    "\n",
    "\n",
    "scpileup_dir = \"/data/Mito_Trace/output/pipeline/v03/CHIP_b1/MTBlacklist_A2/data/Flt3l/MT/cellr_True/numread_200\"\n",
    "af_f = \"/data/Mito_Trace/output/pipeline/v03/CHIP_b1/MTBlacklist_A2/data/Flt3l/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/af_by_cell.tsv\"\n",
    "mt_ref_fa = \"/data/Mito_Trace/data/processed/genomes/mtMasked/GRCh38_MT_blacklist_A2_2020/chrM.fasta\"\n",
    "name = \"Flt3l\"\n",
    "min_cells = 10 \n",
    "min_reads = 50\n",
    "topn = 0\n",
    "het_thresh = 0.001\n",
    "min_het_cells = 10 \n",
    "het_count_thresh = 5\n",
    "bq_thresh = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e17020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from os.path import join, dirname\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from pandarallel import pandarallel\n",
    "import numpy as np\n",
    "from numpanpar import parallel_df as pardf\n",
    "from Bio import SeqIO\n",
    "import click\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import logging\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "from src.utils.data_io import load_sc_pileup, load_and_filter_nt_pileups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a42104",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fill_af_by_cell_loop(cell_df, coverage_dir, type=\"coverage\"):\n",
    "    \"\"\" Cell series where indices are the positions and columns are variant info.\n",
    "\n",
    "    Loads in the A/C/G/T/coverage files, then loops through the\n",
    "    positions and fills in the alternative allele AF.\n",
    "    \"\"\"\n",
    "\n",
    "    for cell, cell_series in cell_df.iterrows():\n",
    "        cell_nucs = dict()\n",
    "        for n in [\"A\", \"C\", \"G\", \"T\", \"coverage\"]:\n",
    "            if not os.path.exists(join(coverage_dir, \"CB_\" + cell + \".\" + n + \".txt\")): #it only has the rev strand\n",
    "                print(f\"{n} not found for {cell}\")\n",
    "                continue\n",
    "            cell_nucs[n] = pd.read_csv(\n",
    "                join(coverage_dir, \"CB_\" + cell + \".\" + n + \".txt\"),\n",
    "                header=None)\n",
    "            if n == \"coverage\":\n",
    "                cell_nucs[n].columns = [\"Position\", \"Cell\", \"Coverage\"]\n",
    "            else:\n",
    "                cell_nucs[n].columns = [\"Position\", \"Cell\", \"Coverage\",\n",
    "                                        \"BQ\"]\n",
    "            cell_nucs[n] = cell_nucs[n].set_index(\"Position\",\n",
    "                                                  drop=False)\n",
    "            cell_nucs[n][\"Cell\"] = cell_nucs[n][\"Cell\"].apply(\n",
    "                lambda x: x.replace(\".bam\", \"\"))\n",
    "            cell_nucs[n][\"Coverage\"] = cell_nucs[n][\"Coverage\"].fillna(\n",
    "                0)\n",
    "        # Loop through each position and calculate AF frequency,\n",
    "        # where the position is the last character of the index name\n",
    "        for ind, val in (cell_series.iteritems()):\n",
    "            pos = int(ind[:-1])\n",
    "            n = ind[-1]\n",
    "            # curr_nuc_df = nt_cov_dict[n]\n",
    "            if n not in cell_nucs or \"coverage\" not in cell_nucs:\n",
    "                continue\n",
    "            if pos in cell_nucs[n].index.values:\n",
    "                if type == 'coverage':\n",
    "                    cell_df.loc[cell, ind] = cell_nucs[n].loc[pos][\n",
    "                                                 \"Coverage\"] / \\\n",
    "                                             cell_nucs[\"coverage\"].loc[pos][\n",
    "                                                 \"Coverage\"]\n",
    "                elif type==\"BQ\":\n",
    "                    cell_df.loc[cell, ind] = cell_nucs[n].loc[pos,\"BQ\"]\n",
    "                else:\n",
    "                    print(\"Type variable not recognized\")\n",
    "\n",
    "                if cell_df.loc[cell, ind] > 1:\n",
    "                    print(\"Above 1\", ind, pos)\n",
    "            else:\n",
    "                cell_df.loc[cell, ind] = 0\n",
    "    return cell_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09250a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_af_by_cell(af, cell_names, coverage_dir, num_proc):\n",
    "    af_by_cell = pd.DataFrame(\n",
    "        index=af.apply(lambda x: (str(x.name) + x[\"Nucleotide\"]),\n",
    "                       axis=1).values, columns=cell_names)\n",
    "    af_by_cell.columns = list(map(lambda x: x.replace(\"CB_\", \"\").replace(\".bam\",\"\"),\n",
    "                             af_by_cell.columns))\n",
    "    af_by_cell = pardf(af_by_cell.transpose(),\n",
    "                            fill_af_by_cell_loop,\n",
    "                            func_args=(coverage_dir,),\n",
    "                            num_processes=num_proc)\n",
    "    af_by_cell = af_by_cell.loc[:,(af_by_cell>0).any(axis=0)]\n",
    "\n",
    "    bq_by_cell = af_by_cell.copy() #Placeholder for shape\n",
    "    bq_by_cell = pardf(bq_by_cell.transpose(),\n",
    "                            fill_af_by_cell_loop,\n",
    "                            func_args=(coverage_dir,),\n",
    "                            num_processes=num_proc)\n",
    "\n",
    "    bq_by_cell = bq_by_cell.loc[:,(bq_by_cell>0).any(axis=0)]\n",
    "    return af_by_cell, bq_by_cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_af_pileup_v02(af, pileup_dir, cell_names):\n",
    "    \"\"\"\n",
    "\n",
    "    Loads in the A/C/G/T/coverage files, then loops through the\n",
    "    positions and fills in the alternative allele AF.\n",
    "    \"\"\"\n",
    "    af_nt_pileup = {}\n",
    "    for n, curr_af in af.groupby(\"Nucleotide\"):\n",
    "        print(n)\n",
    "        var_pos_to_keep = curr_af[\"Position\"].unique()\n",
    "        curr_f = glob.glob(os.path.join(pileup_dir, f\"*.{n}.strands.txt\"))[0]\n",
    "        df = pd.read_csv(curr_f, header=None)\n",
    "        # Only take the Forward reads since it is the one to compare against the reference\n",
    "        if len(df.columns) > 4:\n",
    "            df.columns = [\"Position\", \"Cell\", \"+ Coverage\", \"+ BQ\",\n",
    "                          \"- Coverage\", \"- BQ\"]  # df = df.iloc[:, :4]\n",
    "            df[\"Coverage\"] = df[\"+ Coverage\"] + df[\"- Coverage\"]\n",
    "            # Average bq by weighted sum\n",
    "            df[\"BQ\"] = df[\"+ BQ\"]*(df[\"+ Coverage\"])/(df[\"Coverage\"]) + df[\"- BQ\"]*(df[\"- Coverage\"])/(df[\"Coverage\"])\n",
    "            #df[\"BQ\"] = (df[\"+ BQ\"] + df[\"- BQ\"])/2\n",
    "        else:\n",
    "            df.columns = [\"Position\", \"Cell\", \"Coverage\", \"BQ\"]\n",
    "        df[\"Cell\"] = df[\"Cell\"].apply(lambda x: x.replace(\".bam\", \"\"))\n",
    "\n",
    "        #########\n",
    "        df = df[df[\"Cell\"].isin(cell_names)]\n",
    "        df = df[df[\"Position\"].isin(var_pos_to_keep)]\n",
    "        df[\"NT\"] = n\n",
    "        #########\n",
    "        af_nt_pileup[n] = df\n",
    "\n",
    "    cov = load_sc_pileup(\n",
    "        os.path.join(pileup_dir, f\"*.coverage.strands.txt\"))\n",
    "    cov = cov[cov[\"Cell\"].isin(cell_names)]\n",
    "    cov = cov[cov[\"Position\"].isin(af[\"Position\"])]\n",
    "    af_sparse_df = pd.concat(af_nt_pileup.values(), axis=0)\n",
    "    af_sparse_df = af_sparse_df.rename({\"Coverage\": \"Allele Depth\"},\n",
    "                                       axis=1)\n",
    "\n",
    "    cov_ad = pd.merge(af_sparse_df, cov, how='inner',\n",
    "                      on=[\"Position\", \"Cell\"])\n",
    "    cov_ad[\"ID\"] = cov_ad.apply(\n",
    "        lambda x: (str(x[\"Position\"]) + x[\"NT\"]), axis=1)\n",
    "\n",
    "    cov_ad[\"AF\"] = cov_ad[\"Allele Depth\"] / cov_ad[\"Coverage\"]\n",
    "    return cov_ad\n",
    "\n",
    "\n",
    "def get_gaussian_thresh(df, prob_thresh=0.9, to_plot=False, f_save=\"\"):\n",
    "    cell_depth = np.log10(df)\n",
    "    cell_inds = cell_depth.index\n",
    "    X = cell_depth.values.reshape(-1, 1)\n",
    "    gm = GaussianMixture(n_components=2, random_state=0).fit(X)\n",
    "    probs = gm.predict_proba(X)\n",
    "    max_clust = gm.means_[:, 0].argmax()\n",
    "    gauss_cells_to_keep = np.flatnonzero(\n",
    "        probs[:, max_clust] > prob_thresh)\n",
    "    gauss_cell_labels = cell_inds[gauss_cells_to_keep]\n",
    "    min_clust = (-1 * max_clust) + 1  # 1 or 0\n",
    "    gauss_cells_to_remove = np.flatnonzero(\n",
    "        probs[:, min_clust] > prob_thresh)\n",
    "    gauss_cell_remove_labels = cell_inds[gauss_cells_to_remove]\n",
    "\n",
    "    if to_plot:\n",
    "        f, ax = plt.subplots()\n",
    "        ax.hist(cell_depth)\n",
    "        ax.hist(cell_depth.loc[gauss_cell_labels], color='g', alpha=0.8)\n",
    "        ax.hist(cell_depth.loc[gauss_cell_remove_labels], color='r',\n",
    "                alpha=0.5)\n",
    "        plt.title(\n",
    "            \"Cell total coverage across MT. Filtering out low coverage\")\n",
    "        if not (f_save == \"\"):\n",
    "            plt.savefig(f_save.replace(\".png\", \"\") + \".png\", dpi=300)\n",
    "    print('gauss labels', len(gauss_cell_labels))\n",
    "    if len(gauss_cell_labels) < 0.5 * cell_depth.shape[0]:\n",
    "        print('Removing the low confident cells')\n",
    "        # Throw away the low values instead\n",
    "        gauss_cell_labels = np.delete(cell_inds.values, gauss_cells_to_remove, axis=0) #cell_inds[~(gauss_cells_to_remove)]\n",
    "        print('low conf', len(gauss_cells_to_remove))\n",
    "    return gauss_cell_labels, gm\n",
    "\n",
    "\n",
    "def filter_positions_cells(sc_coverage, topN=500, min_cells=100, min_reads=100, f_save=\"\"):\n",
    "    \"\"\" Filters cells and counts based on depth\n",
    "\n",
    "    :param sc_coverage:\n",
    "    :param topN:\n",
    "    :param min_cells:\n",
    "    :param min_reads:\n",
    "    :param coverage_thresh:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(\"Filtering cells\")\n",
    "    print(\"topN\", topN)\n",
    "    if topN == -1 or topN == 0: ## Keep them all\n",
    "        topCells = sc_coverage.groupby(\"Cell\").sum()[\"Coverage\"].sort_values(ascending=False)\n",
    "\n",
    "    else:\n",
    "        topCells = sc_coverage.groupby(\"Cell\").sum()[\"Coverage\"].sort_values(ascending=False)[:topN]\n",
    "    print(topCells.shape)\n",
    "    print(topCells.head())\n",
    "    cell_filter = topCells.index.values\n",
    "\n",
    "    #above_thresh = sc_coverage.groupby(\"Cell\").sum()[\"Coverage\"]>coverage_thresh\n",
    "    #above_thresh = above_thresh[above_thresh==True].index\n",
    "    print('running gaussian threshold')\n",
    "    cell_gauss, _ = get_gaussian_thresh(topCells, prob_thresh=0.9, to_plot=False, f_save=f_save)\n",
    "    print('cells after gauss thresh', len(cell_gauss))\n",
    "\n",
    "    sc_coverage = sc_coverage.loc[sc_coverage[\"Cell\"].isin(cell_filter)]\n",
    "    # Only positions with minimum number of reads overall in the cell\n",
    "    sc_coverage = sc_coverage.loc[sc_coverage[\"Cell\"].isin(cell_gauss)]\n",
    "\n",
    "    # Only positions with minimum number of reads at the position\n",
    "    pos_counts_filter = (sc_coverage.groupby(\"Position\").apply(\n",
    "        lambda x: (x['Coverage'] >= min_reads).sum())) >= min_cells\n",
    "    pos_counts_filter = pos_counts_filter[pos_counts_filter==True].index.values\n",
    "\n",
    "    cell_filter = list(set(cell_gauss).intersection(set(cell_filter)))\n",
    "    print(f\"Number of positions to keep : {len(pos_counts_filter)}\")\n",
    "    print(f\"Number of cells to keep : {len(cell_filter)}\")\n",
    "    return pos_counts_filter, cell_filter\n",
    "\n",
    "\n",
    "def filter_allele_cells(af_by_cell, het_thresh=0, min_het_cells=0):\n",
    "    \"\"\" Filter the variants based on counts or AF thresholds.\n",
    "\n",
    "    :param af_by_cell:\n",
    "    :type af_by_cell: pd.DataFrame or np.array of floats or ints\n",
    "    :param het_thresh:\n",
    "    :param min_het_cells:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    het_filt = (af_by_cell > het_thresh).sum(axis=0) > min_het_cells\n",
    "    het_filt = het_filt[het_filt].index\n",
    "    print(f'Positions that pass het filter: {len(het_filt)}')\n",
    "    return het_filt\n",
    "\n",
    "\n",
    "def get_nt_bq(concat_dir, cell_inds, nt_pos):\n",
    "    \"\"\" For each position, get the counts and average quality for each nt.\n",
    "    :param concat_dir:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    nucs = [\"A\", \"C\", \"G\", \"T\"]\n",
    "    # Make a |nucleotide|-by-MT dataframe to get  overall allele frequencies for each position\n",
    "    nt_df = pd.DataFrame(index=nt_pos, columns=nucs,\n",
    "                         dtype=int)\n",
    "    bq_df = pd.DataFrame(index=nt_pos, columns=nucs, dtype=int)\n",
    "\n",
    "    # # Dictionary of coverage per cell\n",
    "    cells = dict()\n",
    "    nt_pileup = load_and_filter_nt_pileups(concat_dir,\n",
    "                                           cell_inds, nt_pos,\n",
    "                                           out_d=None, name=None, sum_cov=True,\n",
    "                                           input_suffix=\".strands.txt\")\n",
    "    for n in nt_pileup:\n",
    "        df = nt_pileup[n]\n",
    "        cells[n] = set(df[\"Cell\"].values)\n",
    "        pos = df.groupby(\"Position\")\n",
    "        nt_df.loc[:, n] = pos[\"Coverage\"].agg(\"sum\")\n",
    "        bq_df.loc[:, n] = pos[\"BQ\"].agg(\"mean\")\n",
    "        # nt_cov_dict[n] = df\n",
    "\n",
    "    nt_df = nt_df.fillna(0)\n",
    "    bq_df = bq_df.fillna(0)\n",
    "    cell_names = set()\n",
    "    for n in cells:\n",
    "        cell_names=cell_names.union(cells[n])\n",
    "\n",
    "    return nt_df, bq_df, cell_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf5e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_af_v02(nt_df, bq_df, ref_fasta):\n",
    "    mt_fasta_sequence = list(SeqIO.parse(mt_ref_fa, \"fasta\"))\n",
    "    af_inds = []\n",
    "    for ind, val in nt_df.iterrows():\n",
    "        curr_ref = str(mt_fasta_sequence[0].seq).upper()[ind - 1]\n",
    "        curr_nts = val[val!=0].index\n",
    "        curr_nts = set(curr_nts) - set([curr_ref])\n",
    "        af_inds.extend([f\"{ind}>{x}\" for x in curr_nts])\n",
    "\n",
    "    af = pd.DataFrame(index=af_inds, columns=[\"Position\", \"Nucleotide\", \"AF\", \"Reference\",\n",
    "                               \"Alternative BQ\", \"Depth\"])\n",
    "    no_alt_count = 0\n",
    "    for ind, val in tqdm(nt_df.iterrows()):\n",
    "        if ind > len(str(mt_fasta_sequence[0].seq)) - 1:\n",
    "            break\n",
    "        # Get the reference nucleotide from the fasta file\n",
    "        curr_ref = str(mt_fasta_sequence[0].seq).upper()[ind - 1]\n",
    "\n",
    "        if curr_ref not in nt_df.columns.values: # 'N'\n",
    "            print(f'Not using {curr_ref}')\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # Drop the reference and nts with no counts\n",
    "        curr_nts = list(val[val!=0].index.values)\n",
    "        new_val = val.loc[curr_nts]\n",
    "        if curr_ref in val.index:\n",
    "            curr_nts.remove(curr_ref)\n",
    "            new_val = new_val.drop(curr_ref)\n",
    "\n",
    "        new_val.index =  [f\"{ind}>{x}\" for x in curr_nts] \n",
    "        curr_af = new_val/new_val.sum()\n",
    "        #curr_nts = set(val[val!=0].index.values) - set([curr_ref])\n",
    "        curr_inds = curr_af.index\n",
    "        curr_bq = bq_df.loc[ind]\n",
    "        curr_bq.index =  [f\"{ind}>{x}\" for x in curr_bq.index] \n",
    "        curr_bq = curr_bq.loc[curr_inds]\n",
    "\n",
    "        af.loc[curr_inds, \"Position\"] = ind\n",
    "        af.loc[curr_inds, \"AF\"] = curr_af\n",
    "        af.loc[curr_inds, \"Nucleotide\"] = curr_nts\n",
    "        af.loc[curr_inds, \"Reference\"] = curr_ref\n",
    "        af.loc[curr_inds, \"Alternative BQ\"] = curr_bq\n",
    "        af.loc[curr_inds, \"Depth\"] = new_val.sum() #(val[alt_nuc]+val[curr_ref]) # jan26_2021\n",
    "\n",
    "    # Create variant ID name (e.g. 18A-position 18 variant A)\n",
    "    print(f\"number of positions: {len(af)}\")\n",
    "    print('af head')\n",
    "    print(af.head())\n",
    "    print(af.shape)\n",
    "    logging.info(f'# of positions with no variant detected: {no_alt_count}')\n",
    "    af = af.dropna()\n",
    "    print(af.shape)\n",
    "    af[\"ID\"] = af.index\n",
    "\n",
    "    af.head()\n",
    "    return af\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5248e944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_init(dp_by_cell, out_d=None):\n",
    "    f_init, ax = plt.subplots(nrows=3, ncols=1)\n",
    "    sns.heatmap(np.log2(dp_by_cell.iloc[:min(len(dp_by_cell), 500)] + 1), ax=ax[0])\n",
    "    ax[0].set_title(\"Log2 depth\\nLowest 100 depth cells\")\n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "    if len(dp_by_cell) > 5100:\n",
    "        sns.heatmap(np.log2(dp_by_cell.iloc[5000:5100] + 1), ax=ax[1])\n",
    "        ax[1].set_title(\"Middle 1000 depth cells\")\n",
    "        ax[1].set_xticks([])\n",
    "        ax[1].set_yticks([])\n",
    "    sns.heatmap(np.log2(dp_by_cell.iloc[-100:] + 1), ax=ax[2])\n",
    "    ax[2].set_title(\"Highest 100 depth cells\")\n",
    "    ax[2].set_xticks([])\n",
    "    ax[2].set_yticks([])\n",
    "    plt.subplots_adjust(hspace=1)\n",
    "    #plt.show()\n",
    "    if out_d is not None:\n",
    "        f_init.savefig(join(out_d, \"initial_cell_depth.png\"), dpi=300)\n",
    "        #plt.close(f_init)\n",
    "    return f_init\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ca761",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 0. Create stats df, and figure\n",
    "stats = pd.DataFrame(\n",
    "    columns=[\"# Cells\", \"# Positions\", \"# Variants\"])\n",
    "\n",
    "out_d = os.path.dirname(af_f)\n",
    "if not os.path.exists(out_d):\n",
    "    logging.warning(f'{out_d} not here. Creatign directory')\n",
    "    os.mkdir(out_d)\n",
    "# 1. Load the MTPos pileup matrix, take the average of the +/- strands\n",
    "sc_coverage = load_sc_pileup(\n",
    "    join(scpileup_dir, \"*.coverage.strands.txt\"))\n",
    "\n",
    "stats = stats.append(pd.DataFrame([[len(\n",
    "    sc_coverage[\"Cell\"].unique()), max(sc_coverage[\"Position\"]),\n",
    "                                    0]],\n",
    "                                  columns=[\"# Cells\", \"# Positions\",\n",
    "                                           \"# Variants\"],\n",
    "                                  index=[\"Initial 10x barcodes\"]))\n",
    "logging.info('stats -\\n{}'.format(stats.to_string()))\n",
    "dp_by_cell = sc_coverage.pivot(index=\"Cell\", columns=\"Position\",\n",
    "                               values=\"Coverage\").fillna(0)\n",
    "logging.info('sorting depth')\n",
    "dp_by_cell = dp_by_cell.loc[dp_by_cell.sum(axis=1).sort_values().index]\n",
    "\n",
    "plot_init(dp_by_cell, out_d=out_d)\n",
    "\n",
    "\n",
    "# 2. Filter A: top cells by coverage, minimum coverage, minimum number of cells and certain number of reads\n",
    "pos_counts_filter, cell_filter = filter_positions_cells(sc_coverage,\n",
    "                                                        topN=topn,\n",
    "                                                        min_cells=min_cells,\n",
    "                                                        min_reads=min_reads, f_save=join(out_d, \"gauss_hist.png\"))\n",
    "\n",
    "stats = stats.append(\n",
    "    pd.DataFrame([[len(cell_filter), len(pos_counts_filter), 0]],\n",
    "                 columns=[\"# Cells\", \"# Positions\", \"# Variants\"],\n",
    "                 index=[\n",
    "                     f\"Depth thresh: topN {topn} min_cells {min_cells} min_reads {min_reads}\"]))\n",
    "logging.info('stats -\\n{}'.format(stats.to_string()))\n",
    "if len(cell_filter) == 0 or len(pos_counts_filter) == 0:\n",
    "    logging.warning(\"Nothing passes the filter.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6755ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Get the nt position info from filtered cells and variants.\n",
    "nt_df, bq_df, cell_names = get_nt_bq(scpileup_dir,\n",
    "                                     cell_inds=cell_filter,\n",
    "                                     nt_pos=pos_counts_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9962b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Get the highest alt allele, store in af, which is the filtered AF Pos-by-[AF, BQ] df\n",
    "af = extract_af_v02(nt_df, bq_df, mt_ref_fa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c7f25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# 5. Now that we called our alternate alleles, put them in\n",
    "#    cell-allele sparse form (no 0s), extracting from the sparse\n",
    "#    nucleotide pileups\n",
    "cov_ad = extract_af_pileup_v02(af, scpileup_dir, cell_names)\n",
    "\n",
    "af_by_cell = cov_ad.pivot(index=\"Cell\", columns=\"ID\",\n",
    "                          values=\"AF\").fillna(0)\n",
    "\n",
    "cov_ad = cov_ad[(cov_ad[\"ID\"].isin(af_by_cell.columns)) & (cov_ad[\"Cell\"].isin(af_by_cell.index))]\n",
    "ad_by_cell = cov_ad.pivot(index=\"Cell\", columns=\"ID\",\n",
    "                          values=\"Allele Depth\").fillna(0)\n",
    "depth_by_cell = cov_ad.pivot(index=\"Cell\",\n",
    "                             columns=\"ID\",\n",
    "                             values=\"Coverage\").fillna(0)\n",
    "f_heat, ax = plt.subplots(nrows=4, ncols=3, figsize=(15, 15))\n",
    "if af_by_cell.shape[0]>1000:\n",
    "    logging.info('sampling for the heatmap')\n",
    "    samp_inds = np.random.choice(np.array(af_by_cell.shape[0]), size=1000, replace=False)\n",
    "else:\n",
    "    samp_inds = np.arange(af_by_cell.shape[0])\n",
    "\n",
    "if af_by_cell.shape[1]>1000:\n",
    "    logging.info('sampling for the heatmap')\n",
    "    samp_cols = np.random.choice(np.array(af_by_cell.shape[1]), size=1000, replace=False)\n",
    "else:\n",
    "    samp_cols = np.arange(af_by_cell.shape[1])    \n",
    "\n",
    "sns.heatmap(np.sqrt(af_by_cell.iloc[samp_inds, samp_cols]), vmin=0, vmax=0.3, ax=ax[0, 0])\n",
    "ax[0,0].set_title(\"After filtering for counts\")\n",
    "sns.heatmap(np.log2(depth_by_cell.iloc[samp_inds, samp_cols] + 1), ax=ax[0, 1])\n",
    "sns.heatmap(np.log2(ad_by_cell.iloc[samp_inds, samp_cols] + 1), ax=ax[0, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f648d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_sample(df):\n",
    "    if df.shape[0]>1000:\n",
    "        samp_inds = np.random.choice(np.array(df.shape[0]), size=1000, replace=False)\n",
    "    else:\n",
    "        samp_inds = np.arange(df.shape[0])\n",
    "    if df.shape[1]>1000:\n",
    "        samp_cols = np.random.choice(np.array(df.shape[1]), size=1000, replace=False)\n",
    "    else:\n",
    "        samp_cols = np.arange(df.shape[1]) \n",
    "    return samp_inds, samp_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13881161",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# 6. FILTER B: minimum cells w heterozygous AF minimum\n",
    "het_filt = filter_allele_cells(af_by_cell, het_thresh,\n",
    "                               min_het_cells=min_het_cells)\n",
    "af_by_cell = af_by_cell[het_filt]\n",
    "ad_by_cell = ad_by_cell[het_filt]\n",
    "\n",
    "stats = stats.append(\n",
    "    pd.DataFrame([[af_by_cell.shape[0], af_by_cell.shape[1], 0]],\n",
    "                 columns=[\"# Cells\", \"# Positions\", \"# Variants\"],\n",
    "                 index=[\n",
    "                     f\"min het af {het_thresh} min. het cells {min_het_cells}\"]))\n",
    "samp_inds, samp_cols = df_sample(af_by_cell)\n",
    "\n",
    "sns.heatmap(np.sqrt(af_by_cell.iloc[samp_inds,samp_cols]), vmin=0, vmax=0.3, ax=ax[1, 0])\n",
    "ax[1,0].set_title(\"After filtering het AF\")\n",
    "# Create depth-by-cell\n",
    "depth_by_cell = cov_ad[(cov_ad[\"ID\"].isin(af_by_cell.columns)) & (\n",
    "    cov_ad[\"Cell\"].isin(af_by_cell.index))].pivot(index=\"Cell\",\n",
    "                                                  columns=\"ID\",\n",
    "                                                  values=\"Coverage\").fillna(0)\n",
    "\n",
    "sns.heatmap(np.log2(depth_by_cell.iloc[samp_inds,samp_cols] + 1), ax=ax[1, 1])\n",
    "sns.heatmap(np.log2(ad_by_cell.iloc[samp_inds,samp_cols] + 1), ax=ax[1, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09105c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# 7. FILTER C: by minimum cells w heterozygous count minimum\n",
    "het_filt = filter_allele_cells(ad_by_cell, het_count_thresh,\n",
    "                               min_het_cells=min_het_cells)\n",
    "af_by_cell = af_by_cell[het_filt]\n",
    "ad_by_cell = ad_by_cell[het_filt]\n",
    "\n",
    "stats = stats.append(\n",
    "    pd.DataFrame([[af_by_cell.shape[0], af_by_cell.shape[1], 0]],\n",
    "                 columns=[\"# Cells\", \"# Positions\", \"# Variants\"],\n",
    "                 index=[\n",
    "                     f\"min het count {het_count_thresh} min. het cells {min_het_cells}\"]))\n",
    "logging.info('stats -\\n{}'.format(stats.to_string()))\n",
    "samp_inds, samp_cols = df_sample(af_by_cell)\n",
    "\n",
    "sns.heatmap(np.sqrt(af_by_cell.iloc[samp_inds, samp_cols]), vmin=0, vmax=0.3, ax=ax[2,0])\n",
    "ax[2,0].set_title(\"After filtering het Count\")\n",
    "\n",
    "# Create depth-by-cell\n",
    "depth_by_cell = cov_ad[(cov_ad[\"ID\"].isin(af_by_cell.columns)) & (\n",
    "    cov_ad[\"Cell\"].isin(af_by_cell.index))].pivot(index=\"Cell\",\n",
    "                                                  columns=\"ID\",\n",
    "                                                  values=\"Coverage\").fillna(0)\n",
    "sns.heatmap(np.log2(depth_by_cell.iloc[samp_inds, samp_cols] + 1), ax=ax[2, 1])\n",
    "sns.heatmap(np.log2(ad_by_cell.iloc[samp_inds, samp_cols] + 1), ax=ax[2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e93e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# 8. FILTER D: by minimum cells w average BQ (after filtering other cells.).\n",
    "bq_by_cell = cov_ad[(cov_ad[\"ID\"].isin(af_by_cell.columns)) & (\n",
    "    cov_ad[\"Cell\"].isin(af_by_cell.index))].pivot(index=\"Cell\",\n",
    "                                                  columns=\"ID\",\n",
    "                                                  values=\"BQ\").fillna(0)\n",
    "\n",
    "bq_filt = filter_allele_cells(bq_by_cell, het_thresh = bq_thresh, min_het_cells = min_het_cells)\n",
    "bq_by_cell = bq_by_cell[bq_filt]\n",
    "af_by_cell = af_by_cell[bq_filt]\n",
    "ad_by_cell = ad_by_cell[bq_filt]\n",
    "\n",
    "# Create depth-by-cell\n",
    "depth_by_cell = cov_ad[(cov_ad[\"ID\"].isin(af_by_cell.columns)) & (\n",
    "    cov_ad[\"Cell\"].isin(af_by_cell.index))].pivot(index=\"Cell\",\n",
    "                                                  columns=\"ID\",\n",
    "                                                  values=\"Coverage\").fillna(0)\n",
    "\n",
    "stats = stats.append(\n",
    "    pd.DataFrame([[af_by_cell.shape[0], af_by_cell.shape[1], 0]],\n",
    "                 columns=[\"# Cells\", \"# Positions\", \"# Variants\"],\n",
    "                 index=[f\"BQ {bq_thresh}\"]))\n",
    "logging.info('stats -\\n{}'.format(stats.to_string()))\n",
    "samp_inds, samp_cols = df_sample(af_by_cell)\n",
    "\n",
    "sns.heatmap(np.sqrt(af_by_cell.iloc[samp_inds,samp_cols]), vmin=0, vmax=0.3, ax=ax[3,0])\n",
    "ax[3,0].set_title(\"After filtering BQ averages\")\n",
    "sns.heatmap(np.log2(depth_by_cell.iloc[samp_inds,samp_cols] + 1), ax=ax[3, 1])\n",
    "sns.heatmap(np.log2(ad_by_cell.iloc[samp_inds,samp_cols] + 1), ax=ax[3, 2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c901e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9. Get final positions and cells.\n",
    "final_cells = af_by_cell.index\n",
    "final_positions = af_by_cell.columns  # list(map(lambda x: int(x[:-1]), af_by_cell.columns))\n",
    "\n",
    "logging.info(f\"Number of positions: {len(final_positions)}\")\n",
    "logging.info(f\"Positions: {final_positions}\")\n",
    "logging.info(f\"Number of cells: {len(final_cells)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3205831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# 10. Save files (3 diff ways)\n",
    "# a. af_by_cell; depth_by_cell; bq_by_cell\n",
    "# b. nt pileups: Filtered by cells and positions\n",
    "# c. AF and DP sparse matrices- using our called variants\n",
    "# d. Also save stats file\n",
    "if af_f is not None:\n",
    "    # a.\n",
    "    af_by_cell.to_csv(af_f, sep='\\t')\n",
    "    bq_by_cell.to_csv(af_f.replace('.tsv', '') + \".bq.tsv\", sep='\\t')\n",
    "    ad_by_cell.to_csv(af_f.replace('.tsv', '') + \".AD.tsv\", sep='\\t')\n",
    "    depth_by_cell.to_csv(af_f.replace('.tsv', '') + \".DP.tsv\", sep='\\t')\n",
    "    # alleleDepth_by_cell.to_csv(AF_F.replace('.csv', '') + \".AD.csv\")\n",
    "\n",
    "    logging.info(\"Saving pileup\")\n",
    "    # b. Save filtered nucleotide pileups for mgatk usage\n",
    "    final_positions = [int(x[:-1]) for x in final_positions]\n",
    "    logging.info(out_d)\n",
    "    logging.info(name)\n",
    "    load_and_filter_nt_pileups(scpileup_dir, final_cells,\n",
    "                               np.array(final_positions),\n",
    "                               out_d, name, incl_cov=True, sum_cov=False,\n",
    "                               input_suffix=\".strands.txt\"\n",
    "                               )\n",
    "    # Save depth as well\n",
    "    (depth_by_cell.sum(axis=1)/depth_by_cell.shape[1]).to_csv(join(out_d, name+\".depthTable.txt\"),\n",
    "                                                              header=False,\n",
    "                                                              index=True,\n",
    "                                                              index_label=False, sep=\"\\t\")\n",
    "    #df.groupby(\"Cell\")[\"Coverage\"].sum().to_csv(out_d, name+\".depthTable.txt\", header=False, index=True, index_label=False)\n",
    "    # c. Save depth and allele frequency as sparse matrices\n",
    "    # af_by_cell.melt()\n",
    "\n",
    "    # d. stats and figures\n",
    "    stats.to_csv(join(out_d, \"stats.csv\"))\n",
    "\n",
    "    # e. Heatmap figure\n",
    "    logging.info(\"Saving heatmap\")\n",
    "    for curr_x in range(ax.shape[0]):\n",
    "        for curr_y in range(ax.shape[1]):\n",
    "            ax[curr_x, curr_y].set_yticks([])\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    f_heat.suptitle(\n",
    "        \"Sqrt(allele freq), log2(depth count+1), log2(allele count+1)\")\n",
    "    f_heat.savefig(join(out_d, 'heatmap.png'), dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d718804",
   "metadata": {},
   "outputs": [],
   "source": [
    "af_by_cell.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25994639",
   "metadata": {},
   "outputs": [],
   "source": [
    "af_by_cell.shape"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
