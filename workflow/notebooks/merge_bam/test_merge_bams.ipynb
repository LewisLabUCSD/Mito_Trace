{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "789e7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script adapted from here:\n",
    "# Sythetic mixture of bam files from multiple samples\n",
    "# Author: Yuanhua Huang\n",
    "# Date: 15-06-2019\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pysam\n",
    "import itertools\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "from optparse import OptionParser, OptionGroup\n",
    "from cellSNP.utils.vcf_utils import load_VCF\n",
    "from cellSNP.utils.pileup_utils import check_pysam_chrom\n",
    "import pandas as pd\n",
    "\n",
    "def show_progress(RV=None):\n",
    "    return RV\n",
    "\n",
    "\n",
    "def sample_barcodes(barcodes, n_cell_each=1000, minor_sample=1.0, seed=None):\n",
    "    \"\"\"\n",
    "    generate cell barcodes by down sampling\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    for ss in range(len(barcodes)):\n",
    "        if len(barcodes[ss]) < n_cell_each:\n",
    "            print(\"Error in sample_barcodes: input sample has fewer cell \"\n",
    "                  \"barcodes than n_cell_each.\")\n",
    "            sys.exit(1)\n",
    "        #barcodes[ss] = list(np.random.permutation(barcodes[ss])[:n_cell_each])\n",
    "        barcodes[ss] = list(barcodes[ss][:n_cell_each])\n",
    "    barcodes[0] = barcodes[0][:round(minor_sample * n_cell_each)]\n",
    "    return barcodes\n",
    "\n",
    "\n",
    "def pool_barcodes(barcodes, out_dir, doublet_rate=None, sample_suffix=True, \n",
    "    seed=None):\n",
    "    \"\"\"\n",
    "    Update cell barcodes with sample id and add doublets.\n",
    "    Note, barcodes is a list of multiple samples, each  \n",
    "    sample has a list of barcodes.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    if sample_suffix:\n",
    "        barcodes_out = []\n",
    "        for ss in range(len(barcodes)):\n",
    "            barcodes_out.append([x[:-1]+str(ss+1) for x in barcodes[ss]])\n",
    "    else:\n",
    "        barcodes_out = barcodes.copy()\n",
    "    barcodes_flat = list(itertools.chain(*barcodes_out))\n",
    "            \n",
    "    n_cells = len(barcodes_flat)\n",
    "    if doublet_rate is None:\n",
    "        doublet_rate = n_cells / 100000.0\n",
    "    elif doublet_rate < 0 or doublet_rate > 1:\n",
    "        print(\"Error: doublet rate needs to be between 0 and 1.\")\n",
    "        sys.exit(1)\n",
    "    if doublet_rate == 0:\n",
    "        n_doublets = 0\n",
    "    else:\n",
    "        n_doublets = round(n_cells / (1 + 1 / doublet_rate))\n",
    "        \n",
    "    print(n_cells, n_doublets)\n",
    "\n",
    "    perm_idx = np.arange(n_cells) #np.random.permutation(n_cells)\n",
    "    for ii in range(n_doublets):\n",
    "        if (barcodes_flat[perm_idx[ii]].split(\"-\")[1] == \n",
    "            barcodes_flat[perm_idx[ii + n_doublets]].split(\"-\")[1]):\n",
    "            _barcode = barcodes_flat[perm_idx[ii]] + \"S\"\n",
    "        else:\n",
    "            _barcode = barcodes_flat[perm_idx[ii]] + \"D\"\n",
    "        barcodes_flat[perm_idx[ii]] = _barcode\n",
    "        barcodes_flat[perm_idx[ii + n_doublets]] = _barcode\n",
    "\n",
    "    start_idx = 0\n",
    "    for ss in range(len(barcodes_out)):\n",
    "        _n_cell = len(barcodes_out[ss])\n",
    "        barcodes_out[ss] = barcodes_flat[start_idx: start_idx + _n_cell]\n",
    "        start_idx += _n_cell\n",
    "\n",
    "    ## save new cell barcodes\n",
    "    fid = open(out_dir + \"/barcodes_pool.tsv\", \"w\")\n",
    "    for _barcode in np.unique(barcodes_flat):\n",
    "        fid.writelines(_barcode + \"\\n\")\n",
    "    fid.close()\n",
    "\n",
    "    fid = open(out_dir + \"/cell_info.tsv\", \"w\")\n",
    "    fid.writelines(\"CB_pool\\tCB_origin\\tSample_id\\n\")\n",
    "    for ss in range(len(barcodes_out)):\n",
    "        for ii in range(len(barcodes_out[ss])):\n",
    "            _out = [barcodes_out[ss][ii], barcodes[ss][ii], str(ss + 1)]\n",
    "            fid.writelines(\"\\t\".join(_out) + \"\\n\")\n",
    "    fid.close()\n",
    "    return barcodes_out\n",
    "\n",
    "\n",
    "def fetch_reads(samFile_list, chroms, positions, outbam, \n",
    "                barcodes_in, barcodes_out=None, cell_tag='CB'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    samFile_list = [check_pysam_chrom(x, chroms[0])[0] for x in samFile_list]\n",
    "    outbam = pysam.AlignmentFile(outbam, \"wb\", template=samFile_list[0])\n",
    "    if barcodes_out is None:\n",
    "        barcodes_out = barcodes_in.copy()\n",
    "    \n",
    "    for ss in range(len(samFile_list)):\n",
    "        samFile = samFile_list[ss]\n",
    "        _barcodes_in = barcodes_in[ss]\n",
    "        _barcodes_out = barcodes_out[ss]\n",
    "        \n",
    "        READ_CNT = 0\n",
    "        reads_all = []\n",
    "        for i in range(len(positions)):\n",
    "            chrom = chroms[i]\n",
    "            POS = positions[i]\n",
    "            \n",
    "            for _read in samFile.fetch(chrom, POS-1, POS):\n",
    "                if _read.has_tag(cell_tag) == False:\n",
    "                    continue\n",
    "                try:\n",
    "                    idx = _barcodes_in.index(_read.get_tag(cell_tag))\n",
    "                    _read.set_tag(cell_tag, _barcodes_out[idx])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                reads_all.append(_read)\n",
    "                \n",
    "                READ_CNT += 1\n",
    "                if READ_CNT % 100000 == 0:\n",
    "                    print(\"BAM%d: %.2fM reads.\" %(ss+1, READ_CNT/1000000))\n",
    "        \n",
    "        # remove redundant reads (one read may be called multiple times)\n",
    "        reads_all = set(reads_all)\n",
    "        print(len(reads_all), READ_CNT)\n",
    "        for _read in reads_all:\n",
    "            outbam.write(_read)\n",
    "            \n",
    "        samFile.close()\n",
    "    outbam.close()\n",
    "    return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff355f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "samFiles = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/somatic_variants/preproc/bam/Control.bam,/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/somatic_variants/preproc/bam/Flt3l.bam,/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/somatic_variants/preproc/bam/Input.bam\"\n",
    "barcodeFiles = \"/home/isaac/lewis/mito_lineage/output/mtscATAC/data/CHIP_dec172021_b1/MTBlacklist_A2/Control/outs/filtered_peak_bc_matrix/barcodes.tsv,/home/isaac/lewis/mito_lineage/output/mtscATAC/data/CHIP_dec172021_b1/MTBlacklist_A2/Flt3l/outs/filtered_peak_bc_matrix/barcodes.tsv,/home/isaac/lewis/mito_lineage/output/mtscATAC/data/CHIP_dec172021_b1/MTBlacklist_A2/Input/outs/filtered_peak_bc_matrix/barcodes.tsv\"\n",
    "regionFile = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clones/variants_init/knn/kparam_3/gff_A2_black/annotation_clones/merged_peaks.bed\"\n",
    "outDir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/somatic_variants/preproc/merge_bam\"\n",
    "randomSEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d782c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Options at 0x7fa71c530d50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Options(object):\n",
    "    def __init__(self, samFiles, barcodeFiles, regionFile, outDir, randomSEED):\n",
    "        self.sam_files = samFiles\n",
    "        self.region_file = regionFile\n",
    "        self.double_rate = None\n",
    "        self.barcodes_files = barcodeFiles \n",
    "        self.out_dir = outDir\n",
    "        self.n_cell = None\n",
    "        self.minor_sample = 1.0\n",
    "        self.nproc = 4\n",
    "        self.random_seed = randomSEED\n",
    "        return\n",
    "    \n",
    "options = Options(samFiles, barcodeFiles, regionFile, outDir, randomSEED)\n",
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43e400d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "barcodes_files = options.barcodes_files.split(\",\")\n",
    "samFile_list = options.sam_files.split(\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a2498f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chr</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>9865.0</td>\n",
       "      <td>10638</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>16105.0</td>\n",
       "      <td>16366</td>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>180723.0</td>\n",
       "      <td>181403</td>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>184125.0</td>\n",
       "      <td>184527</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>191058.0</td>\n",
       "      <td>192097</td>\n",
       "      <td>5</td>\n",
       "      <td>.</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Chr     Start     End  3  4  5\n",
       "0  chr1    9865.0   10638  1  .  *\n",
       "1  chr1   16105.0   16366  2  .  *\n",
       "2  chr1  180723.0  181403  3  .  *\n",
       "3  chr1  184125.0  184527  4  .  *\n",
       "4  chr1  191058.0  192097  5  .  *"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bed file\n",
    "bed_dat = pd.read_csv(options.region_file, header=None, sep=\"\\t\")\n",
    "bed_dat = bed_dat.rename({0:\"Chr\", 1:\"Start\", 2:\"End\"}, axis=1)\n",
    "bed_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30edd4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afafb4f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c69b82bb3d4089b3e959806a8fa350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBoxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Pos   Chr\n",
      "0           9866  chr1\n",
      "1           9867  chr1\n",
      "2           9868  chr1\n",
      "3           9869  chr1\n",
      "4           9870  chr1\n",
      "...          ...   ...\n",
      "978773  10338468  chr1\n",
      "978774  10338469  chr1\n",
      "978775  10338470  chr1\n",
      "978776  10338471  chr1\n",
      "978777  10338472  chr1\n",
      "\n",
      "[978778 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def flatten_bed(curr_region):\n",
    "    \"\"\" Create chr and pos dataframe based on the bed region, and add 1 from start\"\"\"\n",
    "    start = curr_region[\"Start\"]+1\n",
    "    positions = np.arange(start, curr_region[\"End\"]+1)\n",
    "    df = pd.DataFrame(positions, columns=[\"Pos\"], dtype=int)\n",
    "    df[\"Chr\"] = curr_region[\"Chr\"]\n",
    "    return df\n",
    "bed_df = pd.concat(bed_dat.parallel_apply(flatten_bed, axis=1).values, axis=0, ignore_index=True)\n",
    "print(bed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84bede5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_chr 978778\n",
      "n_positions 978778\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "chroms = bed_df[\"Chr\"]\n",
    "positions = bed_df[\"Pos\"]\n",
    "\n",
    "print('n_chr', len(chroms))\n",
    "print('n_positions', len(positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f634d7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2392988/1921056798.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     barcodes_in = sample_barcodes(barcodes_in, options.n_cell,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#         options.minor_sample, options.random_seed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m barcodes_out = pool_barcodes(barcodes_in, out_dir, options.doublet_rate, \n\u001b[0m\u001b[1;32m     11\u001b[0m     seed=options.random_seed)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_dir' is not defined"
     ]
    }
   ],
   "source": [
    "barcodes_in = []\n",
    "for _bar in barcodes_files:\n",
    "    fid = open(_bar, 'r')\n",
    "    all_lines = [x.rstrip() for x in fid.readlines()]\n",
    "    fid.close()\n",
    "    barcodes_in.append(all_lines)\n",
    "# if options.n_cell is not None:\n",
    "#     barcodes_in = sample_barcodes(barcodes_in, options.n_cell,\n",
    "#         options.minor_sample, options.random_seed)\n",
    "barcodes_out = pool_barcodes(barcodes_in, out_dir, options.doublet_rate, \n",
    "    seed=options.random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a3756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## out directory\n",
    "# if options.out_dir is None:\n",
    "#     print(\"Error: need outDir for output files.\")\n",
    "#     sys.exit(1)\n",
    "# elif os.path.dirname(options.out_dir) == \"\":\n",
    "#     out_dir= \"./\" + options.out_dir\n",
    "# else:\n",
    "#     out_dir = options.out_dir\n",
    "# if not os.path.exists(out_dir):\n",
    "#     os.mkdir(out_dir)\n",
    "\n",
    "# ## sam files\n",
    "# if options.sam_files is None:\n",
    "#     print(\"Error: need samFile for sam file.\")\n",
    "#     sys.exit(1)\n",
    "# else:\n",
    "#     samFile_list = options.sam_files.split(\",\")\n",
    "\n",
    "# ## cell barcodes\n",
    "# if options.barcodes_files is None:\n",
    "#     print(\"Error: need files for cell barcodes.\")\n",
    "#     sys.exit(1)\n",
    "# else:\n",
    "#     barcodes_files = options.barcodes_files.split(\",\")\n",
    "# if len(barcodes_files) != len(samFile_list):\n",
    "#     print(\"Error: barcodes files are not equal to sam files.\")\n",
    "#     sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f36439",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    import warnings\n",
    "    warnings.filterwarnings('error')\n",
    "\n",
    "#     # parse command line options\n",
    "#     parser = OptionParser()\n",
    "#     parser.add_option(\"--samFiles\", \"-s\", dest=\"sam_files\", default=None,\n",
    "#         help=(\"Input bam or sam files, comma separated.\"))\n",
    "#     parser.add_option(\"--barcodeFiles\", \"-b\", dest=\"barcodes_files\", \n",
    "#         default=None, help=(\"Input barcode files, comma separated.\"))\n",
    "#     parser.add_option(\"--regionFile\", \"-r\", dest=\"region_file\",\n",
    "#         default=None, help=(\"Input SNP list.\"))\n",
    "#     parser.add_option(\"--doubletRate\", \"-d\", dest=\"doublet_rate\", \n",
    "#         type=\"float\", default=None, help=(\"Doublet rate [default: n/100000]\"))\n",
    "#     parser.add_option(\"--outDir\", \"-o\", dest=\"out_dir\", default=None,\n",
    "#         help=(\"Directory for output files: pooled.bam and barcodes_pool.tsv.\"))\n",
    "#     parser.add_option(\"--nproc\", \"-p\", type=\"int\", dest=\"nproc\", default=1,\n",
    "#         help=\"Number of subprocesses [default: %default]\")\n",
    "\n",
    "#     group = OptionGroup(parser, \"Cell barcodes sampling\")\n",
    "#     group.add_option(\"--nCELL\", type=\"int\", dest=\"n_cell\", default=None, \n",
    "#         help=\"The number of cells in each sample [default: %default]\")\n",
    "#     group.add_option(\"--minorSAMPLE\", type=\"float\", dest=\"minor_sample\", \n",
    "#         default=1.0, help=\"Ratio size of minor sample [default: %default]\")\n",
    "#     group.add_option(\"--randomSEED\", type=\"int\", dest=\"random_seed\", \n",
    "#         default=None, help=\"The random seed in numpy [default: %default]\")\n",
    "#     parser.add_option_group(group)\n",
    "\n",
    "#     (options, args) = parser.parse_args()\n",
    "    if len(sys.argv[1:]) == 0:\n",
    "        print(\"Welcome to VCF_convert!\\n\")\n",
    "        print(\"use -h or --help for help on argument.\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    ## out directory\n",
    "    if options.out_dir is None:\n",
    "        print(\"Error: need outDir for output files.\")\n",
    "        sys.exit(1)\n",
    "    elif os.path.dirname(options.out_dir) == \"\":\n",
    "        out_dir= \"./\" + options.out_dir\n",
    "    else:\n",
    "        out_dir = options.out_dir\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "        \n",
    "    ## sam files\n",
    "    if options.sam_files is None:\n",
    "        print(\"Error: need samFile for sam file.\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        samFile_list = options.sam_files.split(\",\")\n",
    "    \n",
    "    ## cell barcodes\n",
    "    if options.barcodes_files is None:\n",
    "        print(\"Error: need files for cell barcodes.\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        barcodes_files = options.barcodes_files.split(\",\")\n",
    "    if len(barcodes_files) != len(samFile_list):\n",
    "        print(\"Error: barcodes files are not equal to sam files.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    barcodes_in = []\n",
    "    for _bar in barcodes_files:\n",
    "        fid = open(_bar, 'r')\n",
    "        all_lines = [x.rstrip() for x in fid.readlines()]\n",
    "        fid.close()\n",
    "        barcodes_in.append(all_lines)\n",
    "    # if options.n_cell is not None:\n",
    "    #     barcodes_in = sample_barcodes(barcodes_in, options.n_cell,\n",
    "    #         options.minor_sample, options.random_seed)\n",
    "    barcodes_out = pool_barcodes(barcodes_in, out_dir, options.doublet_rate, \n",
    "        seed=options.random_seed)\n",
    "    \n",
    "    ## Bed file\n",
    "    bed_dat = pd.read_csv(options.region_file, header=None, sep=\"\\t\")\n",
    "    bed_dat = bed_dat.rename({0:\"Chr\", 1:\"Start\", 2:\"End\"}, axis=1)\n",
    "    def flatten_bed(curr_region):\n",
    "        \"\"\" Create chr and pos dataframe based on the bed region, and add 1 from start\"\"\"\n",
    "        start = curr_region[\"Start\"]+1\n",
    "        positions = np.arange(start, curr_region[\"End\"]+1)\n",
    "        df = pd.DataFrame(positions, columns=[\"Pos\"])\n",
    "        df[\"Chr\"] = curr_region[\"Chr\"]\n",
    "        return df\n",
    "    bed_df = bed_dat.apply(flatten_bed, axis=1)\n",
    "    print('bed_df', bed_df)\n",
    "    print(bed_df.head())\n",
    "    chroms = bed_df[\"Chr\"]\n",
    "    positions = bed_df[\"Pos\"]\n",
    "\n",
    "    print('n_chr', len(chroms))\n",
    "    print('n_positions', len(positions))\n",
    "    # vcf_dat = load_VCF(options.region_file, biallelic_only=False,\n",
    "    #                    load_sample=False)\n",
    "    # chroms = vcf_dat['FixedINFO']['CHROM']\n",
    "    # positions = [int(x) for x in vcf_dat['FixedINFO']['POS']]\n",
    "\n",
    "\n",
    "    # fetch each position\n",
    "    if (options.nproc == 1):\n",
    "        BAM_FILE = out_dir + \"/pooled.bam\"\n",
    "        fetch_reads(samFile_list, chroms, positions, \n",
    "            BAM_FILE, barcodes_in, barcodes_out)\n",
    "    else:\n",
    "        result = []\n",
    "        pool = multiprocessing.Pool(processes=options.nproc)\n",
    "        for ii in range(len(samFile_list)):\n",
    "            BAM_FILE = out_dir + \"/pooled_temp%d.bam\" %(ii)\n",
    "            print(ii, BAM_FILE)\n",
    "            result.append(pool.apply_async(fetch_reads, ([samFile_list[ii]], \n",
    "                chroms, positions, BAM_FILE, [barcodes_in[ii]], \n",
    "                [barcodes_out[ii]], \"CB\"), callback=show_progress))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        ## merge bam files\n",
    "        file_list = [out_dir + \"/pooled.bam\"]\n",
    "        file_list += [out_dir + \"/pooled_temp%d.bam\" %(x) \n",
    "                        for x in range(len(samFile_list))]\n",
    "        bashCommand = \"samtools merge %s\" %(\" \".join(file_list))\n",
    "        pro = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "        pro.communicate()[0]\n",
    "        for dd in range(len(samFile_list)):\n",
    "            os.remove(out_dir + \"/pooled_temp%d.bam\" %(dd))\n",
    "    print(\"\")\n",
    "\n",
    "    ## sort and index bam file\n",
    "    bashCommand = \"samtools sort %s -o %s\" %(out_dir + \"/pooled.bam\", \n",
    "        out_dir + \"/pooled.sorted.bam\")\n",
    "    pro = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    pro.communicate()[0]\n",
    "    \n",
    "    bashCommand = \"samtools index %s\" %(out_dir + \"/pooled.sorted.bam\")\n",
    "    pro = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    pro.communicate()[0]\n",
    "\n",
    "    os.remove(out_dir + \"/pooled.bam\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec8cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
