{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ae72f",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Input info\n",
    "se_cells_meta_f = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clones/variants_simpleUnion/knn/kparam_30/gff_A2_black/annotation_clones/se_cells_meta_labels.tsv\"\n",
    "#mt_as_clones_dir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/multiplex/clones_simpleUnion/mt_clones_thresh/donor_0_thresh_results.tsv\"\n",
    "mt_as_clones_dir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/multiplex/clones_simpleUnion/mt_clones_thresh\"\n",
    "\n",
    "outdir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/multiplex/clones_simpleUnion/mt_clones_thresh/clonal_shifts/\"\n",
    "\n",
    "\n",
    "atac_col = \"cluster_labels\"\n",
    "clone_col = \"Variants\"\n",
    "\n",
    "af_t = 0.1\n",
    "oth_af_t = 0.1\n",
    "cov_t = 10\n",
    "oth_cov_t = 10\n",
    "ncells = 10\n",
    "oth_ncells = 0.25 \n",
    "mean_pos_cov = 0\n",
    "\n",
    "# config\n",
    "N_DONORS = 2\n",
    "input_cond = \"Input\"\n",
    "\n",
    "# params\n",
    "min_clone_size = 10\n",
    "p_thresh = 0.1 \n",
    "\n",
    "\n",
    "#conds_sep = False\n",
    "\n",
    "counts_f = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e6db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join, exists\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scipy.stats import hypergeom, fisher_exact\n",
    "from statsmodels.stats import multitest \n",
    "\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from src import clonal_shifts as cs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e3803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca5a40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cells_dir=join(mt_as_clones_dir, \"cells\")\n",
    "labels_df = pd.read_csv(se_cells_meta_f,sep=\"\\t\").set_index(\"ID\")\n",
    "print(labels_df.shape)\n",
    "\n",
    "labels_df = labels_df[~(labels_df[\"donor\"]=='None')]\n",
    "print(labels_df.shape)\n",
    "labels_df.head()\n",
    "def fill_mt_bin(curr_pos, curr_cells):\n",
    "    print(curr_pos.name)\n",
    "    curr_pos.loc[curr_cells[curr_pos.name][\"other_cells\"]] = 0\n",
    "    curr_pos.loc[curr_cells[curr_pos.name][\"clone_cells\"]] = 1\n",
    "    return curr_pos\n",
    "bin_d = {}\n",
    "for d in range(N_DONORS): \n",
    "    curr_f = join(cells_dir, f\"don.{d}_af.{af_t}_othaf.{oth_af_t}_cov.{cov_t}_othcov.{oth_cov_t}.p\")\n",
    "    curr_cells = pickle.load(open(curr_f,'rb'))\n",
    "    params_results = pd.read_csv(join(mt_as_clones_dir, f\"donor_{d}_thresh_results.tsv\"), sep=\"\\t\")    \n",
    "\n",
    "\n",
    "    curr_p = params_results.loc[(params_results[\"af\"]==af_t) &\n",
    "                       (params_results[\"oth_af\"]==oth_af_t) &\n",
    "                       (params_results[\"cov\"]==cov_t) &\n",
    "                       (params_results[\"oth_cov\"]==oth_cov_t) &\n",
    "                       (params_results[\"ncells\"]==ncells) &\n",
    "                       (params_results[\"oth_ncells\"]==oth_ncells) &\n",
    "                       (params_results[\"mean_cov\"]==mean_pos_cov)]\n",
    "    assert(len(curr_p)==1)\n",
    "    \n",
    "    ## Construct a binary cell-by-variant matrix for the kept variants. \n",
    "    ## Can add N/A if not in oth cells\n",
    "    curr_vars = curr_p.iloc[0][\"Variants\"].split(\";\")\n",
    "\n",
    "    all_cells = set()\n",
    "    for x in curr_cells:\n",
    "        all_cells = all_cells.union(set(curr_cells[x][\"clone_cells\"])) \n",
    "        all_cells = all_cells.union(set(curr_cells[x][\"other_cells\"])) \n",
    "\n",
    "    mt_bin = pd.DataFrame(index = all_cells, columns=curr_vars)\n",
    "    bin_d[d] = mt_bin.apply(fill_mt_bin, curr_cells=curr_cells,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d980b6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_mt_ncells(curr_df, bin_d):\n",
    "    lab, don = curr_df.name\n",
    "    curr_bin = bin_d[int(don)]\n",
    "    out = curr_bin.loc[curr_bin.index.isin(curr_df.index)].sum(axis=0).fillna(0)\n",
    "    out.name = \"count\"\n",
    "    return out #curr_bin.loc[curr_df.index].sum(axis=0)\n",
    "    \n",
    "lin_mt_ncells = labels_df.groupby([\"cluster_labels\", \"donor\"]).apply(get_mt_ncells, bin_d)\n",
    "lin_mt_ncells = lin_mt_ncells.reset_index().rename({\"level_2\":\"Variants\"}, axis=1)\n",
    "\n",
    "# convert back to raw cell count from log2\n",
    "#lin_mt_ncells[\"count\"] = (np.ceil((2**lin_mt_ncells[\"count\"])-1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c5cfeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lin_mt_ncells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a914917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sep_dir = join(outdir,\"sepDonors\")\n",
    "if not exists(sep_dir):\n",
    "    os.mkdir(sep_dir)\n",
    "donor_out = {}\n",
    "for d in np.arange(N_DONORS):\n",
    "    donor_out[d] = join(sep_dir, f\"donor{d}\")\n",
    "    if not exists(donor_out[d]):\n",
    "        os.mkdir(donor_out[d])\n",
    "    if not exists(join(donor_out[d], \"shuffle\")):\n",
    "        os.mkdir(join(donor_out[d], \"shuffle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ef20d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for d, val in cells_meta.groupby(\"donor\"):\n",
    "#for curr_don, don_lin_mt_ncells in lin_mt_ncells.groupby(\"donor\"):\n",
    "\n",
    "for d, val in lin_mt_ncells.groupby(\"donor\"):\n",
    "    #curr_groups = val.groupby([atac_col, clone_col]).size().reset_index().rename({0:\"count\"}, axis=1)\n",
    "    curr_groups = val\n",
    "    curr_sizes = val.groupby(clone_col).size().sort_values(ascending=False)\n",
    "    curr_name_cond_size = val.groupby([clone_col]).size()\n",
    "    curr_name_cond_size = curr_name_cond_size[curr_name_cond_size>min_clone_size]\n",
    "    curr_clones_filt = curr_name_cond_size.index \n",
    "    curr_sizes = curr_sizes.loc[curr_clones_filt].sort_values(ascending=False)\n",
    "    \n",
    "    curr_clones = np.unique(curr_groups[clone_col])\n",
    "    curr_clone_map = {x:ind for ind,x in enumerate(curr_clones)}\n",
    "    print(curr_clones)\n",
    "    curr_atac_cl = np.unique(curr_groups[atac_col])\n",
    "    print(curr_atac_cl)\n",
    "\n",
    "    output_df, bh_enrichment_df = cs.pipeline_groups_hypergeo(curr_groups, curr_clones, curr_atac_cl, curr_sizes,\n",
    "                                                             p_thresh=p_thresh, atac_col=atac_col, \n",
    "                                                              clone_col=clone_col)\n",
    "    #cs.pipeline_groups_hypergeo(curr_groups, curr_clones, curr_atac_cl, curr_sizes)\n",
    "\n",
    "    curr_don_out = donor_out[int(d)]\n",
    "    bh_enrichment_df.to_csv(join(curr_don_out, \"hypergeo_input_padjusted.csv\"))\n",
    "    output_df.to_csv(join(curr_don_out, \"hypergeo_input_padjusted_sigOnly.csv\"))\n",
    "    \n",
    "    if output_df.shape[0] == 0:   \n",
    "        g = sns.clustermap(-np.log10(bh_enrichment_df.fillna(1)), \n",
    "                       row_cluster=False)\n",
    "        g.fig.suptitle(\"No groups were significant\")\n",
    "    else:\n",
    "        g = sns.clustermap(-np.log10(bh_enrichment_df.loc[output_df.index].fillna(1)), \n",
    "                       row_cluster=False)\n",
    "    g.ax_heatmap.set(xlabel=\"Cluster ID\")\n",
    "    g.ax_cbar.set(title=\"-log10 p-value\")\n",
    "    plt.savefig(join(curr_don_out, \"hypergeo_input_padjusted_sigOnly.png\"))\n",
    "    \n",
    "    \n",
    "    init_bh_enrichment = cs.create_enrichment(curr_groups, atac_col, clone_col, p_thresh,\n",
    "                                              clones=curr_clones, atac_cl=curr_atac_cl)\n",
    "    \n",
    "    shuffle = cs.shuffle_hypergeo(curr_groups, atac_col, clone_col, p_thresh, curr_clones, curr_atac_cl, \n",
    "                                  n_shuffle=1000, to_parallel=True, n_cpus=24)\n",
    "\n",
    "    results_df, out_d = cs.get_out(shuffle, curr_clones, init_bh_enrichment, p_thresh, \n",
    "                                                          curr_clone_map, atac_col, \n",
    "                                                          outdir=join(curr_don_out, \"shuffle\"))\n",
    "    \n",
    "    \n",
    "#     # plot just the counts\n",
    "#     curr_groups[\"log2_count\"] = np.log2(curr_groups[\"count\"]+1)\n",
    "#     g = sns.clustermap(curr_groups.pivot(index=atac_col,columns=clone_col, values=\"log2_count\").fillna(0))\n",
    "#     plt.gca().set_title(\"log2 ncells\")\n",
    "#     plt.savefig(join(curr_don_out, \"ncells.png\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_clones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f3308d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16059d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd7256a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cs.create_enrichment(curr_groups, atac_col, clone_col, p_thresh, clones=curr_clones, atac_cl=curr_atac_cl)\n",
    "#     clones, atac_cl = get_groups(curr_groupsr, curr_clones, curr_atac_cl, clone_col,\n",
    "#                                  atac_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f8a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65550f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e87f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e62b098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b348b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for curr_don, don_lin_mt_ncells in lin_mt_ncells.groupby(\"donor\"):\n",
    "    curr_don_mt = don_lin_mt_ncells.set_index([\"cluster_labels\",\"donor\"])\n",
    "    #lin_mt_ncells_w = curr_don_mt.reset_index().melt(id_vars=[\"cluster_labels\", \"donor\"], var_name=\"Variant\", value_name=\"ncells\")\n",
    "    don_lin_mt_ncells_df = don_lin_mt_ncells.pivot(index=\"cluster_labels\", columns=\"Variants\", values=\"ncells\" )\n",
    "    sns.clustermap(don_lin_mt_ncells_df.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6bdd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "don_lin_mt_ncells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592525d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b712cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036aa781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08c1b8e0",
   "metadata": {},
   "source": [
    "## Load cells_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bb0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_meta = pd.read_csv(se_cells_meta_f, sep=\"\\t\")\n",
    "cells_meta = cells_meta.loc[~(cells_meta[\"name\"]==\"None\")]\n",
    "\n",
    "if not \"cluster_labels\" in cells_meta.columns.values:\n",
    "    cells_meta[\"cluster_labels\"] = cells_meta[\"seurat_clusters\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6393619",
   "metadata": {},
   "source": [
    "## Map the new group to cells_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bb2ceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cells_meta[clone_col] = cells_meta.apply(lambda x: barcodes_in[int(x[\"donor\"])].loc[x[\"name\"], clone_col] , axis=1)\n",
    "cells_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bcd75a",
   "metadata": {},
   "source": [
    "## Filter for input only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b53517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_meta = cells_meta.loc[cells_meta[\"condition\"]==input_cond]\n",
    "cells_meta.head()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
