{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ae72f",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Input info\n",
    "# se_cells_meta_f = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clones/variants_init/knn/kparam_30/gff_A2_black/annotation_clones/se_cells_meta_labels.tsv\"\n",
    "# barcodes_dir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clones/variants_init/knn/kparam_30/barcodes/btwnClones_dendro_dt_0.6\"\n",
    "# outdir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clones/variants_init/knn/kparam_30/clonal_shifts/mincl.10_bothConds.False_p0.1/clones.dendro_dt_0.6__nuc.clust/\"\n",
    "clone_col = \"den_clust\"\n",
    "atac_col = \"cluster_labels\"\n",
    "\n",
    "# config\n",
    "input_cond = \"Input\"\n",
    "condition = \"inputOnly\" # noInput\n",
    "\n",
    "# params\n",
    "min_clone_size = 2\n",
    "p_thresh = 0.1 \n",
    "n_shuffle=1000\n",
    "n_cpus = 8\n",
    "\n",
    "\n",
    "se_cells_meta_f = \"/data/Mito_Trace/output/pipeline/v03/CHIP_Input_nameFix_april08_2021/MTblacklist/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clones/variants_init/knn/kparam_50/gff_hg38_1_2/annotation_clones/se_cells_meta_labels.tsv\"\n",
    "outdir = \"/data/Mito_Trace/output/pipeline/v03/CHIP_Input_nameFix_april08_2021/MTblacklist/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clonal_shifts/variants_init/dendro_bc/results/inputOnly/knn/kparam_50\"\n",
    "barcodes_dir = \"/data/Mito_Trace/output/pipeline/v03/CHIP_Input_nameFix_april08_2021/MTblacklist/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clones/variants_init/knn/kparam_50/barcodes/btwnClones_dendro_dt_0.6\"\n",
    "N_DONORS = 5\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e6db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join, exists\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scipy.stats import hypergeom, fisher_exact\n",
    "from statsmodels.stats import multitest \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import clonal_shifts as cs\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cec211d",
   "metadata": {},
   "source": [
    "### Setup outdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99550014",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dir = join(outdir,\"combDonors\")\n",
    "sep_dir = join(outdir,\"sepDonors\")\n",
    "\n",
    "\n",
    "if not exists(all_dir):\n",
    "    os.mkdir(all_dir)\n",
    "    \n",
    "if not exists(sep_dir):\n",
    "    os.mkdir(sep_dir)\n",
    "\n",
    "donor_out = {}\n",
    "for d in np.arange(N_DONORS):\n",
    "    donor_out[d] = join(sep_dir, f\"donor{d}\")\n",
    "    if not exists(donor_out[d]):\n",
    "        os.mkdir(donor_out[d])\n",
    "        \n",
    "    \n",
    "# sim_all_dir = join(all_dir, \"shuffle\")\n",
    "# sim_sep_dir = join(sep_dir, \"shuffle\")\n",
    "# if not exists(sep_dir):\n",
    "#     os.mkdir(sep_dir)\n",
    "# if not exists(sim_all_dir):\n",
    "#     os.mkdir(sim_all_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b230858",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c87b838",
   "metadata": {},
   "source": [
    "## Load barcodes, and add donor id for the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc38ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_in = {}\n",
    "for d in np.arange(N_DONORS):\n",
    "    barcodes_in[d] = pd.read_csv(join(barcodes_dir,f\"donor{d}.clones_dendro.csv\"), index_col=0)\n",
    "\n",
    "    barcodes_in[d][clone_col] = str(d) + \"_\" + barcodes_in[d][clone_col]\n",
    "    \n",
    "barcodes_in[d].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe79fa1",
   "metadata": {},
   "source": [
    "## Load cells_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93cc076",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_meta = pd.read_csv(se_cells_meta_f, sep=\"\\t\")\n",
    "cells_meta = cells_meta.loc[~(cells_meta[\"name\"]==\"None\")]\n",
    "\n",
    "if not \"cluster_labels\" in cells_meta.columns.values:\n",
    "    cells_meta[\"cluster_labels\"] = cells_meta[\"seurat_clusters\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfc4c3e",
   "metadata": {},
   "source": [
    "## Map the new group to cells_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42121d7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cells_meta[clone_col] = cells_meta.apply(lambda x: barcodes_in[int(x[\"donor\"])].loc[x[\"name\"], clone_col] , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62833b8",
   "metadata": {},
   "source": [
    "# Filter based on condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e990249d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if condition == \"inputOnly\":\n",
    "    cells_meta = cells_meta.loc[cells_meta[\"condition\"]==input_cond]\n",
    "else:\n",
    "    cells_meta = cells_meta.loc[cells_meta[\"condition\"]!=input_cond]\n",
    "sns.countplot(data=cells_meta,x=clone_col)\n",
    "cells_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760156f3",
   "metadata": {},
   "source": [
    "## construct the clone_groups and atac_cl_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea127c26",
   "metadata": {},
   "source": [
    "## A) Loop through donor and run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d8e162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d, val in cells_meta.groupby(\"donor\"):\n",
    "    print('donor', d)\n",
    "    curr_groups = val.groupby([atac_col, clone_col]).size().reset_index().rename({0:\"count\"}, axis=1)\n",
    "    curr_groups\n",
    "    curr_sizes = val.groupby(clone_col).size().sort_values(ascending=False)\n",
    "    curr_name_cond_size = val.groupby([clone_col]).size()\n",
    "    curr_name_cond_size = curr_name_cond_size[curr_name_cond_size>min_clone_size]\n",
    "    curr_clones_filt = curr_name_cond_size.index \n",
    "    curr_sizes = curr_sizes.loc[curr_clones_filt].sort_values(ascending=False)\n",
    "    \n",
    "    curr_clones = np.unique(curr_groups[clone_col])\n",
    "    curr_clone_map = {x:ind for ind,x in enumerate(curr_clones)}\n",
    "    print(curr_clones)\n",
    "    curr_atac_cl = np.unique(curr_groups[atac_col])\n",
    "    print(curr_atac_cl)\n",
    "    \n",
    "    curr_don_out = donor_out[int(d)]\n",
    "    \n",
    "    # Run init hypergeo and the counts data\n",
    "    cs.hypergeo_plots(curr_groups, curr_clones, curr_atac_cl, curr_sizes, p_thresh, atac_col,\n",
    "                   clone_col, curr_don_out)\n",
    "    \n",
    "    out_df, hyper_df, results_df, out_d = cs.run_data_and_shuffle(curr_groups, curr_don_out, atac_col, clone_col, p_thresh, curr_clones, \n",
    "                                                      curr_atac_cl, n_shuffle=n_shuffle, figs_close=False, to_p_correct=False,\n",
    "                                                                  n_cpus=n_cpus)\n",
    "    \n",
    "#     output_df, bh_enrichment_df = cs.pipeline_groups_hypergeo(curr_groups, curr_clones, curr_atac_cl, curr_sizes,\n",
    "#                                                              p_thresh=p_thresh, atac_col=atac_col, \n",
    "#                                                               clone_col=clone_col)\n",
    "#     #cs.pipeline_groups_hypergeo(curr_groups, curr_clones, curr_atac_cl, curr_sizes)\n",
    "\n",
    "#     curr_don_out = donor_out[int(d)]\n",
    "#     bh_enrichment_df.to_csv(join(curr_don_out, \"hypergeo_input_padjusted.csv\"))\n",
    "#     output_df.to_csv(join(curr_don_out, \"hypergeo_input_padjusted_sigOnly.csv\"))\n",
    "    \n",
    "#     if output_df.shape[0] == 0:   \n",
    "#         g = sns.clustermap(-np.log10(bh_enrichment_df.fillna(1)), \n",
    "#                        row_cluster=False)\n",
    "#         g.fig.suptitle(\"No groups were significant\")\n",
    "#     else:\n",
    "#         g = sns.clustermap(-np.log10(bh_enrichment_df.loc[output_df.index].fillna(1)), \n",
    "#                        row_cluster=False)\n",
    "#     g.ax_heatmap.set(xlabel=\"Cluster ID\")\n",
    "#     g.ax_cbar.set(title=\"-log10 p-value\")\n",
    "#     plt.savefig(join(curr_don_out, \"hypergeo_input_padjusted_sigOnly.png\"))\n",
    "    \n",
    "    \n",
    "#     init_bh_enrichment = cs.create_enrichment(curr_groups, atac_col, clone_col, p_thresh,\n",
    "#                                               clones=curr_clones, atac_cl=curr_atac_cl)\n",
    "    \n",
    "#     shuffle = cs.shuffle_hypergeo(curr_groups, atac_col, clone_col, p_thresh, curr_clones, curr_atac_cl, \n",
    "#                                   n_shuffle=n_shuffle, to_parallel=True, n_cpus=24)\n",
    "\n",
    "#     results_df, out_d = cs.get_out(shuffle, curr_clones, init_bh_enrichment, p_thresh, \n",
    "#                                                           curr_clone_map, atac_col, \n",
    "#                                                           outdir=join(curr_don_out, \"shuffle\"))\n",
    "    \n",
    "    \n",
    "#     # plot just the counts\n",
    "#     curr_groups[\"log2_count\"] = np.log2(curr_groups[\"count\"]+1)\n",
    "#     g = sns.clustermap(curr_groups.pivot(index=atac_col,columns=clone_col, values=\"log2_count\").fillna(0))\n",
    "#     plt.gca().set_title(\"log2 ncells\")\n",
    "#     plt.savefig(join(curr_don_out, \"ncells.png\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8360e5e1",
   "metadata": {},
   "source": [
    "## B) Run using all donors as background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c88b44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sizes = cells_meta.groupby(clone_col).size().sort_values(ascending=False)\n",
    "name_cond_size = cells_meta.groupby([clone_col]).size()\n",
    "name_cond_size = name_cond_size[name_cond_size>min_clone_size]\n",
    "clones_filt = name_cond_size.index \n",
    "\n",
    "sizes = sizes.loc[clones_filt].sort_values(ascending=False)\n",
    "clones_filt\n",
    "\n",
    "groups = cells_meta.groupby([atac_col, clone_col]).size().reset_index().rename({0:\"count\"}, axis=1)\n",
    "groups\n",
    "\n",
    "clones = clones_filt.values #np.unique(groups[\"name\"])\n",
    "clone_map = {x:ind for ind,x in enumerate(clones)}\n",
    "\n",
    "atac_cl = np.unique(groups[atac_col])\n",
    "atac_cl\n",
    "\n",
    "\n",
    "# Run init hypergeo\n",
    "cs.hypergeo_plots(groups, clones, atac_cl, sizes, p_thresh, atac_col,\n",
    "               clone_col, all_dir)\n",
    "## Run shuffle\n",
    "print(\"Running hypergeo shuffle and saving sig results\")\n",
    "out_df, hyper_df, results_df, out_d = cs.run_data_and_shuffle(groups, all_dir, atac_col, clone_col, p_thresh, clones, \n",
    "                                                  atac_cl, n_shuffle=n_shuffle, figs_close=False, to_p_correct=False,\n",
    "                                                              n_cpus=n_cpus)\n",
    "\n",
    "# output_df, bh_enrichment_df = cs.pipeline_groups_hypergeo(groups, clones, atac_cl, sizes,p_thresh, atac_col, clone_col)\n",
    "\n",
    "# bh_enrichment_df.to_csv(join(all_dir, \"hypergeo_input_padjusted.csv\"))\n",
    "# output_df.to_csv(join(all_dir, \"hypergeo_input_padjusted_sigOnly.csv\"))\n",
    "    \n",
    "# g = sns.clustermap(-np.log10(bh_enrichment_df.loc[output_df.index].fillna(1)), \n",
    "#                row_cluster=False)\n",
    "\n",
    "# g.ax_heatmap.set(xlabel=\"Cluster ID\")\n",
    "# g.ax_cbar.set(title=\"-log10 p-value\")\n",
    "# plt.savefig(join(all_dir, \"hypergeo_input_padjusted_sigOnly.png\"))\n",
    "\n",
    "\n",
    "\n",
    "# ## Run shuffle\n",
    "# init_bh_enrichment = cs.create_enrichment(groups, atac_col, clone_col, p_thresh,\n",
    "#                                           clones=clones, atac_cl=atac_cl)\n",
    "\n",
    "# shuffle = cs.shuffle_hypergeo(groups, atac_col, clone_col, p_thresh, clones, atac_cl, n_shuffle=n_shuffle, \n",
    "#                               to_parallel=True, n_cpus=24)\n",
    "\n",
    "# results_df, out_d = cs.get_out(shuffle, clones, bh_enrichment_df, p_thresh, clone_map, atac_col, \n",
    "#                                                      outdir=sim_all_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6027ccc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1972ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind, val in results_df[results_df[\"value\"]<p_thresh].groupby(\"method\"):\n",
    "#     sns.clustermap(val.astype(object).pivot(index=\"index\", columns=\"variable\",values=\"value\").fillna(1),\n",
    "#                   vmax=p_thresh+0.1)\n",
    "#     plt.suptitle(ind)\n",
    "\n",
    "# for ind, val in results_df[results_df[\"value\"]<p_thresh].groupby(\"method\"):\n",
    "#     sns.clustermap(val.astype(object).pivot(index=\"index\", columns=\"variable\",values=\"value\").fillna(1),\n",
    "#                   vmax=0.05)\n",
    "#     plt.suptitle(ind)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
