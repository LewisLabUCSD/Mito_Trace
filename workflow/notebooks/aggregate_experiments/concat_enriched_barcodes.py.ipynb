{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57a92ea7",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "outdir = snakemake.params.outdir\n",
    "clone_var_dirs = snakemake.params.clone_var \n",
    "clcounts_dirs = snakemake.params.clcounts\n",
    "dendro_dirs = snakemake.params.dendro \n",
    "vaf_dirs = snakemake.params.vaf\n",
    "\n",
    "\n",
    "# output\n",
    "# outdir = \"/data/Mito_Trace/output/aggregate/CHIP_aggr/v04/results/enriched_barcodes\"\n",
    "\n",
    "# ## Setup input directories\n",
    "# n_donors = {\n",
    "#     \"chip_b1\": 2,\n",
    "#     \"chip_b2\": 2,\n",
    "#     \"chip_a1\": 5,\n",
    "#     \"cd34\":4\n",
    "# }\n",
    "\n",
    "# clone_var_donor_dirs = {\n",
    "#     \"chip_b1\": \"/data/Mito_Trace/output/pipeline/v04/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/enriched_barcodes/objs_high_cells/clones/variants_init/knn/kparam_30\",\n",
    "#     \"chip_b2\": \"/data/Mito_Trace/output/pipeline/v04/CHIP_b2/InputOnly/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/enriched_barcodes/objs_high_cells/clones/variants_init/knn/kparam_30/\",\n",
    "#     \"chip_a1\": \"/data/Mito_Trace/output/pipeline/v04/CHIP_Input_nameFix_april08_2021/MTblacklist/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/enriched_barcodes/objs_high_cells/clones/variants_init/knn/kparam_30\",\n",
    "#     \"cd34\": \"/data/Mito_Trace/output/pipeline/v04/cd34norm/MTblacklist/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/enriched_barcodes/objs_high_cells/clones/variants_init/knn/kparam_30\"\n",
    "# }\n",
    "\n",
    "\n",
    "# # VAF and clone combine\n",
    "# method_type = \"clonalShift_method_clones/top\"\n",
    "\n",
    "# variants = \"init\"\n",
    "# kparam = 30\n",
    "\n",
    "# cloneMethod = f\"cloneMethod_variants_{variants}_knn_resolution_{kparam}\"\n",
    "\n",
    "# vaf_donor_dirs = {\n",
    "#     \"chip_b1\": \"/data/Mito_Trace/output/pipeline/v04/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/enriched_barcodes/objs_high_cells/repr_clones/\",\n",
    "#     \"chip_b2\": \"/data/Mito_Trace/output/pipeline/v04/CHIP_b2/InputOnly/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/enriched_barcodes/objs_high_cells/repr_clones/\",\n",
    "#     \"chip_a1\": \"/data/Mito_Trace/output/pipeline/v04/CHIP_Input_nameFix_april08_2021/MTblacklist/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/enriched_barcodes/objs_high_cells/repr_clones\",\n",
    "#     \"cd34\": \"/data/Mito_Trace/output/pipeline/v04/cd34norm/MTblacklist/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/enriched_barcodes/objs_high_cells/repr_clones\"\n",
    "# }\n",
    "\n",
    "overwrite=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b786f82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os.path import join, exists, dirname\n",
    "from glob import glob\n",
    "import pickle\n",
    "import mplh.cluster_help as ch\n",
    "import mplh.fig_utils as fu\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.io import mmread\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import hypergeom\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "np.set_printoptions(formatter={'float': lambda x: format(x, '.5f')})\n",
    "\n",
    "from svgutils.compose import *\n",
    "\n",
    "\n",
    "import svgutils.transform as sg\n",
    "import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bcc78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "based on https://neuroscience.telenczuk.pl/?p=331\n",
    "\"\"\"\n",
    "\n",
    "import svgutils.transform as sg\n",
    "\n",
    "\n",
    "class Svg(object):\n",
    "    \"svg files with a data object (the svg), width, height and coordinates\"\n",
    "\n",
    "    def __init__(self, data, dim, coords, name, global_scale=0.5):\n",
    "        self.data = data\n",
    "        self.width = dim[0]*global_scale\n",
    "        self.height = dim[1]*global_scale\n",
    "        self.x = coords[0]\n",
    "        self.y = coords[1]\n",
    "        self.global_scale = global_scale\n",
    "        self.name = name\n",
    "\n",
    "    def scale_width_to_reference(self, reference_width):\n",
    "        \"\"\"Proportionally scale the image to a given width.\"\"\"\n",
    "        scalings_factor = reference_width / self.width\n",
    "        self.data.moveto(0, 0)#, scale=scalings_factor)\n",
    "        self.width = self.width * scalings_factor\n",
    "        self.height = self.height * scalings_factor\n",
    "\n",
    "    def scale_height_to_reference(self, reference_height):\n",
    "        \"\"\"Proportionally scale the image to a given height.\"\"\"\n",
    "        scalings_factor = reference_height / self.height\n",
    "        self.data.moveto(0, 0)#, scale=scalings_factor)\n",
    "        self.width = self.width * scalings_factor\n",
    "        self.height = self.height * scalings_factor\n",
    "        \n",
    "    def scale_by_factor(self, scalings_factor):\n",
    "        \"\"\"Proportionally scale image by a scaling factor.\"\"\"\n",
    "        self.data.moveto(0, 0, scale=scalings_factor)\n",
    "        self.width = self.width * scalings_factor\n",
    "        self.height = self.height * scalings_factor\n",
    "\n",
    "    def move(self, x, y):\n",
    "        \"\"\"Move the coordinates of an image.\"\"\"\n",
    "        self.data.moveto(x, y)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "def get_size(svg_file):\n",
    "    \"\"\"Naively parse the svg text file to get the width and height.\"\"\"\n",
    "    with open(svg_file) as svg:\n",
    "        for line in svg:\n",
    "            if line.startswith('<svg'):\n",
    "                paramdict = {e.split('=\"')[0]: e.split('=\"')[1] for e in line[5:-2].split('\" ')}\n",
    "                break\n",
    "    print(paramdict[\"width\"])\n",
    "    print(\"height\")\n",
    "    print(paramdict[\"height\"])\n",
    "    return int(np.ceil(float(paramdict[\"width\"].replace('pt', '').replace('\"', '')))), int(np.ceil(float(paramdict[\"height\"].replace('pt', '').replace('\"', ''))))\n",
    "\n",
    "\n",
    "\n",
    "def rescale_height(svgs, curr_keys, ref_key):\n",
    "    \"\"\"Change the dimensions of the images to the desired combinations.\"\"\"\n",
    "    for key in curr_keys:\n",
    "        svgs[key].scale_height_to_reference(svgs[ref_key].height)\n",
    "    #assert svgs[ref_key].height == svgs[curr_keys[0]].height == svgs[curr_keys[-1]].height\n",
    "\n",
    "\n",
    "def rescale_width(svgs, curr_keys, ref_key):\n",
    "    \"\"\"Change the dimensions of the images to the desired combinations.\"\"\"\n",
    "    for key in curr_keys:\n",
    "        svgs[key].scale_width_to_reference(svgs[ref_key].width)\n",
    "    #assert svgs[ref_key].height == svgs[curr_keys[0]].height == svgs[curr_keys[-1]].height\n",
    "\n",
    "\n",
    "def change_positions(df, svgs, widths, heights):\n",
    "    \"\"\"Move the images to the desired positions.\"\"\"\n",
    "    for i_row, row in enumerate(df.index):\n",
    "        for i_col, col in enumerate(df.columns):\n",
    "            curr = df.loc[row, col].split(\".svg\")[0]\n",
    "            svgs[curr].move(sum(widths[:i_col]), sum(heights[:i_row]))\n",
    "    \n",
    "\n",
    "def letter_annotations(svgs, df=None, only_grid_titles=True, figure_names=None, transposed=False):\n",
    "    if only_grid_titles:\n",
    "        all_texts = []\n",
    "        if transposed: # make donors the columns and figure_names the rows\n",
    "            for ind in df.index:\n",
    "                nm = figure_names[ind]\n",
    "                value = svgs[df.loc[ind].iloc[0].split(\".svg\")[0]]\n",
    "                all_texts.append(sg.TextElement(value.x, value.y-10, nm, size=15, weight=\"bold\")) \n",
    "            for col in df.columns:\n",
    "                value = svgs[df[col].iloc[0].split(\".svg\")[0]]\n",
    "                all_texts.append(sg.TextElement(value.x, value.y-10, col, size=15, weight=\"bold\"))\n",
    "                \n",
    "        else:\n",
    "            for ind in df.index:\n",
    "                value = svgs[df.loc[ind].iloc[0].split(\".svg\")[0]]\n",
    "                all_texts.append(sg.TextElement(value.x, value.y, ind, size=15, weight=\"bold\"))\n",
    "            for col in df.columns:\n",
    "                nm = figure_names[col]\n",
    "                value = svgs[df[col].iloc[0].split(\".svg\")[0]]\n",
    "                all_texts.append(sg.TextElement(value.x, value.y-10, nm, size=15, weight=\"bold\"))    \n",
    "        return all_texts\n",
    "    \"\"\"Add letters based on the location of the images.\"\"\"\n",
    "    return [sg.TextElement(value.x, value.y, value.name, size=15, weight=\"bold\")\n",
    "            for key, value in svgs.items()]\n",
    "#     return [sg.TextElement(value.x + 10, value.y + 15, value.name, size=15, weight=\"bold\")\n",
    "#             for key, value in svgs.items()]\n",
    "\n",
    "\n",
    "def files_to_svg_dict(df, scale=0.5, verbose=False):\n",
    "    \"\"\"Convert a list of images to a dictionary.\n",
    "    Mapping the image basename to the Svg class instance,\n",
    "    setting the dimensions based on sizes and coordinates (0,0) by default\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for row in df.index:\n",
    "        for col in df.columns:\n",
    "            s = df.loc[row, col]\n",
    "            key = df.loc[row, col].split(\".svg\")[0]\n",
    "            name = f\"{row} {col.replace('dendro', '').replace('.svg', '')}\"\n",
    "            if verbose:\n",
    "                print(s)\n",
    "            out[key] = Svg(\n",
    "                data=sg.fromfile(s).getroot().scale(scale),\n",
    "                dim=get_size(s),\n",
    "                coords=(0, 0),\n",
    "                global_scale=scale,\n",
    "                name=name)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main_df(df, out_f, scale=0.25, figure_names=None, to_pdf=False):\n",
    "    svgs = files_to_svg_dict(df, scale=scale)#df.values().flatten())\n",
    "    \n",
    "    for don, val in df.iterrows():\n",
    "        curr_init_files = []\n",
    "        curr_ref = val.iloc[0].split('.svg')[0] #svgs[val.iloc[0].split('.svg')[0]]\n",
    "        curr_keys = [x.split('.svg')[0] for x in val.values] \n",
    "        rescale_height(svgs, curr_keys, curr_ref)\n",
    "    \n",
    "    col_max_widths = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        curr_col_max = 0\n",
    "        for ind in df.index:\n",
    "            tmp_width = svgs[df.loc[ind, col].split(\".svg\")[0]].width\n",
    "            if tmp_width > curr_col_max:\n",
    "                curr_col_max = tmp_width\n",
    "        col_max_widths.append(curr_col_max)\n",
    "\n",
    "    row_max_heights = [] #should be the same in theory  \n",
    "    for ind in df.index:\n",
    "        curr_row_max = 0\n",
    "        for col in df.columns:\n",
    "            tmp_height = svgs[df.loc[ind, col].split(\".svg\")[0]].height\n",
    "            if tmp_height > curr_row_max:\n",
    "                curr_row_max = tmp_height\n",
    "        row_max_heights.append(curr_row_max)\n",
    "    \n",
    "    change_positions(df, svgs, col_max_widths, row_max_heights)\n",
    "    \n",
    "    full_width = sum(col_max_widths) #[svgs[i].width for i in ['A', 'E']])\n",
    "    full_height = sum(row_max_heights) #[svgs[i].height for i in ['A', 'B', 'C', 'D']])\n",
    "    fig = sg.SVGFigure(full_width+20, full_height+20)\n",
    "    text = letter_annotations(svgs, df=df, figure_names=figure_names)\n",
    "    fig.append([s.data for s in svgs.values()])\n",
    "    fig.append(text)\n",
    "    fig.save(out_f)\n",
    " \n",
    "    cmd = f'inkscape --file={out_f} -d 300 --export-area-drawing --without-gui --export-png={out_f.replace(\".svg\", \".png\")}' # --export-area-drawing --without-gui --export-pdf=output.pdf'\n",
    "    print(cmd)\n",
    "    !{cmd}\n",
    "    \n",
    "    if to_pdf:\n",
    "        cmd = f'inkscape --file={out_f} --export-area-drawing --without-gui --export-pdf={out_f.replace(\"svg\", \"pdf\")} '\n",
    "        print(cmd)\n",
    "        !{cmd}\n",
    "    \n",
    "    \n",
    "\n",
    "def main_df_transpose(df, out_f, scale=0.25, figure_names=None, to_pdf=False, to_transpose=True):\n",
    "    svgs = files_to_svg_dict(df, scale=scale)#df.values().flatten())\n",
    "    \n",
    "    df = df.transpose()\n",
    "    for don, val in df.iterrows():\n",
    "        curr_init_files = []\n",
    "        curr_ref = val.iloc[0].split('.svg')[0] #svgs[val.iloc[0].split('.svg')[0]]\n",
    "        curr_keys = [x.split('.svg')[0] for x in val.values] \n",
    "        rescale_width(svgs, curr_keys, curr_ref)\n",
    "    \n",
    "    col_max_widths = []\n",
    "    for col in df.columns:\n",
    "        curr_col_max = 0\n",
    "        for ind in df.index:\n",
    "            tmp_width = svgs[df.loc[ind, col].split(\".svg\")[0]].width\n",
    "            if tmp_width > curr_col_max:\n",
    "                curr_col_max = tmp_width\n",
    "        col_max_widths.append(curr_col_max)\n",
    "\n",
    "    row_max_heights = [] #should be the same in theory  \n",
    "    for ind in df.index:\n",
    "        curr_row_max = 0\n",
    "        for col in df.columns:\n",
    "            tmp_height = svgs[df.loc[ind, col].split(\".svg\")[0]].height\n",
    "            if tmp_height > curr_row_max:\n",
    "                curr_row_max = tmp_height\n",
    "        row_max_heights.append(curr_row_max)\n",
    "    \n",
    "    change_positions(df, svgs, col_max_widths, row_max_heights)\n",
    "    \n",
    "    full_width = sum(col_max_widths) #[svgs[i].width for i in ['A', 'E']])\n",
    "    full_height = sum(row_max_heights) #[svgs[i].height for i in ['A', 'B', 'C', 'D']])\n",
    "    fig = sg.SVGFigure(full_width+20, full_height+20)\n",
    "    text = letter_annotations(svgs, df=df, figure_names=figure_names, transposed=True)\n",
    "    fig.append([s.data for s in svgs.values()])\n",
    "    fig.append(text)\n",
    "    fig.save(out_f)\n",
    " \n",
    "    cmd = f'inkscape --file={out_f} -d 300 --export-area-drawing --without-gui --export-png={out_f.replace(\".svg\", \".png\")}' # --export-area-drawing --without-gui --export-pdf=output.pdf'\n",
    "    print(cmd)\n",
    "    !{cmd}\n",
    "    \n",
    "    if to_pdf:\n",
    "        cmd = f'inkscape --file={out_f} --export-area-drawing --without-gui --export-pdf={out_f.replace(\"svg\", \"pdf\")} '\n",
    "        print(cmd)\n",
    "        !{cmd}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9728f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"single_clones/donor0/cloneMethod_variants_init_knn_resolution_30/clonalShift_method_clones/top/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499e5ef6",
   "metadata": {},
   "source": [
    "# 4. Variants concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995c870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vaf_figure_names =  {\n",
    "#     \"all_variants_af.svg\":\"vaf\",\n",
    "#     \"all_variants_distinct_pct_vs_other.svg\": \"barcode pct in clone\"\n",
    "# }\n",
    "vaf_figure_names =  {\n",
    "    \"all_variants_af.svg\":\"vaf\",\n",
    "    \"all_variants_distinct_pct_vs_other.svg\": \"barcode pct in clone\"\n",
    "}\n",
    "\n",
    "# fvars_pct = join(outdir, \"top_variants_distinct_pct_vs_other.svg\")\n",
    "# fvars_pct_minus = join(outdir, \"top_variants_pct_minus_other.svg\")\n",
    "# fvars_vars_af = join(outdir, \"top_variants_af.svg\")\n",
    "# fvars_vars_af_box = join(outdir, \"top_variants_in_clone_af_boxen.svg\") \n",
    "\n",
    "\n",
    "vaf_subfig_df = pd.DataFrame(index=list(vaf_dirs.keys()),columns = list(vaf_figure_names.keys()))\n",
    "\n",
    "for run in vaf_dirs:\n",
    "    curr_dir = vaf_dirs[run]\n",
    "    for f_name in vaf_subfig_df.columns:\n",
    "        #print('curr_f', curr_f)\n",
    "        curr_f = join(curr_dir, f_name)\n",
    "        vaf_subfig_df.loc[run, f_name] = curr_f\n",
    "        assert(exists(curr_f))\n",
    "vaf_subfig_df   \n",
    "\n",
    "if overwrite or not exists(join(outdir, \"vaf.svg\")):\n",
    "    main_df_transpose(vaf_subfig_df, join(outdir, \"vaf.svg\"), \n",
    "            scale=0.25, figure_names=vaf_figure_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d382216f",
   "metadata": {},
   "source": [
    "# 1. clone_var supplementary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c4be21",
   "metadata": {},
   "source": [
    "## Convert from pdf to svg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ccf6853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for run in clone_var_dirs:\n",
    "#     for d in np.arange(n_donors[run]):\n",
    "#         curr_pdfs = glob(join(clone_var_dirs[run], f\"donor{d}\",  \"*.pdf\"))\n",
    "#         for in_f in curr_pdfs:\n",
    "#         #in_f = join(clone_var_dirs, \"best_params.pdf\")\n",
    "#             out_f = in_f.replace(\".pdf\", \".svg\")\n",
    "#             if not exists(out_f):\n",
    "#                 cmd = f\"inkscape -l {out_f} {in_f}\" \n",
    "#                 print(cmd)\n",
    "#                 !{cmd}\n",
    "#             else:\n",
    "#                 print(f\"{out_f} already here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec83d99",
   "metadata": {},
   "source": [
    "## Loop through and align svgs, with each donor in horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d87adaf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clonevar_figure_names = {\n",
    "    \"best_params.svg\": \"Final clone-barcode table\",\n",
    "    \"top10perc_param_group_clusters.svg\": \"Cluster top hyperparameters by multi-objectives\",\n",
    "    \"elbow_multi_obj_nclust.svg\": \"Elbow plot for determining number of objective clusters\",\n",
    "    \"multi_clusters_nclust.svg\": \"multi_obj_clusters\" ,\n",
    "    \"top_param_group_results.svg\": \"top_objective_scores\"\n",
    "    #\"top_param_groups_clone_vars.svg\": \"clone-barcode table of top hyperparameter clusters\",\n",
    "}\n",
    "\n",
    "#     \"multi_clusters_nclust.svg\": \"Cluster hyperparameter and take highest objective score cluster\",\n",
    "#     \"top_param_group_results.svg\": \"Hyperparameter cluster objective results\"\n",
    "# }\n",
    "\n",
    "# indexes = []\n",
    "# for run in clone_var_dirs:\n",
    "#     indexes.append(run)\n",
    "#     for d in np.arange(n_donors[run]):\n",
    "#         indexes.append(join(f\"{run}_donor{d}\"))\n",
    "        \n",
    "don_row_subfig_col_df = pd.DataFrame(index=list(clone_var_dirs.keys()),columns = list(clonevar_figure_names.keys()))\n",
    "for run in clone_var_dirs:\n",
    "    curr_dir = clone_var_dirs[run]\n",
    "    for f_name in don_row_subfig_col_df.columns:\n",
    "        curr_f = join(curr_dir, f_name)\n",
    "        don_row_subfig_col_df.loc[run, f_name] = curr_f\n",
    "\n",
    "don_row_subfig_col_df\n",
    "\n",
    "\n",
    "if overwrite or not exists(join(outdir, \"clone_var_supplementary.svg\")):\n",
    "    main_df(don_row_subfig_col_df, join(outdir, \"clone_var_supplementary.svg\"), \n",
    "            scale=0.25, figure_names=clonevar_figure_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b510fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f31482a",
   "metadata": {},
   "source": [
    "# 2. Dendrograms: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a8f4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dendro_figure_names =  {\"dendro.NoCondition.max2.AF.svg\": \"AF (max 0.2)\",\n",
    "             \"dendro.NoCondition.max5.AF.svg\": \"AF (max 0.5)\",\n",
    "             \"dendro.NoCondition.DP.svg\": \"Log2 reads per cell-MT position\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f29740f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dendro_don_subfig_df = pd.DataFrame(index=list(dendro_dirs.keys()),columns = [\"dendro.NoCondition.max2.AF.svg\",\n",
    "                                                             \"dendro.NoCondition.max5.AF.svg\",\n",
    "                                                             \"dendro.NoCondition.DP.svg\"]\n",
    "                                   )\n",
    "\n",
    "for run in dendro_dirs:\n",
    "    curr_dendro_prefix = dendro_dirs[run] # full path prefix,  not a directory, so concat dir and file \n",
    "    for f_name in dendro_don_subfig_df.columns:\n",
    "        curr_f = curr_dendro_prefix + f_name\n",
    "        dendro_don_subfig_df.loc[run, f_name] = curr_f\n",
    "        assert(exists(curr_f))\n",
    "        \n",
    "# for run in clone_var_donor_dirs:\n",
    "#     for d in np.arange(n_donors[run]):\n",
    "#         curr_ind = f\"{run}_donor{d}\"\n",
    "#         curr_dendro_prefix = join(clone_var_donor_dirs[run], \"barcodes/btwnClones_dendro\", f\"donor{d}.\")\n",
    "#         for f_name in dendro_don_subfig_df.columns:\n",
    "#             curr_f = curr_dendro_prefix + f_name\n",
    "#             dendro_don_subfig_df.loc[curr_ind, f_name] = curr_f\n",
    "#             assert(exists(curr_f))\n",
    "dendro_don_subfig_df   \n",
    "\n",
    "if overwrite or not exists(join(outdir, \"dendrogram_barcodes.svg\")):\n",
    "    main_df(dendro_don_subfig_df, join(outdir, \"dendrogram_barcodes.svg\"), \n",
    "            scale=0.25, figure_names=dendro_figure_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69268843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ec29b30",
   "metadata": {},
   "source": [
    "# 3. Clone count barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8023abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_count_figure_names =  {\n",
    "    \"normalized_counts.barplot_conditions.svg\": \"normalized clone counts\",\n",
    "    \"top20_minCell10_clone_counts.barplot_conditions.svg\": \"top 20 clones\",\n",
    "    \"clone_counts.conditionScatter.svg\": \"scatterplot of ncells across conditions\"\n",
    "}\n",
    "\n",
    "#    \"clone barplot\": \"clone_counts.barplot_conditions.svg\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15671847",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cl_count_subfig_df = pd.DataFrame(index=list(clcounts_dirs.keys()),\n",
    "                                  columns = list(cl_count_figure_names.keys()))\n",
    "\n",
    "for run in clcounts_dirs:\n",
    "    curr_dir = clcounts_dirs[run]\n",
    "    for f_name in cl_count_subfig_df.columns:\n",
    "        curr_f = join(curr_dir, f_name)\n",
    "        cl_count_subfig_df.loc[run, f_name] = curr_f\n",
    "        assert(exists(curr_f))\n",
    "cl_count_subfig_df   \n",
    "\n",
    "if overwrite or not exists(join(outdir, \"clone_counts.svg\")):\n",
    "    main_df(cl_count_subfig_df, join(outdir, \"clone_counts.svg\"), \n",
    "            scale=0.5, figure_names=cl_count_figure_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aaf465",
   "metadata": {},
   "source": [
    "## 5. Representative clones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c2b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # repr_figure_names =  {\n",
    "# #     \"all_variants_af.svg\":\"vaf\",\n",
    "# #     \"all_variants_distinct_pct_vs_other.svg\": \"barcode pct in clone\"\n",
    "# # }\n",
    "\n",
    "\n",
    "# vaf_subfig_df = pd.DataFrame(index=list(vaf_dirs.keys()),columns = list(vaf_figure_names.keys()))\n",
    "\n",
    "# for run in vaf_dirs:\n",
    "#     curr_dir = vaf_dirs[run]\n",
    "#     for f_name in vaf_subfig_df.columns:\n",
    "#         print('curr_f', curr_f)\n",
    "#         curr_f = join(curr_dir, f_name)\n",
    "#         vaf_subfig_df.loc[run, f_name] = curr_f\n",
    "#         assert(exists(curr_f))\n",
    "# vaf_subfig_df   \n",
    "\n",
    "# if overwrite or not exists(join(outdir, \"vaf.svg\"))\n",
    "#     main_df_transpose(vaf_subfig_df, join(outdir, \"vaf.svg\"), \n",
    "#             scale=0.25, figure_names=vaf_figure_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1293f6",
   "metadata": {},
   "source": [
    "## Create Figure 2\n",
    "(Need select variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb229be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f82f75fc",
   "metadata": {},
   "source": [
    "## Create hyperparam clone-var supplementary"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
