{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding specific variants in each cluster\n",
    "Using the clones, we want to find variants in each clone that are specific to them.\n",
    "To define specificity, we will use two parameters: VAF frequency cutoff, and different %of population to have that variant.\n",
    "These parameters will be used to compare each clone's variants to the population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T20:12:12.105680Z",
     "start_time": "2021-05-13T20:12:12.099105Z"
    },
    "scrolled": false,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    indir = snakemake.params.indir\n",
    "    outdir = snakemake.params.outdir\n",
    "    donor =  snakemake.params.donor\n",
    "    # Objective weights. order of the columns\n",
    "    weights =  snakemake.params.weights\n",
    "    objectives_l = snakemake.params.get(objectives_l, \n",
    "                                        [\"variants_with_clone_norm_by_1_over_nclones_with_variant\", \n",
    "                                         \"max_clone_ncells_over_nclones\", \"max_clone_ncells_over_ncells\", \n",
    "                                         \"pct_thresh\",\"other_pct_thresh\", \n",
    "                                         \"n_vars\", \"obj_nclones_more_than_one_unique\"])\n",
    "    ncpus = snakemake.params.get(ncpus, 8)\n",
    "    topn = snakemake.params.get(topn, 16)\n",
    "except:                                       \n",
    "    indir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clones/variants_init/knn/kparam_30/\"\n",
    "    outdir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clones/variants_init/knn/kparam_30/distinct_variants/donor0/scrap/\"\n",
    "    donor = 0\n",
    "    # pct_thresh = [0.01, 0.1, 0.25, 0.4, 0.5, 0.75, 0.95]\n",
    "    # other_pct_thresh = [0.01, 0.1, 0.25, 0.5]\n",
    "    # af_thresh = [0, 0.01, 0.1, 0.25, 0.4]\n",
    "\n",
    "    # Objective weights. order of the columns\n",
    "    weights = [1,0,0,1,-1, 1, 1] #[1,1,1,1,1] #np.ones([len(objectives),])\n",
    "    objectives_l = [\"variants_with_clone_norm_by_1_over_nclones_with_variant\", \n",
    "                    \"max_clone_ncells_over_nclones\", \"max_clone_ncells_over_ncells\", \n",
    "                    \"pct_thresh\",\"other_pct_thresh\", \"n_vars\", \"obj_nclones_more_than_one_unique\"] #\"nvars\"\n",
    "    ncpus=8\n",
    "    topn=16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T20:12:13.155526Z",
     "start_time": "2021-05-13T20:12:12.130665Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fig_utils from mplh\n",
      "0.5.6\n"
     ]
    }
   ],
   "source": [
    "from os.path import join, exists, dirname\n",
    "from glob import glob\n",
    "import pickle\n",
    "import mplh.cluster_help as ch\n",
    "import mplh.fig_utils as fu\n",
    "\n",
    "import os\n",
    "import vireoSNP\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.io import mmread\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import hypergeom\n",
    "print(vireoSNP.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mplh import cluster_help as ch\n",
    "from vireoSNP import Vireo\n",
    "np.set_printoptions(formatter={'float': lambda x: format(x, '.3f')})\n",
    "\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives = {ind:x for ind,x in enumerate(objectives_l)}\n",
    "weights = np.array(weights)\n",
    "\n",
    "assert(len(weights)==len(objectives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'variants_with_clone_norm_by_1_over_nclones_with_variant',\n",
       " 1: 'max_clone_ncells_over_nclones',\n",
       " 2: 'max_clone_ncells_over_ncells',\n",
       " 3: 'pct_thresh',\n",
       " 4: 'other_pct_thresh',\n",
       " 5: 'n_vars',\n",
       " 6: 'obj_nclones_more_than_one_unique'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [\"pct_thresh\",\"af_thresh\", \"other_pct_thresh\"]\n",
    "n_params = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from deap import base, algorithms\n",
    "from deap import creator\n",
    "from deap import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists(outdir):\n",
    "    os.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & preprocess:\n",
    "- AF df\n",
    "- DP df\n",
    "- cells_meta with clone labels. need to create name as donor_lineage\n",
    "\n",
    "Remove donor variants (>0.9 in 90% of pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 9023)\n",
      "(68, 9023)\n",
      "Depth\n",
      "         AAACGAAAGAATCAAC-1_Control  AAACGAAAGCGAGAAA-1_Control  \\\n",
      "Variant                                                           \n",
      "10397G                          2.0                        16.0   \n",
      "10463C                         11.0                        16.0   \n",
      "10559G                         15.0                        26.0   \n",
      "10589A                         17.0                        21.0   \n",
      "11251G                         13.0                        25.0   \n",
      "\n",
      "         AAACGAAAGTACAGAT-1_Control  AAACGAAAGTTAGCAA-1_Control  \\\n",
      "Variant                                                           \n",
      "10397G                          1.0                         5.0   \n",
      "10463C                          3.0                         9.0   \n",
      "10559G                          5.0                         5.0   \n",
      "10589A                          6.0                         7.0   \n",
      "11251G                          5.0                         7.0   \n",
      "\n",
      "         AAACGAACACTCGCAG-1_Control  AAACGAATCAGGCGCT-1_Control  \\\n",
      "Variant                                                           \n",
      "10397G                         14.0                        58.0   \n",
      "10463C                          6.0                        48.0   \n",
      "10559G                         10.0                        66.0   \n",
      "10589A                          9.0                        67.0   \n",
      "11251G                         12.0                        91.0   \n",
      "\n",
      "         AAACGAATCCATCGAA-1_Control  AAACGAATCTCGTAGA-1_Control  \\\n",
      "Variant                                                           \n",
      "10397G                         39.0                        12.0   \n",
      "10463C                         30.0                         3.0   \n",
      "10559G                         16.0                         5.0   \n",
      "10589A                         24.0                        12.0   \n",
      "11251G                         37.0                        16.0   \n",
      "\n",
      "         AAACTCGAGTGAAGGA-1_Control  AAACTCGCATGCACTA-1_Control  ...  \\\n",
      "Variant                                                          ...   \n",
      "10397G                         15.0                        59.0  ...   \n",
      "10463C                          8.0                        39.0  ...   \n",
      "10559G                         21.0                        59.0  ...   \n",
      "10589A                         18.0                        48.0  ...   \n",
      "11251G                         26.0                        75.0  ...   \n",
      "\n",
      "         TTTGGTTTCTGATCCC-1_Input  TTTGTGTAGTTCGTTG-1_Input  \\\n",
      "Variant                                                       \n",
      "10397G                       99.0                      92.0   \n",
      "10463C                       78.0                      99.0   \n",
      "10559G                       86.0                      80.0   \n",
      "10589A                       88.0                      66.0   \n",
      "11251G                       78.0                      83.0   \n",
      "\n",
      "         TTTGTGTCACACATTG-1_Input  TTTGTGTGTAAGCCGA-1_Input  \\\n",
      "Variant                                                       \n",
      "10397G                      116.0                      39.0   \n",
      "10463C                      156.0                      22.0   \n",
      "10559G                      138.0                      32.0   \n",
      "10589A                      135.0                      34.0   \n",
      "11251G                      133.0                      45.0   \n",
      "\n",
      "         TTTGTGTGTAGATTAG-1_Input  TTTGTGTGTAGGGTCA-1_Input  \\\n",
      "Variant                                                       \n",
      "10397G                       38.0                      69.0   \n",
      "10463C                       14.0                      77.0   \n",
      "10559G                       13.0                      60.0   \n",
      "10589A                       19.0                      59.0   \n",
      "11251G                       30.0                      81.0   \n",
      "\n",
      "         TTTGTGTGTTTCTTAC-1_Input  TTTGTGTTCCTGAAAC-1_Input  \\\n",
      "Variant                                                       \n",
      "10397G                       72.0                      93.0   \n",
      "10463C                       58.0                      89.0   \n",
      "10559G                       48.0                      77.0   \n",
      "10589A                       55.0                      99.0   \n",
      "11251G                       90.0                     139.0   \n",
      "\n",
      "         TTTGTGTTCGGGAAAC-1_Input  TTTGTGTTCTGGCACG-1_Input  \n",
      "Variant                                                      \n",
      "10397G                       71.0                      67.0  \n",
      "10463C                       49.0                      91.0  \n",
      "10559G                       64.0                      87.0  \n",
      "10589A                       71.0                      80.0  \n",
      "11251G                       80.0                      86.0  \n",
      "\n",
      "[5 rows x 9023 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['10397G', '10589A', '11761T', '13188T', '1438G', '146C', '14766T',\n",
       "       '15326G', '16126C', '16355T', '16362C', '196C', '204C', '2442C', '263G',\n",
       "       '2706G', '3847C', '4769G', '58C', '64T', '7028T', '73G', '750G',\n",
       "       '7598A', '827G', '8292A', '8461T', '8860G'],\n",
       "      dtype='object', name='Variant')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af_indir = join(indir, \"sc_af\", f\"donor{donor}\")\n",
    "\n",
    "AF_df = pd.read_csv(join(af_indir, \"af.tsv\"), index_col=0, sep=\"\\t\")\n",
    "DP_df = pd.read_csv(join(af_indir, \"dp.tsv\"), index_col=0, sep=\"\\t\")\n",
    "\n",
    "print(AF_df.shape)\n",
    "print(DP_df.shape)\n",
    "print(\"Depth\")\n",
    "print(DP_df.head())\n",
    "AF_df.head()\n",
    "\n",
    "cells_meta = pd.read_csv(join(indir, \"cells_meta.tsv\"), sep='\\t', index_col=\"ID\")#.sort_values([\"donor\", \"lineage\"])\n",
    "cells_meta[\"name\"] = cells_meta[\"donor\"].astype(str)+\"_\"+cells_meta[\"lineage\"].astype(str)\n",
    "# if \"donor_index\" in cells_meta.columns and \"lineage_index\" in cells_meta.columns:\n",
    "#     cells_meta = cells_meta.sort_values([\"donor_index\", \"lineage_index\"])\n",
    "#AD_df = pd.merge(AD_df, vcf[[\"#CHROM\", \"POS\", \"ALT\"]], how=\"inner\", left_index=True,right_index=True).set_index([\"#CHROM\", \"POS\", \"ALT\"])\n",
    "curr_labels = cells_meta[cells_meta[\"donor\"]==donor]\n",
    "curr_labels\n",
    "\n",
    "conditions = curr_labels[\"condition\"].unique()\n",
    "conditions\n",
    "\n",
    "def rm_high(df, thresh, pct_thresh):\n",
    "    return df.loc[~(((df>thresh).sum(axis=1)>pct_thresh*df.shape[0]))]\n",
    "\n",
    "def rm_low(df, thresh, pct_thresh):\n",
    "    return df.loc[~((df<thresh).sum(axis=1)>(pct_thresh*df.shape[1]))]\n",
    "\n",
    "    #return df.loc[~(((df<=thresh).sum(axis=1)>pct_thresh*df.shape[0]))]\n",
    "#df[(df<0.01).sum(axis=1)]\n",
    "\n",
    "## Get donor inds\n",
    "\n",
    "donor_inds = AF_df.index[((AF_df>0.9).sum(axis=1)>(0.9*AF_df.shape[1]))]\n",
    "donor_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all cells in each clone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## objective: \n",
    "1. Maximize: /sum_{v \\in V}{max({c_{ncells}\\in C}/|C|), where V is number of variants, c_{i,v,ncells} is number of cells in clone i with variant v, and C is the set of clones with the variant. We want to maximize this objective. Across all variants.\n",
    "2. Same as 1, but denominator is not number of clones with variant but number of cells with variant\n",
    "3. Maximize pct_thresh\n",
    "4. Minimize other_pct_thresh (not high priority)\n",
    "\n",
    "## Constraint:\n",
    "1. pct_thresh>=other_pct_thresh\n",
    "2. af_thresh*coverage_thresh>=2\n",
    "\n",
    "## Bounds:\n",
    "1. pct_thresh: 0.1-1\n",
    "2. other_pct_thresh: 0.1-1\n",
    "3. af_thresh: 0.01-0.4\n",
    "4. coverage_thresh: 2-60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "\n",
    "ic.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_variants(cln_af, other_af, pct_thresh, af_thresh, other_pct_thresh):\n",
    "    \"\"\" gets the distinct variants in a clone.\n",
    "    \"\"\"\n",
    "    n_thresh = pct_thresh*cln_af.shape[1]\n",
    "    n_oth_thresh = other_pct_thresh*other_af.shape[1]\n",
    "    bin_cln = cln_af>af_thresh\n",
    "    bin_other = other_af>af_thresh\n",
    "    cells_above = bin_cln.sum(axis=1)\n",
    "    pct_cells_above = cells_above/bin_cln.shape[1]\n",
    "    up_vars = bin_cln.loc[cells_above > n_thresh].index\n",
    "    cells_other_above = bin_other.sum(axis=1)\n",
    "    pct_cells_other_above = cells_other_above/bin_other.shape[1]\n",
    "    up_oth_vars = bin_other.loc[cells_other_above > n_oth_thresh].index\n",
    "    uniq_vars = list(set(up_vars) - set(up_oth_vars))\n",
    "    out = pd.DataFrame(index=uniq_vars, data={\"n_cells\":cells_above.loc[uniq_vars].values, \n",
    "                                              \"n_other_cells\": cells_other_above.loc[uniq_vars].values,\n",
    "                                              \"pct_above\": pct_cells_above,\n",
    "                                              \"pct_other_above\": pct_cells_other_above})\n",
    "    out[\"pct_thresh\"] = pct_thresh\n",
    "    out[\"af_thresh\"] = af_thresh\n",
    "    out[\"other_pct_thresh\"] = other_pct_thresh\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_clones_unique_variants(solution, data):\n",
    "    all_unique_df = []\n",
    "    pct_thresh, af_thresh, other_pct_thresh = solution[\"pct_thresh\"], solution[\"af_thresh\"], solution[\"other_pct_thresh\"] #solution[0], solution[1], solution[2]\n",
    "    curr_labels = data[\"curr_labels\"]\n",
    "    AF_df = data[\"AF_df\"]\n",
    "    DP_df = data[\"DP_df\"]\n",
    "    for cln, val in curr_labels.groupby(\"name\"):\n",
    "        ic(cln)\n",
    "        cln_af = AF_df.loc[:, val.index]\n",
    "        other_af = AF_df.loc[:, curr_labels.drop(val.index).index]\n",
    "        curr_dp = DP_df.loc[:, val.index]\n",
    "        curr_labs = curr_labels[curr_labels.index.isin(cln_af.columns)]\n",
    "        ic(cln_af.shape)\n",
    "        unique_df = get_unique_variants(cln_af, other_af, pct_thresh, af_thresh, other_pct_thresh)\n",
    "        unique_df[\"clone\"] = cln\n",
    "        unique_df[\"id\"] = unique_df[\"clone\"] + \"_\" + unique_df[\"pct_thresh\"].astype(str)+ \"_\" + unique_df[\"af_thresh\"].astype(str)+ \"_\" + unique_df[\"other_pct_thresh\"].astype(str)\n",
    "        unique_df[\"variant\"] = unique_df.index\n",
    "        unique_df = unique_df.set_index(\"id\")\n",
    "        all_unique_df.append(unique_df)\n",
    "    all_unique_df = pd.concat(all_unique_df)\n",
    "    all_unique_df[\"log2_n_cells\"] = np.log2(all_unique_df[\"n_cells\"]+1)\n",
    "    return all_unique_df\n",
    "\n",
    "\n",
    "\n",
    "def _objective_two_unique_vars_in_clone(all_unique_df, to_pivot=True):\n",
    "    if to_pivot:\n",
    "        if \"id\" in all_unique_df.columns:\n",
    "            df = all_unique_df.pivot(index=\"id\", columns=\"variant\", values=\"n_cells\").fillna(0).astype(int)\n",
    "        else:\n",
    "            df = all_unique_df.reset_index().pivot(index=\"id\", columns=\"variant\", values=\"n_cells\").fillna(0).astype(int)\n",
    "    else:\n",
    "        df = all_unique_df\n",
    "    vars_to_keep = df.loc[:,(df>0).sum()==1].columns # Variants with just 1 clone\n",
    "    clones_to_keep = df.loc[df.sum(axis=1)>1].index # Clones w >2 enriched variants\n",
    "    obj = 0\n",
    "    def cl_more_than_one(cl_ser):  \n",
    "        curr = cl_ser[cl_ser > 0] # variants in a clone\n",
    "        # check if more than one unique variant for this clone\n",
    "        return sum([True if x in vars_to_keep else False for x in curr.index]) > 1\n",
    "\n",
    "#     def cl_more_than_one(cl_ser, vars_to_keep):  \n",
    "#         curr = cl_ser[cl_ser > 0] # variants in a clone\n",
    "#         # check if more than one unique variant for this clone\n",
    "#         return sum([True if x in vars_to_keep else False for x in curr.index]) > 1\n",
    "    #obj = sum(df.loc[clones_to_keep].apply(lambda x: x(lambda y):, axis=0))\n",
    "    obj = sum(df.loc[clones_to_keep].apply(cl_more_than_one, axis=1))\n",
    "    return obj\n",
    "\n",
    "\n",
    "def _objectives(data):\n",
    "    all_unique_df = data[\"all_unique_df\"]\n",
    "    #print('all_unique_df', all_unique_df.head)\n",
    "    ic('all_unique_df', all_unique_df.shape)\n",
    "    obj_max_nce_over_ncl = 0\n",
    "    obj_max_nce_over_nce = 0\n",
    "    obj_cl_over_ncl = 0\n",
    "    obj_nvars = 0\n",
    "    if len(all_unique_df) == 0:\n",
    "        #print('all 0', all_unique_df.columns)\n",
    "        return {x:(-1*np.inf) for x in objectives_l} # return score of 0 since all positive values\n",
    "    obj_d = all_unique_df.iloc[0][\"pct_thresh\"] \n",
    "    obj_e = all_unique_df.iloc[0][\"other_pct_thresh\"]\n",
    "    for v, v_df in all_unique_df.groupby(\"variant\"):\n",
    "        ic(v)\n",
    "        max_ncells = max(v_df[\"n_cells\"])\n",
    "        n_clones = len(set(v_df[\"clone\"].values))\n",
    "        obj_max_nce_over_ncl += max_ncells/n_clones\n",
    "        obj_max_nce_over_nce += max_ncells/v_df[\"n_cells\"].sum()\n",
    "        \n",
    "        if n_clones != 0:\n",
    "            obj_cl_over_ncl += 1/n_clones\n",
    "            obj_nvars += 1\n",
    "        \n",
    "    # calculate objective number of clones with more than one unique variant\n",
    "    obj_nclones_more_than_one_unique =  _objective_two_unique_vars_in_clone(all_unique_df, to_pivot=True)\n",
    "    \n",
    "    objectives = {\"variants_with_clone_norm_by_1_over_nclones_with_variant\":obj_cl_over_ncl,\n",
    "                  \"max_clone_ncells_over_nclones\":obj_max_nce_over_ncl, \n",
    "                  \"max_clone_ncells_over_ncells\":obj_max_nce_over_nce, \n",
    "                  \"pct_thresh\":obj_d,\"other_pct_thresh\":obj_e,\n",
    "                   \"n_vars\":obj_nvars, \"obj_nclones_more_than_one_unique\": obj_nclones_more_than_one_unique}\n",
    "    return objectives\n",
    "\n",
    "def _constraints(solution):\n",
    "    #if solution[\"pct_thresh\"] < solution[\"other_pct_thresh\"]:\n",
    "    if \"coverage_thresh\" not in solution:\n",
    "        return None\n",
    "    if solution[\"af_thresh\"]*solution[\"coverage_thresh\"] >= 2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def evaluate_series(individual_ser, AF_df, DP_df, curr_labels, return_data=False):\n",
    "    params = individual_ser.to_dict()\n",
    "    #print('params', params)\n",
    "    #solution = {\"pct_thresh\": individual[0], \"af_thresh\":individual[1],  \"other_pct_thresh\": individual[2]}\n",
    "    data = {\"AF_df\": AF_df, \"DP_df\":DP_df, \"curr_labels\":curr_labels} \n",
    "    all_unique_df = get_clones_unique_variants(params, data)\n",
    "    data[\"all_unique_df\"] = all_unique_df\n",
    "    eval_out = _objectives(data)\n",
    "    if return_data:\n",
    "        return pd.Series(eval_out), data\n",
    "    else:\n",
    "        return pd.Series(eval_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GA or gridsearch on parameters and evaluate objectives \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# parallel setup\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=ncpus, progress_bar=True)\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7600, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_thresh</th>\n",
       "      <th>other_pct_thresh</th>\n",
       "      <th>af_thresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pct_thresh  other_pct_thresh  af_thresh\n",
       "0        0.05             0.005      0.005\n",
       "1        0.05             0.005      0.055\n",
       "2        0.05             0.005      0.105\n",
       "3        0.05             0.005      0.155\n",
       "4        0.05             0.005      0.205"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_thresh = np.arange(0.05, 1, 0.05)\n",
    "other_pct_thresh = np.arange(0.005, 1, 0.05)\n",
    "af_thresh = np.arange(0.005, 1, 0.05)\n",
    "\n",
    "\n",
    "# There are 7 params to use for calling the clone\n",
    "params = {\"pct_thresh\": pct_thresh,\n",
    "          \"other_pct_thresh\": other_pct_thresh,\n",
    "          \"af_thresh\": af_thresh,}\n",
    "full_params = list(product(*list(params.values())))\n",
    "full_params = pd.DataFrame(full_params, columns=params.keys())\n",
    "\n",
    "print(full_params.shape)\n",
    "full_params.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5288389b5c8c4934bcb786d9494a4bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=950), Label(value='0 / 950'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = full_params.parallel_apply(evaluate_series, args=(AF_df, DP_df, curr_labels), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the 0 scores before weighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(results_df>0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_inds = results_df.loc[(results_df==0).all(axis=1)].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_multi_rank(results, weights):\n",
    "    if \"multi\" in results.columns: #in case multi was added before\n",
    "        rank_results = results.drop(\"multi\",axis=1).rank(na_option='top')\n",
    "    else:\n",
    "        rank_results = results.rank(na_option='top')\n",
    "    rank_results[\"multi\"] = (weights*rank_results).sum(axis=1)\n",
    "    return rank_results.sort_values(by=\"multi\")[::-1]\n",
    "\n",
    "def set_multi(results, weights):\n",
    "    print(results.shape)\n",
    "    # first normalize results for each column to sum to 1\n",
    "    objs_total = results.replace([-np.inf, np.inf], np.nan).sum(axis=0)\n",
    "    print('objs_total', objs_total.head())\n",
    "    results_norm = results.apply(lambda x: x/objs_total.loc[x.name], axis=0)\n",
    "    \n",
    "    results_norm[\"multi\"] = (weights*results_norm).sum(axis=1)\n",
    "    return results_norm.sort_values(by=\"multi\")[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df.replace([-np.inf, np.inf], np.nan).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_norm = set_multi(results_df, weights)\n",
    "\n",
    "rank_df = set_multi_rank(results_norm, weights)\n",
    "rank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df.replace([-np.inf], np.nan).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop the na ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_results = results_norm.loc[results_norm[\"multi\"].isnull()]\n",
    "results_norm = results_norm.loc[~(results_norm[\"multi\"].isnull())]\n",
    "results_norm\n",
    "#results_norm.loc[results_norm[\"multi\"] == np.nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.displot(results_norm[\"multi\"])\n",
    "plt.title(\"multiobjective function (want to maximize)\")\n",
    "plt.savefig(join(outdir, \"loss_multi.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.displot(rank_df[\"multi\"])\n",
    "#plt.title(\"multiobjective function rankings (ties are averaged, want to maximize)\")\n",
    "#plt.savefig(join(outdir, \"multi_loss.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.displot(rank_df[\"variants_with_clone_norm_by_1_over_nclones_with_variant\"])\n",
    "plt.title(\"objective: variants_with_clone_norm_by_1_over_nclones_with_variant (want to maximize)\")\n",
    "plt.savefig(join(outdir, \"loss_variants_with_clone_norm_by_1_over_nclones_with_variant.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.displot(rank_df[\"obj_nclones_more_than_one_unique\"])\n",
    "plt.title(\"objective: Number of clones with at least 2 unique variants (want to maximize)\")\n",
    "plt.savefig(join(outdir, \"loss_variants_with_clone_norm_by_1_over_nclones_with_variant.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_results(results_df, rank_df, n=12):\n",
    "    filt_rank = rank_df.sort_values(by=[\"multi\"])[::-1].iloc[:n]\n",
    "    filt_results = results_df.loc[filt_rank.index]\n",
    "    return filt_rank, filt_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filt_rank, filt_results = get_top_n_results(results_norm, rank_df, n=topn)\n",
    "\n",
    "filt_results.columns = [f\"{x}_obj\" for x in filt_results.columns]\n",
    "\n",
    "filt_results = pd.merge(filt_results, full_params, left_index=True, right_index=True, how=\"left\")\n",
    "filt_rank = filt_rank.loc[filt_results.index]\n",
    "filt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6061\n",
      "7380\n",
      "5681\n"
     ]
    }
   ],
   "source": [
    "all_df = []\n",
    "all_objs = {}\n",
    "for ind, val in filt_results.iterrows():\n",
    "    print(ind)\n",
    "    obj_out, data = evaluate_series(val, AF_df, DP_df, curr_labels, return_data=True)\n",
    "    all_df.append(data[\"all_unique_df\"])\n",
    "    all_objs[ind] = obj_out \n",
    "all_df = pd.concat(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df = all_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Either re-run results for top to get unique_df for each param, or store in a dict (harder b/c of the parallel apply). After, need to make all_df by concatenating the results.\n",
    "Plot A: heatmap FacetGrid, but each axis is a combination of the parameters (can I do col=[\"colA\", \"colC\"]?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0_0', '0_1', '0_15', '0_19', '0_2', '0_20', '0_21', '0_22', '0_23',\n",
       "       '0_24', '0_25', '0_27', '0_28', '0_29', '0_30', '0_31', '0_32', '0_33',\n",
       "       '0_5'],\n",
       "      dtype='object', name='clone')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmap_input = all_df[[\"n_cells\", \"variant\"]].reset_index().pivot(index=\"id\", columns=\"variant\", values=\"n_cells\").fillna(0).astype(int)\n",
    "meta_df = all_df[[\"af_thresh\", \"other_pct_thresh\", \"pct_thresh\", \"clone\"]]\n",
    "meta_df = meta_df.loc[~(meta_df.index.duplicated())]\n",
    "meta_df = meta_df.sort_values([\"af_thresh\",\"pct_thresh\", \"other_pct_thresh\", \"clone\"])\n",
    "heatmap_input = heatmap_input.loc[meta_df.index]\n",
    "\n",
    "# Get the variants based on total number of cells across parameters\n",
    "heatmap_input = heatmap_input.loc[:,heatmap_input.sum().sort_values()[::-1].index]\n",
    "variants_order = heatmap_input.columns\n",
    "\n",
    "# Get the clones based on total number of cells across parameters\n",
    "def clone_sum(val):\n",
    "    #print(val)\n",
    "    return(heatmap_input.loc[val.index].sum())\n",
    "\n",
    "clone_sums = meta_df.groupby(\"clone\").apply(clone_sum)\n",
    "clone_sums = clone_sums.loc[:, clone_sums.sum().sort_values()[::-1].index]\n",
    "clones_order = clone_sums.index\n",
    "clones_order\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create column with all parameter names  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_to_str(ser, param_names):\n",
    "    name = \"\"\n",
    "    for p in param_names:\n",
    "        name = name + f\"{p}={ser[p]:.3f}\\t\"\n",
    "    return name\n",
    "\n",
    "def params_and_multi_str(ser):\n",
    "    param_str = ser[\"params\"]\n",
    "    name = f\"params:\\n{param_str.strip()}\\nObjective score={ser['multi_obj']} (want to maximize)\" \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_cells</th>\n",
       "      <th>n_other_cells</th>\n",
       "      <th>pct_above</th>\n",
       "      <th>pct_other_above</th>\n",
       "      <th>pct_thresh</th>\n",
       "      <th>af_thresh</th>\n",
       "      <th>other_pct_thresh</th>\n",
       "      <th>clone</th>\n",
       "      <th>variant</th>\n",
       "      <th>log2_n_cells</th>\n",
       "      <th>params</th>\n",
       "      <th>multi_obj</th>\n",
       "      <th>params_multi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_15_0.9500000000000001_0.005_0.10500000000000001</th>\n",
       "      <td>232</td>\n",
       "      <td>710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080764</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0_15</td>\n",
       "      <td>3109C</td>\n",
       "      <td>7.864186</td>\n",
       "      <td>pct_thresh=0.950\\naf_thresh=0.005\\nother_pct_t...</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>params:\\npct_thresh=0.950\\naf_thresh=0.005\\not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_19_0.9500000000000001_0.005_0.10500000000000001</th>\n",
       "      <td>197</td>\n",
       "      <td>462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052345</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0_19</td>\n",
       "      <td>1949A</td>\n",
       "      <td>7.629357</td>\n",
       "      <td>pct_thresh=0.950\\naf_thresh=0.005\\nother_pct_t...</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>params:\\npct_thresh=0.950\\naf_thresh=0.005\\not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_20_0.9500000000000001_0.005_0.10500000000000001</th>\n",
       "      <td>177</td>\n",
       "      <td>498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.056297</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0_20</td>\n",
       "      <td>11251G</td>\n",
       "      <td>7.475733</td>\n",
       "      <td>pct_thresh=0.950\\naf_thresh=0.005\\nother_pct_t...</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>params:\\npct_thresh=0.950\\naf_thresh=0.005\\not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_21_0.9500000000000001_0.005_0.10500000000000001</th>\n",
       "      <td>163</td>\n",
       "      <td>573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064673</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0_21</td>\n",
       "      <td>1888A</td>\n",
       "      <td>7.357552</td>\n",
       "      <td>pct_thresh=0.950\\naf_thresh=0.005\\nother_pct_t...</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>params:\\npct_thresh=0.950\\naf_thresh=0.005\\not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_22_0.9500000000000001_0.005_0.10500000000000001</th>\n",
       "      <td>154</td>\n",
       "      <td>104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011726</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0_22</td>\n",
       "      <td>11453A</td>\n",
       "      <td>7.276124</td>\n",
       "      <td>pct_thresh=0.950\\naf_thresh=0.005\\nother_pct_t...</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>params:\\npct_thresh=0.950\\naf_thresh=0.005\\not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_25_0.7500000000000001_0.055_0.20500000000000002</th>\n",
       "      <td>99</td>\n",
       "      <td>285</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.032048</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0_25</td>\n",
       "      <td>14233G</td>\n",
       "      <td>6.643856</td>\n",
       "      <td>pct_thresh=0.750\\naf_thresh=0.055\\nother_pct_t...</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>params:\\npct_thresh=0.750\\naf_thresh=0.055\\not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_29_0.7500000000000001_0.055_0.20500000000000002</th>\n",
       "      <td>92</td>\n",
       "      <td>265</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.029745</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0_29</td>\n",
       "      <td>13368A</td>\n",
       "      <td>6.539159</td>\n",
       "      <td>pct_thresh=0.750\\naf_thresh=0.055\\nother_pct_t...</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>params:\\npct_thresh=0.750\\naf_thresh=0.055\\not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_30_0.7500000000000001_0.055_0.20500000000000002</th>\n",
       "      <td>82</td>\n",
       "      <td>342</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.038345</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0_30</td>\n",
       "      <td>4117C</td>\n",
       "      <td>6.375039</td>\n",
       "      <td>pct_thresh=0.750\\naf_thresh=0.055\\nother_pct_t...</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>params:\\npct_thresh=0.750\\naf_thresh=0.055\\not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_31_0.7500000000000001_0.055_0.20500000000000002</th>\n",
       "      <td>97</td>\n",
       "      <td>296</td>\n",
       "      <td>0.950980</td>\n",
       "      <td>0.033180</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0_31</td>\n",
       "      <td>1949A</td>\n",
       "      <td>6.614710</td>\n",
       "      <td>pct_thresh=0.750\\naf_thresh=0.055\\nother_pct_t...</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>params:\\npct_thresh=0.750\\naf_thresh=0.055\\not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_33_0.7500000000000001_0.055_0.20500000000000002</th>\n",
       "      <td>71</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0_33</td>\n",
       "      <td>152C</td>\n",
       "      <td>6.169925</td>\n",
       "      <td>pct_thresh=0.750\\naf_thresh=0.055\\nother_pct_t...</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>params:\\npct_thresh=0.750\\naf_thresh=0.055\\not...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   n_cells  n_other_cells  \\\n",
       "id                                                                          \n",
       "0_15_0.9500000000000001_0.005_0.10500000000000001      232            710   \n",
       "0_19_0.9500000000000001_0.005_0.10500000000000001      197            462   \n",
       "0_20_0.9500000000000001_0.005_0.10500000000000001      177            498   \n",
       "0_21_0.9500000000000001_0.005_0.10500000000000001      163            573   \n",
       "0_22_0.9500000000000001_0.005_0.10500000000000001      154            104   \n",
       "...                                                    ...            ...   \n",
       "0_25_0.7500000000000001_0.055_0.20500000000000002       99            285   \n",
       "0_29_0.7500000000000001_0.055_0.20500000000000002       92            265   \n",
       "0_30_0.7500000000000001_0.055_0.20500000000000002       82            342   \n",
       "0_31_0.7500000000000001_0.055_0.20500000000000002       97            296   \n",
       "0_33_0.7500000000000001_0.055_0.20500000000000002       71             25   \n",
       "\n",
       "                                                   pct_above  pct_other_above  \\\n",
       "id                                                                              \n",
       "0_15_0.9500000000000001_0.005_0.10500000000000001   1.000000         0.080764   \n",
       "0_19_0.9500000000000001_0.005_0.10500000000000001   1.000000         0.052345   \n",
       "0_20_0.9500000000000001_0.005_0.10500000000000001   1.000000         0.056297   \n",
       "0_21_0.9500000000000001_0.005_0.10500000000000001   1.000000         0.064673   \n",
       "0_22_0.9500000000000001_0.005_0.10500000000000001   1.000000         0.011726   \n",
       "...                                                      ...              ...   \n",
       "0_25_0.7500000000000001_0.055_0.20500000000000002   0.761538         0.032048   \n",
       "0_29_0.7500000000000001_0.055_0.20500000000000002   0.807018         0.029745   \n",
       "0_30_0.7500000000000001_0.055_0.20500000000000002   0.788462         0.038345   \n",
       "0_31_0.7500000000000001_0.055_0.20500000000000002   0.950980         0.033180   \n",
       "0_33_0.7500000000000001_0.055_0.20500000000000002   1.000000         0.002793   \n",
       "\n",
       "                                                   pct_thresh  af_thresh  \\\n",
       "id                                                                         \n",
       "0_15_0.9500000000000001_0.005_0.10500000000000001        0.95      0.005   \n",
       "0_19_0.9500000000000001_0.005_0.10500000000000001        0.95      0.005   \n",
       "0_20_0.9500000000000001_0.005_0.10500000000000001        0.95      0.005   \n",
       "0_21_0.9500000000000001_0.005_0.10500000000000001        0.95      0.005   \n",
       "0_22_0.9500000000000001_0.005_0.10500000000000001        0.95      0.005   \n",
       "...                                                       ...        ...   \n",
       "0_25_0.7500000000000001_0.055_0.20500000000000002        0.75      0.055   \n",
       "0_29_0.7500000000000001_0.055_0.20500000000000002        0.75      0.055   \n",
       "0_30_0.7500000000000001_0.055_0.20500000000000002        0.75      0.055   \n",
       "0_31_0.7500000000000001_0.055_0.20500000000000002        0.75      0.055   \n",
       "0_33_0.7500000000000001_0.055_0.20500000000000002        0.75      0.055   \n",
       "\n",
       "                                                   other_pct_thresh clone  \\\n",
       "id                                                                          \n",
       "0_15_0.9500000000000001_0.005_0.10500000000000001             0.105  0_15   \n",
       "0_19_0.9500000000000001_0.005_0.10500000000000001             0.105  0_19   \n",
       "0_20_0.9500000000000001_0.005_0.10500000000000001             0.105  0_20   \n",
       "0_21_0.9500000000000001_0.005_0.10500000000000001             0.105  0_21   \n",
       "0_22_0.9500000000000001_0.005_0.10500000000000001             0.105  0_22   \n",
       "...                                                             ...   ...   \n",
       "0_25_0.7500000000000001_0.055_0.20500000000000002             0.205  0_25   \n",
       "0_29_0.7500000000000001_0.055_0.20500000000000002             0.205  0_29   \n",
       "0_30_0.7500000000000001_0.055_0.20500000000000002             0.205  0_30   \n",
       "0_31_0.7500000000000001_0.055_0.20500000000000002             0.205  0_31   \n",
       "0_33_0.7500000000000001_0.055_0.20500000000000002             0.205  0_33   \n",
       "\n",
       "                                                  variant  log2_n_cells  \\\n",
       "id                                                                        \n",
       "0_15_0.9500000000000001_0.005_0.10500000000000001   3109C      7.864186   \n",
       "0_19_0.9500000000000001_0.005_0.10500000000000001   1949A      7.629357   \n",
       "0_20_0.9500000000000001_0.005_0.10500000000000001  11251G      7.475733   \n",
       "0_21_0.9500000000000001_0.005_0.10500000000000001   1888A      7.357552   \n",
       "0_22_0.9500000000000001_0.005_0.10500000000000001  11453A      7.276124   \n",
       "...                                                   ...           ...   \n",
       "0_25_0.7500000000000001_0.055_0.20500000000000002  14233G      6.643856   \n",
       "0_29_0.7500000000000001_0.055_0.20500000000000002  13368A      6.539159   \n",
       "0_30_0.7500000000000001_0.055_0.20500000000000002   4117C      6.375039   \n",
       "0_31_0.7500000000000001_0.055_0.20500000000000002   1949A      6.614710   \n",
       "0_33_0.7500000000000001_0.055_0.20500000000000002    152C      6.169925   \n",
       "\n",
       "                                                                                              params  \\\n",
       "id                                                                                                     \n",
       "0_15_0.9500000000000001_0.005_0.10500000000000001  pct_thresh=0.950\\naf_thresh=0.005\\nother_pct_t...   \n",
       "0_19_0.9500000000000001_0.005_0.10500000000000001  pct_thresh=0.950\\naf_thresh=0.005\\nother_pct_t...   \n",
       "0_20_0.9500000000000001_0.005_0.10500000000000001  pct_thresh=0.950\\naf_thresh=0.005\\nother_pct_t...   \n",
       "0_21_0.9500000000000001_0.005_0.10500000000000001  pct_thresh=0.950\\naf_thresh=0.005\\nother_pct_t...   \n",
       "0_22_0.9500000000000001_0.005_0.10500000000000001  pct_thresh=0.950\\naf_thresh=0.005\\nother_pct_t...   \n",
       "...                                                                                              ...   \n",
       "0_25_0.7500000000000001_0.055_0.20500000000000002  pct_thresh=0.750\\naf_thresh=0.055\\nother_pct_t...   \n",
       "0_29_0.7500000000000001_0.055_0.20500000000000002  pct_thresh=0.750\\naf_thresh=0.055\\nother_pct_t...   \n",
       "0_30_0.7500000000000001_0.055_0.20500000000000002  pct_thresh=0.750\\naf_thresh=0.055\\nother_pct_t...   \n",
       "0_31_0.7500000000000001_0.055_0.20500000000000002  pct_thresh=0.750\\naf_thresh=0.055\\nother_pct_t...   \n",
       "0_33_0.7500000000000001_0.055_0.20500000000000002  pct_thresh=0.750\\naf_thresh=0.055\\nother_pct_t...   \n",
       "\n",
       "                                                   multi_obj  \\\n",
       "id                                                             \n",
       "0_15_0.9500000000000001_0.005_0.10500000000000001   0.002432   \n",
       "0_19_0.9500000000000001_0.005_0.10500000000000001   0.002432   \n",
       "0_20_0.9500000000000001_0.005_0.10500000000000001   0.002432   \n",
       "0_21_0.9500000000000001_0.005_0.10500000000000001   0.002432   \n",
       "0_22_0.9500000000000001_0.005_0.10500000000000001   0.002432   \n",
       "...                                                      ...   \n",
       "0_25_0.7500000000000001_0.055_0.20500000000000002   0.002145   \n",
       "0_29_0.7500000000000001_0.055_0.20500000000000002   0.002145   \n",
       "0_30_0.7500000000000001_0.055_0.20500000000000002   0.002145   \n",
       "0_31_0.7500000000000001_0.055_0.20500000000000002   0.002145   \n",
       "0_33_0.7500000000000001_0.055_0.20500000000000002   0.002145   \n",
       "\n",
       "                                                                                        params_multi  \n",
       "id                                                                                                    \n",
       "0_15_0.9500000000000001_0.005_0.10500000000000001  params:\\npct_thresh=0.950\\naf_thresh=0.005\\not...  \n",
       "0_19_0.9500000000000001_0.005_0.10500000000000001  params:\\npct_thresh=0.950\\naf_thresh=0.005\\not...  \n",
       "0_20_0.9500000000000001_0.005_0.10500000000000001  params:\\npct_thresh=0.950\\naf_thresh=0.005\\not...  \n",
       "0_21_0.9500000000000001_0.005_0.10500000000000001  params:\\npct_thresh=0.950\\naf_thresh=0.005\\not...  \n",
       "0_22_0.9500000000000001_0.005_0.10500000000000001  params:\\npct_thresh=0.950\\naf_thresh=0.005\\not...  \n",
       "...                                                                                              ...  \n",
       "0_25_0.7500000000000001_0.055_0.20500000000000002  params:\\npct_thresh=0.750\\naf_thresh=0.055\\not...  \n",
       "0_29_0.7500000000000001_0.055_0.20500000000000002  params:\\npct_thresh=0.750\\naf_thresh=0.055\\not...  \n",
       "0_30_0.7500000000000001_0.055_0.20500000000000002  params:\\npct_thresh=0.750\\naf_thresh=0.055\\not...  \n",
       "0_31_0.7500000000000001_0.055_0.20500000000000002  params:\\npct_thresh=0.750\\naf_thresh=0.055\\not...  \n",
       "0_33_0.7500000000000001_0.055_0.20500000000000002  params:\\npct_thresh=0.750\\naf_thresh=0.055\\not...  \n",
       "\n",
       "[212 rows x 13 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df[\"params\"] = all_df.apply(params_to_str, axis=1, args=(param_names,))\n",
    "all_df.head()\n",
    "\n",
    "filt_results[\"params\"] = filt_results.apply(params_to_str, axis=1, args=(param_names,))\n",
    "filt_results\n",
    "\n",
    "\n",
    "filt_results[\"params_multi\"] = filt_results.apply(params_and_multi_str, axis=1)\n",
    "filt_results\n",
    "tmp = filt_results.set_index(\"params\")\n",
    "all_df[\"multi_obj\"] = all_df.apply(lambda x: tmp.loc[x[\"params\"], \"multi_obj\"], axis=1)\n",
    "del tmp                               \n",
    "\n",
    "all_df[\"params_multi\"] = all_df.apply(params_and_multi_str, axis=1)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tmp = heatmap_input.loc[heatmap_input.index.str.contains(\"0.8_0.005_0.055\")]\n",
    "# tmp.loc[\"0_19_0.8_0.005_0.055\", \"14905A\"] = 1\n",
    "# tmp.loc[\"0_33_0.8_0.005_0.055\", \"14233G\"] = 1\n",
    "# #print('tmp', tmp.head())\n",
    "\n",
    "# tmp_obj = _objective_two_unique_vars_in_clone(tmp, to_pivot=False)\n",
    "# tmp_obj\n",
    "\n",
    "#     for cl in clones_to_keep:\n",
    "#         curr_v = df.loc[[cl], (df.loc[cl]>0)]\n",
    "#         # if clones with >2 variants, count how many of those are unique\n",
    "#         n_unique_vars = sum(curr_v.apply(lambda x: x.name in vars_to_keep, axis=0))\n",
    "#         if n_unique_vars>1:\n",
    "#             obj += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap of clone-variant number of cells for all the distinguishing variants of the top results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_heatmap(*args, **kwargs):\n",
    "    data = kwargs.pop('data')\n",
    "    #param_names = kwargs.pop('param_names', None)\n",
    "    print(data.shape)\n",
    "    d = data.pivot(index=args[1], columns=args[0], values=args[2]).fillna(0)\n",
    "    \n",
    "    # get all clones and variants\n",
    "    d_full = pd.DataFrame(index=clones_order, columns=variants_order)\n",
    "    d_full.loc[:,:] = 0\n",
    "    d_full.loc[d.index,d.columns] = d\n",
    "    d_full = d_full.astype(float)\n",
    "    \n",
    "    # get cluster results with jaccard\n",
    "    g = sns.clustermap(d_full, method=\"single\")\n",
    "    inds = g.dendrogram_row.dendrogram[\"leaves\"]\n",
    "    cols = g.dendrogram_col.dendrogram[\"leaves\"]\n",
    "    plt.close(g.fig)  \n",
    "\n",
    "    sns.heatmap(d_full.iloc[inds,cols], cbar_kws = dict(orientation=\"vertical\"), **kwargs)\n",
    "    plt.title(data[\"params_multi\"].values[0])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'params:\\npct_thresh=0.950\\naf_thresh=0.005\\nother_pct_thresh=0.105\\nObjective score=0.0024315666210959126 (want to maximize)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df[\"params_multi\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 14)\n",
      "(17, 14)\n",
      "(8, 14)\n",
      "(17, 14)\n",
      "(17, 14)\n",
      "(17, 14)\n",
      "(11, 14)\n",
      "(7, 14)\n",
      "(17, 14)\n",
      "(11, 14)\n",
      "(7, 14)\n",
      "(17, 14)\n",
      "(11, 14)\n",
      "(7, 14)\n",
      "(20, 14)\n",
      "(11, 14)\n"
     ]
    }
   ],
   "source": [
    "fg = sns.FacetGrid(data=all_df.reset_index(), height=4, sharey=False, sharex=False,\n",
    "                   col=\"params\", col_wrap=4, col_order=filt_results[\"params\"].values, margin_titles=True)\n",
    "\n",
    "fg.map_dataframe(draw_heatmap, 'variant','clone', 'log2_n_cells')#, cbar=False)\n",
    "#fg.set_titles(row_template = 'other_pct_thresh: {row_name}', col_template = 'pct_thresh: {col_name}')\n",
    "fg.fig.suptitle(f\"Best parameter combinations shown in order\")\n",
    "fg.fig.subplots_adjust(top=0.9, hspace = 0.8)\n",
    "\n",
    "plt.title(\"multiobjective function (want to maximize)\")\n",
    "plt.savefig(join(outdir, \"top_param_results.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table for the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_params = filt_results.iloc[0]\n",
    "best_params = pd.DataFrame(best_params).transpose()\n",
    "best_params.index = [\"objective_scores\"]\n",
    "best_params.loc[\"weight\"] = None\n",
    "for obj, w in zip(objectives_l, weights):\n",
    "    best_params.loc[\"weight\", f\"{obj}_obj\"] = w\n",
    "\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_df = all_df[all_df['params'] == best_params.loc[\"objective_scores\", \"params\"]]\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clone_var_table = (out_df.pivot(index= 'variant',columns='clone', values='log2_n_cells').fillna(0))\n",
    "clone_var_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.clustermap(clone_var_table)\n",
    "plt.title(best_params.loc[\"objective_scores\", \"params_multi\"])\n",
    "plt.savefig(join(outdir, \"best_params.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save clone-variant table and the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_var_table.to_csv(join(outdir, \"best_params_clone_vars.csv\"))\n",
    "best_params.to_csv(join(outdir, \"best_params.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_results.to_csv(join(outdir, \"param_results.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter cells meta and af and df and save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clones_keep = clone_var_table.loc[:, ~((clone_var_table==0).all(axis=0))].columns\n",
    "vars_keep = clone_var_table.loc[~((clone_var_table==0).all(axis=1))].index\n",
    "\n",
    "out_cells_meta = curr_labels[curr_labels[\"name\"].isin(clones_keep)]\n",
    "out_AF_df = AF_df.loc[vars_keep, out_cells_meta.index]\n",
    "out_DP_df = DP_df.loc[vars_keep, out_cells_meta.index]\n",
    "\n",
    "## save cells-meta, af and dp\n",
    "out_cells_meta.to_csv(join(outdir, \"cells_meta.tsv\"),sep=\"\\t\")\n",
    "out_AF_df.to_csv(join(outdir, \"af.tsv\"), sep=\"\\t\")\n",
    "out_DP_df.to_csv(join(outdir, \"dp.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(clone_var_table.loc[vars_keep,clones_keep])\n",
    "plt.title(best_params.loc[\"objective_scores\", \"params_multi\"])\n",
    "plt.savefig(join(outdir, \"best_params_filt.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Initialize ga\n",
    "\n",
    "# pool = multiprocessing.Pool(processes=16)\n",
    "\n",
    "\n",
    "\n",
    "# # the random initialization of the genetic algorithm is done here\n",
    "# # it gives a list of integers with for each products the number of times it is bought\n",
    "\n",
    "# lower_bounds = [0,0,0]\n",
    "# upper_bounds = [1,1,1]\n",
    "\n",
    "\n",
    "# def init_pop(n):\n",
    "#     return list(np.random.random(size=n))\n",
    "\n",
    "\n",
    "# def evaluate(individual, AF_df, DP_df, curr_labels):\n",
    "#     ic('individual before', individual)\n",
    "#     ic(len(individual))\n",
    "#     individual = individual[0]\n",
    "#     ic('individual after', individual)\n",
    "#     ic(len(individual))\n",
    "#     #pct_thresh, af_thresh, other_pct_thresh = individual[\"pct_thresh\"], individual[\"af_thresh\"], individual[\"other_pct_thresh\"] #solution[0], solution[1], solution[2]\n",
    "    \n",
    "#     solution = {\"pct_thresh\": individual[0], \"af_thresh\":individual[1],  \"other_pct_thresh\": individual[2]}\n",
    "#     #data = \n",
    "#     data = {\"AF_df\": AF_df, \"DP_df\":DP_df, \"curr_labels\":curr_labels} \n",
    "#     all_unique_df = get_clones_unique_variants(solution, data)\n",
    "#     data[\"all_unique_df\"] = all_unique_df\n",
    "#     eval_out = _objectives(data)\n",
    "#     return tuple(eval_out.values())\n",
    "\n",
    "# def checkBounds(min, max):\n",
    "#     def decorator(func):\n",
    "#         def wrapper(*args, **kargs):\n",
    "#             offspring = func(*args, **kargs)\n",
    "#             for child in offspring:\n",
    "#                 for i in range(len(child)):\n",
    "#                     if child[i] > max[i]:\n",
    "#                         child[i] = max[i]\n",
    "#                     elif child[i] < min[i]:\n",
    "#                         child[i] = min[i]\n",
    "#             return offspring\n",
    "#         return wrapper\n",
    "#     return decorator\n",
    "\n",
    "# #from scoop import futures\n",
    "\n",
    "# # this is the setup of the deap library: registering the different function into the toolbox\n",
    "# creator.create(\"FitnessMulti\", base.Fitness, weights=(1.0, 1.0, 2.0, 1.0, 1.0))\n",
    "# creator.create(\"Individual\", list, fitness=creator.FitnessMulti)\n",
    "\n",
    "# toolbox = base.Toolbox()\n",
    "\n",
    "# #toolbox.register(\"map\", futures.map)\n",
    "# toolbox.register(\"n_per_product\", init_pop, n=n_params)\n",
    "\n",
    "# toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.n_per_product, n=n_params)\n",
    "# toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "\n",
    "# toolbox.register(\"evaluate\", evaluate, AF_df=AF_df, DP_df=DP_df, curr_labels=curr_labels)\n",
    "\n",
    "# toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "# toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "# toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# # toolbox.register(\"mate\", tools.cxBlend, alpha=0.2)\n",
    "# # toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=2, indp=0.05)\n",
    "\n",
    "# # LOWER AND UPPER BOUNDs\n",
    "# toolbox.decorate(\"mate\", checkBounds(lower_bounds, upper_bounds))\n",
    "# toolbox.decorate(\"mutate\", checkBounds(lower_bounds, upper_bounds))\n",
    "\n",
    "# toolbox.register(\"map\", pool.map)\n",
    "\n",
    "\n",
    "# stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "# stats.register(\"avg\", np.mean)\n",
    "# stats.register(\"std\", np.std)\n",
    "# stats.register(\"min\", np.min)\n",
    "# stats.register(\"max\", np.max)\n",
    "\n",
    "# # logbook = tools.Logbook()\n",
    "# # logbook.record(gen=0, evals=30, **record)\n",
    "# # import pickle\n",
    "# # pickle.dump(logbook, lb_file)\n",
    "\n",
    "# ## Run\n",
    "\n",
    "# ## V01 - using pre-defined algorithms\n",
    "\n",
    "# # this is the definition of the total genetic algorithm is executed, it is almost literally copied from the deap library\n",
    "# def main():\n",
    "#     pop = toolbox.population(n=10)\n",
    "#     pop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=3, \n",
    "#                                        stats=stats, verbose=True)\n",
    "\n",
    "# best_solution = main()\n",
    "\n",
    "# #products_table['univariate_choice'] = pd.Series(best_solution[0])\n",
    "# #products_table.head()\n",
    "# pd.Series(best_solution[0])\n",
    "\n",
    "# ## V02 - using main function taken from site\n",
    "\n",
    "# # this is the definition of the total genetic algorithm is executed, it is almost literally copied from the deap library\n",
    "# def main():\n",
    "#     pop = toolbox.population(n=300)\n",
    "    \n",
    "#     # Evaluate the entire population\n",
    "#     fitnesses = list(map(toolbox.evaluate, pop))\n",
    "#     for ind, fit in zip(pop, fitnesses):\n",
    "#         ind.fitness.values = fit\n",
    "\n",
    "#     # CXPB  is the probability with which two individuals\n",
    "#     #       are crossed\n",
    "#     #\n",
    "#     # MUTPB is the probability for mutating an individual\n",
    "#     CXPB, MUTPB = 0.5, 0.2\n",
    "    \n",
    "#     # Extracting all the fitnesses of \n",
    "#     fits = [ind.fitness.values[0] for ind in pop]\n",
    "    \n",
    "#     # Variable keeping track of the number of generations\n",
    "#     g = 0\n",
    "    \n",
    "#     # Begin the evolution\n",
    "#     while g < 5:\n",
    "#         # A new generation\n",
    "#         g = g + 1\n",
    "#         print(\"-- Generation %i --\" % g)\n",
    "        \n",
    "#         # Select the next generation individuals\n",
    "#         offspring = toolbox.select(pop, len(pop))\n",
    "#         # Clone the selected individuals\n",
    "#         offspring = list(map(toolbox.clone, offspring))\n",
    "        \n",
    "#         # Apply crossover and mutation on the offspring\n",
    "#         for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "#             if random.random() < CXPB:\n",
    "#                 toolbox.mate(child1[0], child2[0])\n",
    "#                 del child1.fitness.values\n",
    "#                 del child2.fitness.values\n",
    "\n",
    "#         for mutant in offspring:\n",
    "#             if random.random() < MUTPB:\n",
    "#                 toolbox.mutate(mutant[0])\n",
    "#                 del mutant.fitness.values\n",
    "            \n",
    "#         # Evaluate the individuals with an invalid fitness\n",
    "#         invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "#         fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "#         for ind, fit in zip(invalid_ind, fitnesses):\n",
    "#             ind.fitness.values = fit\n",
    "            \n",
    "#         pop[:] = offspring\n",
    "        \n",
    "#         # Gather all the fitnesses in one list and print the stats\n",
    "#         fits = [ind.fitness.values[0] for ind in pop]\n",
    "        \n",
    "#         length = len(pop)\n",
    "#         mean = sum(fits) / length\n",
    "#         sum2 = sum(x*x for x in fits)\n",
    "#         std = abs(sum2 / length - mean**2)**0.5\n",
    "        \n",
    "#         ic(min(fits), max(fits), mean, std)\n",
    "    \n",
    "#     best = pop[np.argmax([toolbox.evaluate(x) for x in pop])]\n",
    "#     return best\n",
    "\n",
    "# best_solution = main()\n",
    "\n",
    "# #products_table['univariate_choice'] = pd.Series(best_solution[0])\n",
    "# #products_table.head()\n",
    "# pd.Series(best_solution[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5560.364131,
   "end_time": "2021-01-27T10:03:31.625455",
   "environment_variables": {},
   "exception": null,
   "input_path": "/data2/mito_lineage/src/vireo/vireoSNP_clones.ipynb",
   "output_path": "results/jan21_2021/chrM/P2_cellSNP_minC200_minAF0.01/lineage_chrM.ipynb",
   "parameters": {
    "AD_F": "data/jan21_2021/chrM/P2_cellSNP_minC200_minAF0.01/cellSNP.tag.AD.mtx",
    "DP_F": "data/jan21_2021/chrM/P2_cellSNP_minC200_minAF0.01/cellSNP.tag.DP.mtx"
   },
   "start_time": "2021-01-27T08:30:51.261324",
   "version": "2.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
