{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c7504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['ps.useafm'] = True\n",
    "matplotlib.rcParams['pdf.use14corefonts'] = True\n",
    "#matplotlib.rcParams['text.usetex'] = True\n",
    "from icecream import ic\n",
    "\n",
    "ic.disable()\n",
    "\n",
    "# #indir = snakemake.input.indir\n",
    "# indir = snakemake.params.indir\n",
    "# outdir = snakemake.params.outdir\n",
    "# donor =  int(snakemake.params.donor)\n",
    "# anno_cells_meta_f = snakemake.input.anno_cells_meta_f  #\"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clones/variants_init/knn/kparam_30/gff_A2_black/annotation_clones/se_cells_meta_labels.tsv\"\n",
    "# # Objective weights. order of the columns\n",
    "# weights_cfg = snakemake.params.weights_cfg\n",
    "# objectives_l = snakemake.params.get(\"objectives_l\", \n",
    "#                                     [\"variants_with_clone_norm_by_1_over_nclones_with_variant\", \n",
    "#                                      \"max_clone_ncells_over_ncells\",\n",
    "#                                      \"pct_thresh\",\"other_pct_thresh\", \n",
    "#                                      \"n_vars\", \"obj_nclones_more_than_one_unique\"])\n",
    "# ncpus = snakemake.params.get('ncpus', 8)\n",
    "# topn = snakemake.params.get(\"topn\", 16)\n",
    "indir = snakemake.params.indir\n",
    "outdir = snakemake.params.outdir\n",
    "donor =  int(snakemake.params.donor)\n",
    "# Objective weights. order of the columns\n",
    "weights_cfg =  snakemake.params.weights_cfg\n",
    "objectives_l = snakemake.params.objectives_l\n",
    "ncpus = snakemake.params.get(\"ncpus\", 8)\n",
    "topn = snakemake.params.get(\"topn\", 8)\n",
    "to_test = snakemake.params.get(\"to_test\", False)\n",
    "\n",
    "constraint_name = snakemake.params.constraint_name\n",
    "constraints = snakemake.params.get(\"constraints\", None)\n",
    "\n",
    "#anno_cells_meta_f = snakemake.input.anno_cells_meta_f\n",
    "\n",
    "# try:\n",
    "#     indir = snakemake.params.indir\n",
    "#     outdir = snakemake.params.outdir\n",
    "#     donor =  int(snakemake.params.donor)\n",
    "#     anno_cells_meta_f = snakemake.input.anno_cells_meta_f  #\"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clones/variants_init/knn/kparam_30/gff_A2_black/annotation_clones/se_cells_meta_labels.tsv\"\n",
    "#     # Objective weights. order of the columns\n",
    "#     weights_cfg =  snakemake.params.weights_cfg\n",
    "#     objectives_l = snakemake.params.objectives_l\n",
    "# #     objectives_l = snakemake.params.get(\"objectives_l\", \n",
    "# #                                         [\"variants_with_clone_norm_by_1_over_nclones_with_variant\",\n",
    "# #                                          \"max_clone_ncells_over_nclones\", \"max_clone_ncells_over_ncells\",\n",
    "# #                                          \"pct_thresh\",\"other_pct_thresh\", \"n_vars\", \n",
    "# #                                          \"obj_nclones_more_than_one_unique\"])\n",
    "#     ncpus = snakemake.params.get(ncpus, 8)\n",
    "#     topn = snakemake.params.get(topn, 8)\n",
    "#     to_test = snakemake.params.get(\"to_test\", False)\n",
    "\n",
    "# except:                                       \n",
    "#     indir = \"/data/Mito_Trace/output/pipeline/v04/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clones/variants_init/knn/kparam_30/\"\n",
    "#     outdir = \"/data/Mito_Trace/output/pipeline/v04/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clones/variants_init/knn/kparam_30/distinct_variants/donor0/scrap/\"\n",
    "#     donor = 0\n",
    "#     anno_cells_meta_f = \"/data/Mito_Trace/output/pipeline/v04/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clones/variants_init/knn/kparam_30/gff_A2_black/annotation_clones/se_cells_meta_labels.tsv\"\n",
    "#     # pct_thresh = [0.01, 0.1, 0.25, 0.4, 0.5, 0.75, 0.95]\n",
    "#     # other_pct_thresh = [0.01, 0.1, 0.25, 0.5]\n",
    "#     # af_thresh = [0, 0.01, 0.1, 0.25, 0.4]\n",
    "\n",
    "#     # Objective weights. order of the columns\n",
    "#     #weights = [1,0,0,1,-1, 1, 1] #[1,1,1,1,1] #np.ones([len(objectives),])\n",
    "#     objectives_l = [\"variants_with_clone_norm_by_1_over_nclones_with_variant\",\n",
    "#                  \"max_clone_ncells_over_ncells\",\n",
    "#                  \"pct_thresh\",\"other_pct_thresh\",\n",
    "#                  \"n_vars\", \"obj_nclones_more_than_one_unique\"]\n",
    "#     weights_cfg = {\"standard\": [1,1,1,-1, 1, 1], \"multivar_clones\": [1,1,1,-1, 1, 3], \n",
    "#                    \"high_unique\": [2,1,1,-1, 1, 2], \"high_cells\": [1,1,2,-1, 1, 1],\n",
    "#                    \"high_pct\": [1,1,2,-2, 1, 1]\n",
    "#                   }\n",
    "\n",
    "#     ncpus=8\n",
    "#     topn=8\n",
    "#     to_test = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc3edc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba4f7147",
   "metadata": {},
   "outputs": [],
   "source": [
    "if constraints is not None:\n",
    "    min_pct_thresh = constraints[\"min_pct_thresh\"]\n",
    "    max_other_pct_thresh = constraints[\"max_other_pct_thresh\"]\n",
    "    min_af_thresh = constraints[\"min_af_thresh\"]\n",
    "else:\n",
    "    min_pct_thresh = 0.1 # np.arange(0.2, 1, 0.05)\n",
    "    max_other_pct_thresh = 0.99 #np.arange(0.005, 1, 0.05)\n",
    "    min_af_thresh = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e2376d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import src.clone_variants_optim  as optim\n",
    "\n",
    "from os.path import join, exists, dirname\n",
    "from glob import glob\n",
    "import pickle\n",
    "import mplh.cluster_help as ch\n",
    "import mplh.fig_utils as fu\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "from scipy import sparse\n",
    "from scipy.io import mmread\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import hypergeom\n",
    "from itertools import product\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: format(x, '.3f')})\n",
    "\n",
    "# parallel setup\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=ncpus) #, progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766ee5b3",
   "metadata": {},
   "source": [
    "## Setup parameters and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adabef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives = {ind:x for ind,x in enumerate(objectives_l)}\n",
    "param_names = [\"pct_thresh\",\"af_thresh\", \"other_pct_thresh\"]\n",
    "n_params = 3\n",
    "\n",
    "\n",
    "pct_thresh = np.arange(min_pct_thresh, 1, 0.05)\n",
    "other_pct_thresh = np.arange(0.005, max_other_pct_thresh, 0.05)\n",
    "af_thresh = np.arange(min_af_thresh, 1, 0.05)\n",
    "\n",
    "params = {\"pct_thresh\": pct_thresh,\n",
    "          \"other_pct_thresh\": other_pct_thresh,\n",
    "          \"af_thresh\": af_thresh,}\n",
    "\n",
    "\n",
    "\n",
    "# There are 3 params used for calling the clone\n",
    "full_params = list(product(*list(params.values())))\n",
    "full_params = pd.DataFrame(full_params, columns=params.keys())\n",
    "\n",
    "print(full_params.shape)\n",
    "full_params.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5144e874",
   "metadata": {},
   "source": [
    "## Set up the weights and their folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97ecdcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "exists(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18b6f1a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "weights_outdirs = {}\n",
    "for w in weights_cfg:\n",
    "    weights_outdirs[w] = join(outdir, f\"objs_{w}_{constraint_name}\")\n",
    "    if not exists(weights_outdirs[w]):\n",
    "        os.mkdir(weights_outdirs[w])\n",
    "\n",
    "    weights = np.array(weights_cfg[w])\n",
    "\n",
    "    # save weights and params:\n",
    "    weights_params_str = \"objective, weight\"\n",
    "    for i in zip(objectives_l, weights):\n",
    "        weights_params_str = weights_params_str + f\"{i[0]},{i[1]}\\n\"\n",
    "    with open(join(weights_outdirs[w], \"obj_weights.txt\"), 'w') as f:\n",
    "        f.write(weights_params_str)\n",
    "\n",
    "    assert(len(weights)==len(objectives))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67533fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_outdirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c9b1af",
   "metadata": {},
   "source": [
    "\n",
    "## Load & preprocess:\n",
    "- AF df\n",
    "- DP df\n",
    "- cells_meta with clone labels. need to create name as donor_lineage\n",
    "\n",
    "Remove donor variants (>0.9 in 90% of pop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "783fbcd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "af_indir = join(indir, \"sc_af\", f\"donor{donor}\")\n",
    "\n",
    "AF_df = pd.read_csv(join(af_indir, \"af.tsv\"), index_col=0, sep=\"\\t\")\n",
    "DP_df = pd.read_csv(join(af_indir, \"dp.tsv\"), index_col=0, sep=\"\\t\")\n",
    "\n",
    "print(AF_df.shape)\n",
    "print(DP_df.shape)\n",
    "\n",
    "AF_df.head()\n",
    "\n",
    "cells_meta = pd.read_csv(join(indir, \"cells_meta.tsv\"), sep='\\t', index_col=\"ID\")#.sort_values([\"donor\", \"lineage\"])\n",
    "cells_meta[\"name\"] = cells_meta[\"donor\"].astype(str)+\"_\"+cells_meta[\"lineage\"].astype(str)\n",
    "curr_labels = cells_meta[cells_meta[\"donor\"]==donor]\n",
    "\n",
    "\n",
    "conditions = curr_labels[\"condition\"].unique()\n",
    "\n",
    "\n",
    "\n",
    "## Get donor inds\n",
    "donor_inds = AF_df.index[((AF_df>0.9).sum(axis=1)>(0.9*AF_df.shape[1]))]\n",
    "\n",
    "\n",
    "def rm_high(df, thresh, pct_thresh):\n",
    "    return df.loc[~(((df>thresh).sum(axis=1)>pct_thresh*df.shape[0]))]\n",
    "\n",
    "def rm_low(df, thresh, pct_thresh):\n",
    "    return df.loc[~((df<thresh).sum(axis=1)>(pct_thresh*df.shape[1]))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ce2c642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################################\n",
    "# Run pipeline \n",
    "################################################\n",
    "if to_test:\n",
    "    results_df = full_params.sample(32).parallel_apply(\n",
    "        optim.evaluate_series, args=(AF_df, DP_df, curr_labels, False, objectives_l), axis=1)\n",
    "else:\n",
    "    if full_params.shape[0]>=10000:\n",
    "        results_df = full_params.sample(10000).parallel_apply(optim.evaluate_series, args=(AF_df, DP_df, \n",
    "                                                                                           curr_labels, False, objectives_l),\n",
    "                                                              axis=1)\n",
    "    else:\n",
    "        results_df = full_params.parallel_apply(optim.evaluate_series, args=(AF_df, DP_df, curr_labels, False, objectives_l),\n",
    "                                                axis=1)\n",
    "    #results_df = full_params.sample(100).parallel_apply(evaluate_series, args=(AF_df, DP_df, curr_labels), axis=1)\n",
    "\n",
    "#print(results_df.head())\n",
    "print((results_df>0).any())\n",
    "drop_inds = results_df.loc[(results_df==0).all(axis=1)].index\n",
    "results_df = results_df.loc[(~(results_df==0).all(axis=1))]\n",
    "full_params = full_params.loc[results_df.index]\n",
    "results_df.to_csv(join(outdir, \"objectives.csv\"))\n",
    "full_params.to_csv(join(outdir, \"raw_params.csv\"))\n",
    "\n",
    "results_norm = optim.norm_results(results_df)\n",
    "results_norm.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bbe3f9",
   "metadata": {},
   "source": [
    "## For each weights config get objective scores and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20e174c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for w in weights_cfg:\n",
    "    print(\"w\", w)\n",
    "    curr_outdir = weights_outdirs[w]\n",
    "    if not exists(curr_outdir):\n",
    "        os.mkdir(curr_outdir)\n",
    "    weights = weights_cfg[w]\n",
    "    print('weights', weights)\n",
    "    curr_results_norm = optim.set_multi(results_norm.copy(), weights, to_norm_results=False)\n",
    "    rank_df = optim.set_multi_rank(curr_results_norm, weights)\n",
    "\n",
    "    drop_results = curr_results_norm.loc[curr_results_norm[\"multi\"].isnull()]\n",
    "    curr_results_norm = curr_results_norm.loc[~(curr_results_norm[\"multi\"].isnull())]\n",
    "\n",
    "    ########################\n",
    "    ## Save the objective results\n",
    "    ########################\n",
    "    curr_results_norm.to_csv(join(curr_outdir, \"objectives_norm.csv\"))\n",
    "    rank_df.to_csv(join(curr_outdir, \"objectives_rank.csv\"))\n",
    "    #curr_results_norm.loc[curr_results_norm[\"multi\"] == np.nan]\n",
    "    full_params.to_csv(join(curr_outdir, \"params.csv\"))\n",
    "\n",
    "    \n",
    "    if len(curr_results_norm) == 0:\n",
    "        \"\"\" Empty dataframe b/c no barcodes were enriched\"\"\"\n",
    "        continue\n",
    "\n",
    "    ########################\n",
    "    # Plot distribution results\n",
    "    ########################\n",
    "    \n",
    "    sns.displot(curr_results_norm[\"multi\"])\n",
    "    plt.title(\"multiobjective function (want to maximize)\")\n",
    "    plt.savefig(join(curr_outdir, \"loss_multi.pdf\"))\n",
    "\n",
    "    \n",
    "    sns.displot(rank_df[\"multi\"])\n",
    "    plt.title(\"ranked multiobjective scores\")\n",
    "    #sns.pairplot(rank_df)\n",
    "\n",
    "\n",
    "\n",
    "    ########################\n",
    "    # Get the top n results\n",
    "    ########################\n",
    "    filt_rank, filt_results = optim.get_top_n_results(curr_results_norm, rank_df, n=topn)\n",
    "    filt_results.columns = [f\"{x}_obj\" for x in filt_results.columns]\n",
    "    filt_results = pd.merge(filt_results, full_params, left_index=True, right_index=True, how=\"left\")\n",
    "    filt_rank = filt_rank.loc[filt_results.index]\n",
    "\n",
    "    all_df = []\n",
    "    all_objs = {}\n",
    "    print(\"Plotting top objective results\")\n",
    "    for ind, val in filt_results.iterrows():\n",
    "        print(f\"param id {ind}\")\n",
    "        obj_out, data = optim.evaluate_series(val, AF_df, DP_df, curr_labels, return_data=True, objectives_l=objectives_l)\n",
    "        all_df.append(data[\"all_unique_df\"])\n",
    "        all_objs[ind] = obj_out\n",
    "    all_df = pd.concat(all_df)\n",
    "\n",
    "    heatmap_input = all_df[[\"n_cells\", \"variant\"]].reset_index().pivot(index=\"id\", columns=\"variant\", values=\"n_cells\").fillna(0).astype(int)\n",
    "    meta_df = all_df[[\"af_thresh\", \"other_pct_thresh\", \"pct_thresh\", \"clone\"]]\n",
    "    meta_df = meta_df.loc[~(meta_df.index.duplicated())]\n",
    "    meta_df = meta_df.sort_values([\"af_thresh\",\"pct_thresh\", \"other_pct_thresh\", \"clone\"])\n",
    "    heatmap_input = heatmap_input.loc[meta_df.index]\n",
    "\n",
    "    # Get the variants based on total number of cells across parameters\n",
    "    heatmap_input = heatmap_input.loc[:,heatmap_input.sum().sort_values()[::-1].index]\n",
    "    variants_order = heatmap_input.columns\n",
    "\n",
    "    clone_sums = meta_df.groupby(\"clone\").apply(optim.clone_sum, heatmap_input)\n",
    "    clone_sums = clone_sums.loc[:, clone_sums.sum().sort_values()[::-1].index]\n",
    "    clones_order = clone_sums.index\n",
    "\n",
    "    all_df[\"params\"] = all_df.apply(optim.params_to_str, axis=1, args=(param_names,))\n",
    "    filt_results[\"params\"] = filt_results.apply(optim.params_to_str, axis=1, args=(param_names,))\n",
    "    filt_results[\"params_multi\"] = filt_results.apply(optim.params_and_multi_str, axis=1)\n",
    "    tmp = filt_results.set_index(\"params\")\n",
    "    all_df[\"multi_obj\"] = all_df.apply(lambda x: tmp.loc[x[\"params\"], \"multi_obj\"], axis=1)\n",
    "    del tmp\n",
    "\n",
    "\n",
    "    all_df[\"params_multi\"] = all_df.apply(optim.params_and_multi_str, axis=1)\n",
    "\n",
    "\n",
    "    fg = sns.FacetGrid(data=all_df.reset_index(), height=4, sharey=False, sharex=False,\n",
    "                       col=\"params_multi\", col_wrap=4, col_order=filt_results[\"params_multi\"].values, margin_titles=True)\n",
    "\n",
    "    fg.map_dataframe(optim.draw_heatmap, 'variant','clone', 'log2_n_cells',\n",
    "                     clones_order=clones_order, variants_order=variants_order)#, cbar=False)\n",
    "\n",
    "    #fg.set_titles(row_template = 'other_pct_thresh: {row_name}', col_template = 'pct_thresh: {col_name}')\n",
    "    fg.fig.suptitle(f\"Best parameter combinations shown in order\")\n",
    "    fg.fig.subplots_adjust(top=0.9, hspace = 0.8)\n",
    "\n",
    "    plt.savefig(join(curr_outdir, \"top_param_results.pdf\"), dpi=300)\n",
    "    plt.savefig(join(curr_outdir, \"top_param_results.svg\"), dpi=300)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8650e19e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
