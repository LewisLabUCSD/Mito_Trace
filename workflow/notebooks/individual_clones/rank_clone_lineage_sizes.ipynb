{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec027fb",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#cells_meta_f = \"\"\n",
    "# Input info\n",
    "#indir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clonal_shifts/variants_init/donors/donor0/clones/knn_kparam_30/\"\n",
    "#noInput_indir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clonal_shifts/variants_init/clones/results/noInput/knn/kparam_30/\"\n",
    "#input_indir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clonal_shifts/variants_init/clones/results/inputOnly/knn/kparam_30/\"\n",
    "#outdir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clonal_shifts/donors/donor0/variants_init/knn/kparam_30/clones/\"\n",
    "\n",
    "# params\n",
    "p_thresh = 0.1 \n",
    "\n",
    "\n",
    "indir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clonal_shifts/variants_init/donors/donor1/mt_as_clones_dendro/af.0.1_othaf.0.1_cov.10_othcov.10_ncells.10_othncells.0.25_mean.0\"\n",
    "outdir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/single_clones/donor1/cloneMethod_variants_init_mt_bestparams_af.0.1_othaf.0.1_cov.10_othcov.10_ncells.10_othncells.0.25_mean.0/clonalShift_method_mt_as_clones_dendro/clones_ranked\"\n",
    "#cloneID = \"\"\n",
    "clone_id = \"cloneID\" # \"den_clust\"\n",
    "#clust_id = \"clusterID\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join, exists\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scipy.stats import hypergeom, fisher_exact\n",
    "from statsmodels.stats import multitest \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import clonal_shifts as cs\n",
    "from icecream import ic\n",
    "\n",
    "from mplh import cluster_help as ch\n",
    "\n",
    "from scipy.stats import rankdata, gmean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8817e294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cells_meta = pd.read_csv(cells_meta_f, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32916a94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f0918d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noInput_ncells = pd.read_csv(join(indir, \"noInput_ncells.csv\"),  index_col=0)\n",
    "input_ncells = pd.read_csv(join(indir, \"input_ncells.csv\"), index_col=0)\n",
    "\n",
    "# input_ncells_df = input_ncells.reset_index().melt(id_vars=\"index\", value_name=\"pval\")\n",
    "# noInput_ncells_df = noInput_ncells.reset_index().melt(id_vars=\"index\", value_name=\"pval\")\n",
    "\n",
    "# noInput_ncells_df[\"condition\"] = \"cultured\"\n",
    "# noInput_shuffle_df[\"condition\"] = \"cultured\"\n",
    "# input_ncells_df[\"condition\"] = \"input\"\n",
    "# input_shuffle_df[\"condition\"] = \"input\"\n",
    "\n",
    "input_ncells = input_ncells.groupby(clone_id).sum()[[\"count\"]].sort_values(by=\"count\")[::-1]\n",
    "noInput_ncells = noInput_ncells.groupby(clone_id).sum()[[\"count\"]].sort_values(by=\"count\")[::-1]\n",
    "ncells_df = pd.merge(input_ncells,noInput_ncells,left_index=True, right_index=True, suffixes=[\"_input\", \"_cultured\"])\n",
    "ncells_df = ncells_df.loc[ncells_df.sum(axis=1).sort_values()[::-1].index]\n",
    "ncells_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a620f6af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noInput_hyper = pd.read_csv(join(indir, \"noInput_hypergeo_pvals.csv\"),  index_col=0)\n",
    "noInput_shuffle_df = pd.read_csv(join(indir, \"noInput_shuffle_results_pvals.csv\"), index_col=0)\n",
    "noInput_shuffle_df = noInput_shuffle_df.rename({\"value\":\"pval\"}, axis=1)\n",
    "\n",
    "input_hyper = pd.read_csv(join(indir, \"input_hypergeo_pvals.csv\"), index_col=0)\n",
    "input_shuffle_df = pd.read_csv(join(indir, \"input_shuffle_results_pvals.csv\"), index_col=0)\n",
    "\n",
    "input_shuffle_df = input_shuffle_df.rename({\"value\":\"pval\"}, axis=1)\n",
    "input_shuffle_df\n",
    "\n",
    "input_hyper_df = input_hyper.reset_index().melt(id_vars=\"index\", value_name=\"pval\")\n",
    "input_hyper_df[\"method\"] = \"hypergeo\"\n",
    "noInput_hyper_df = noInput_hyper.reset_index().melt(id_vars=\"index\", value_name=\"pval\")\n",
    "noInput_hyper_df[\"method\"] = \"hypergeo\"\n",
    "\n",
    "\n",
    "\n",
    "noInput_hyper_df[\"condition\"] = \"cultured\"\n",
    "noInput_shuffle_df[\"condition\"] = \"cultured\"\n",
    "input_hyper_df[\"condition\"] = \"input\"\n",
    "input_shuffle_df[\"condition\"] = \"input\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.concat((input_hyper_df, input_shuffle_df), axis=0, ignore_index=True)\n",
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a72fef9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noInput_df = pd.concat((noInput_hyper_df, noInput_shuffle_df), axis=0, ignore_index=True)\n",
    "noInput_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01edae28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat((input_df, noInput_df), axis=0).reset_index(drop=True)\n",
    "#df = pd.merge(input_df, noInput_df, on=[\"index\", \"variable\", \"method\"], suffixes=[\"_input\", \"_cultured\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df = df.copy()\n",
    "p_df[\"is_sig\"] = p_df[\"pval\"]<p_thresh\n",
    "p_df\n",
    "\n",
    "def check_sig(x):\n",
    "    #print(x.head())\n",
    "    name, clust, cond = x.name\n",
    "    x = x.set_index(\"method\")[\"is_sig\"]\n",
    "    assert(x.index.duplicated().sum()==0)\n",
    "    #print('x',x )\n",
    "    sig = x.loc[\"hypergeo\"] \n",
    "    #print('sig', sig)\n",
    "    sig = sig.astype(int) + (x.loc[\"global_all\"]).astype(int)\n",
    "    sig = sig.astype(int) + (x.loc[\"clone_min\"]).astype(int)\n",
    "    sig = sig.astype(int) + (x.loc[\"global_min\"]).astype(int)\n",
    "    sig\n",
    "    return sig\n",
    "\n",
    "p_df = p_df.groupby([\"index\",\"variable\", \"condition\"]).apply(check_sig)\n",
    "p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7205e7e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca7b28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_df_out = p_df.reset_index().rename({0:\"significant_score\"}, axis=1)\n",
    "#p_df_out.set_index( )\n",
    "p_df_out[\"cluster_condition\"] = p_df_out.apply(lambda x: f'{x[\"variable\"]}_{x[\"condition\"]}', axis=1)\n",
    "p_df_out\n",
    "\n",
    "#p_df_out[\"clone_condition\"] = p_df_out.apply(lambda x: f'{x[\"index\"]}_{x[\"condition\"]}', axis=1)\n",
    "\n",
    "\n",
    "p_df_out = p_df_out.pivot(index='index', columns='cluster_condition', values=\"significant_score\").fillna(0)\n",
    "\n",
    "p_df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106fe6cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clone_meta = pd.DataFrame(index=p_df_out.columns, columns = [\"condition\"])\n",
    "clone_meta[\"condition\"] = [\"input\" if \"input\" in x else \"cultured\" for x in clone_meta.index]\n",
    "clone_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_clust(x):\n",
    "#     print('x')\n",
    "#     print(x)\n",
    "#     print(p_df_out.loc[:, x.index])\n",
    "    g = ch.plot_cluster(p_df_out.loc[:, x.index], to_row_clust=False, to_col_clust=False)\n",
    "    plt.suptitle(x.name)\n",
    "    return\n",
    "\n",
    "clone_meta.groupby(\"condition\").apply(sig_clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf417af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.clustermap(p_df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15c8456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3539ba9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_df = df.groupby([\"index\", \"method\", \"condition\"]).min()[\"pval\"].reset_index()\n",
    "min_df\n",
    "\n",
    "min_df_wide = min_df.pivot(index=\"index\", values=\"pval\", columns=[\"method\", \"condition\"])\n",
    "min_df_wide.columns = ['_'.join(col).strip() for col in min_df_wide.columns.values] # flatten to 1D columns\n",
    "min_df_wide\n",
    "ncells_df[\"ncells\"] = ncells_df.sum(axis=1)\n",
    "min_df_wide = pd.concat((min_df_wide,ncells_df), axis=1)\n",
    "\n",
    "rank_df = min_df_wide.apply(lambda x: rankdata(x, method='max'), axis=0)\n",
    "\n",
    "\n",
    "gmean_ser = rank_df.apply(gmean, axis=1)\n",
    "gmean_ser = gmean_ser.sort_values()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f433f",
   "metadata": {},
   "source": [
    "## Get the clone order based on the ncells \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = rank_df.sort_values(\"ncells\")[::-1]\n",
    "rank_df\n",
    "## Get the clone order based on the mean of the rankings\n",
    "clone_order = rank_df.index\n",
    "min_df_wide = min_df_wide.loc[clone_order]\n",
    "rank_df = rank_df.loc[clone_order]\n",
    "rank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee9836",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clone_meta = pd.DataFrame(index=min_df_wide.columns, columns = [\"condition\"])\n",
    "clone_meta[\"condition\"] = [\"input\" if \"input\" in x else \"cultured\" for x in clone_meta.index]\n",
    "clone_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bbc43a",
   "metadata": {},
   "source": [
    "## Plot rankings ordered by clone, annd save output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbbff17",
   "metadata": {},
   "source": [
    "## Save:\n",
    "a) cloneID_rank.png  \n",
    "b) cloneID_order.txt - line-delimited text file with cloneID on each line  \n",
    "c) cloneID_rank.csv  - csv file of the ranking for each category  \n",
    "d) all_pvals: all p-values for for each clone-method-cluster-condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(outdir, \"cloneID_rank_ncells.txt\"), 'w') as f:\n",
    "    f.write('\\n'.join(clone_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420cb540",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df.to_csv(join(outdir, \"cloneID_rank_ncells_df.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be4db9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = ch.plot_cluster(rank_df, to_row_clust=False, to_col_clust=False, col_meta=clone_meta[[\"condition\"]])\n",
    "g.fig.suptitle(\"Ranking of each method across clones (lowest is best). Top is best-ranked clone\")\n",
    "#plt.savefig(join(outdir, \"cloneID_rank_sizes.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228858a",
   "metadata": {},
   "source": [
    "## Convert results to number of significant variables\n",
    "a. hypergeo < p  \n",
    "b. global_all < p  \n",
    "b. clone_min < p  \n",
    "c. global_min < p  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f0f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = min_df_wide.columns[min_df_wide.columns.str.contains(\"_input\")]\n",
    "input_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2f51a6",
   "metadata": {},
   "source": [
    "## Convert p-vals into * or shapes (a. hypergeo sig. b. hyper+global all c. hyper+global all + clone min d. hyper+global all + clone min + global min"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
