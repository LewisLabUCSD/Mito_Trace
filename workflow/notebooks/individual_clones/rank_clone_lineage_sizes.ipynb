{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec027fb",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# indir = \"/data/Mito_Trace/output/pipeline/v04/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clonal_shifts/variants_prefilterMerge_impute/donors/donor0/clones/knn_kparam_30\"\n",
    "# outdir = \"/data/Mito_Trace/output/pipeline/v04/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/single_clones/donor0/cloneMethod_variants_prefilterMerge_impute_knn_resolution_30/clonalShift_method_clones/clones_ranked\"\n",
    "# cells_meta_f = \"/data/Mito_Trace/output/pipeline/v04/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/single_clones/donor0/cloneMethod_variants_prefilterMerge_impute_knn_resolution_30/clonalShift_method_clones/cells_meta.tsv\"\n",
    "# is_mt = False\n",
    "# condition = None\n",
    "indir = \"/data/Mito_Trace/output/pipeline/v04/CHIP_b2/InputOnly/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clonal_shifts/variants_init/donors/donor1/dendro_bc/knn_kparam_30\"\n",
    "outdir = \"/data/Mito_Trace/output/pipeline/v04/CHIP_b2/InputOnly/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/single_clones/donor1/cloneMethod_variants_init_knn_resolution_30/clonalShift_method_dendro_bc/clones_ranked\"\n",
    "cells_meta_f = \"/data/Mito_Trace/output/pipeline/v04/CHIP_b2/InputOnly/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/single_clones/donor1/cloneMethod_variants_init_knn_resolution_30/clonalShift_method_dendro_bc/cells_meta.tsv\"\n",
    "is_mt = False\n",
    "condition = \"inputOnly\"\n",
    "\n",
    "# Input info\n",
    "# indir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clonal_shifts/variants_init/donors/donor1/mt_as_clones/af.0.1_othaf.0.1_cov.10_othcov.10_ncells.10_othncells.0.25_mean.0/\"\n",
    "# outdir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/single_clones/donor1/cloneMethod_variants_init_mt_bestparams_af.0.1_othaf.0.1_cov.10_othcov.10_ncells.10_othncells.0.25_mean.0/clonalShift_method_mt_as_clones/clones_ranked/\"\n",
    "# is_mt = True\n",
    "# #only used if clone is mt, to remove some clones. see where we save the csv and text file\n",
    "# cells_meta_f = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/single_clones/donor1/cloneMethod_variants_init_mt_bestparams_af.0.1_othaf.0.1_cov.10_othcov.10_ncells.10_othncells.0.25_mean.0/clonalShift_method_mt_as_clones/cells_meta.tsv\"\n",
    "# condition=None\n",
    "\n",
    "clone_id = \"cloneID\" # \"den_clust\"\n",
    "p_thresh = 0.1 \n",
    "#clust_id = \"clusterID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5043a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f2cc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "fig_utils from mplh\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join, exists\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scipy.stats import hypergeom, fisher_exact\n",
    "from statsmodels.stats import multitest \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import clonal_shifts as cs\n",
    "from icecream import ic\n",
    "\n",
    "from mplh import cluster_help as ch\n",
    "\n",
    "from scipy.stats import rankdata, gmean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32916a94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/Mito_Trace/output/pipeline/v04/CHIP_b2/InputOnly/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clonal_shifts/variants_init/donors/donor1/dendro_bc/knn_kparam_30'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b70b97",
   "metadata": {},
   "source": [
    "## Load ncells and save to output. Sort by ncells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f0918d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/Mito_Trace/output/pipeline/v04/CHIP_b2/InputOnly/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clonal_shifts/variants_init/donors/donor1/dendro_bc/knn_kparam_30/noInput_ncells.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_778238/459949413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnoInput_ncells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"noInput_ncells.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minput_ncells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_ncells.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# input_ncells_df = input_ncells.reset_index().melt(id_vars=\"index\", value_name=\"pval\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# noInput_ncells_df = noInput_ncells.reset_index().melt(id_vars=\"index\", value_name=\"pval\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mttrace/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mttrace/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mttrace/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mttrace/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mttrace/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mttrace/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mttrace/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mttrace/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/Mito_Trace/output/pipeline/v04/CHIP_b2/InputOnly/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clonal_shifts/variants_init/donors/donor1/dendro_bc/knn_kparam_30/noInput_ncells.csv'"
     ]
    }
   ],
   "source": [
    "noInput_ncells = pd.read_csv(join(indir, \"noInput_ncells.csv\"),  index_col=0)\n",
    "input_ncells = pd.read_csv(join(indir, \"input_ncells.csv\"), index_col=0)\n",
    "\n",
    "# input_ncells_df = input_ncells.reset_index().melt(id_vars=\"index\", value_name=\"pval\")\n",
    "# noInput_ncells_df = noInput_ncells.reset_index().melt(id_vars=\"index\", value_name=\"pval\")\n",
    "\n",
    "# noInput_ncells_df[\"condition\"] = \"cultured\"\n",
    "# noInput_shuffle_df[\"condition\"] = \"cultured\"\n",
    "# input_ncells_df[\"condition\"] = \"input\"\n",
    "# input_shuffle_df[\"condition\"] = \"input\"\n",
    "\n",
    "input_ncells = input_ncells.groupby(clone_id).sum()[[\"count\"]].sort_values(by=\"count\")[::-1]\n",
    "noInput_ncells = noInput_ncells.groupby(clone_id).sum()[[\"count\"]].sort_values(by=\"count\")[::-1]\n",
    "ncells_df = pd.merge(input_ncells,noInput_ncells,left_index=True, right_index=True, suffixes=[\"_input\", \"_cultured\"])\n",
    "ncells_df = ncells_df.loc[ncells_df.sum(axis=1).sort_values()[::-1].index]\n",
    "ncells_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b68c7f7",
   "metadata": {},
   "source": [
    "## Load shuffle hypergeometric results for input and cultured\n",
    "## Convert into long df with cloneID ('index'), clusterID ('variable'), pval, method (hypergeo or one of four shuffle methods), and condition ('input' or 'cultured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a620f6af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noInput_hyper = pd.read_csv(join(indir, \"noInput_hypergeo_pvals.csv\"),  index_col=0)\n",
    "noInput_shuffle_df = pd.read_csv(join(indir, \"noInput_shuffle_results_pvals.csv\"), index_col=0)\n",
    "noInput_shuffle_df = noInput_shuffle_df.rename({\"value\":\"pval\"}, axis=1)\n",
    "\n",
    "input_hyper = pd.read_csv(join(indir, \"input_hypergeo_pvals.csv\"), index_col=0)\n",
    "input_shuffle_df = pd.read_csv(join(indir, \"input_shuffle_results_pvals.csv\"), index_col=0)\n",
    "\n",
    "input_shuffle_df = input_shuffle_df.rename({\"value\":\"pval\"}, axis=1)\n",
    "input_shuffle_df\n",
    "\n",
    "input_hyper_df = input_hyper.reset_index().melt(id_vars=\"index\", value_name=\"pval\")\n",
    "input_hyper_df[\"method\"] = \"hypergeo\"\n",
    "noInput_hyper_df = noInput_hyper.reset_index().melt(id_vars=\"index\", value_name=\"pval\")\n",
    "noInput_hyper_df[\"method\"] = \"hypergeo\"\n",
    "\n",
    "\n",
    "\n",
    "noInput_hyper_df[\"condition\"] = \"cultured\"\n",
    "noInput_shuffle_df[\"condition\"] = \"cultured\"\n",
    "input_hyper_df[\"condition\"] = \"input\"\n",
    "input_shuffle_df[\"condition\"] = \"input\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e9435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_df = pd.concat((input_hyper_df, input_shuffle_df), axis=0, ignore_index=True)\n",
    "input_df[\"variable\"] = input_df[\"variable\"].astype(object).astype(str)\n",
    "\n",
    "noInput_df = pd.concat((noInput_hyper_df, noInput_shuffle_df), axis=0, ignore_index=True)\n",
    "noInput_df[\"variable\"] = noInput_df[\"variable\"].astype(object).astype(str)\n",
    "\n",
    "\n",
    "df = pd.concat((input_df, noInput_df), axis=0).reset_index(drop=True)\n",
    "#df = pd.merge(input_df, noInput_df, on=[\"index\", \"variable\", \"method\"], suffixes=[\"_input\", \"_cultured\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b8493",
   "metadata": {},
   "source": [
    "## Create 'sig score' that merges the hypergeo and the shuffle results. Score 0-4, with 4 the highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49cc7f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_df = df.copy()\n",
    "p_df[\"is_sig\"] = p_df[\"pval\"]<p_thresh\n",
    "print(p_df.shape)\n",
    "\n",
    "print(p_df.duplicated([\"index\",\"variable\", \"condition\", \"method\"]).any())\n",
    "\n",
    "def check_sig(x):\n",
    "    #print(x.head())\n",
    "    print('name', x.name)\n",
    "    name, clust, cond = x.name\n",
    "    x = x.set_index(\"method\")[\"is_sig\"]\n",
    "\n",
    "    assert(x.index.duplicated().sum()==0)\n",
    "\n",
    "    sig = 0    \n",
    "    if 'hypergeo' not in x.index:\n",
    "        print('hypergeo not sig')\n",
    "        return sig\n",
    "    if x[\"hypergeo\"]==True:\n",
    "        if (\"global_all\" in x) and x[\"global_all\"]==True:\n",
    "            if (\"clone_min\" in x) and (x[\"clone_min\"]==True):\n",
    "                if (\"global_min\" in x) and (x[\"global_min\"]==True):\n",
    "                    sig = 4    \n",
    "                else:\n",
    "                    sig = 3\n",
    "            else:\n",
    "                sig = 2\n",
    "        else:\n",
    "            sig = 1\n",
    "    return sig\n",
    "\n",
    "p_df_group = p_df.groupby([\"index\",\"variable\", \"condition\"]).apply(check_sig)\n",
    "print(p_df_group.shape)\n",
    "p_df_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2988bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df_group.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07685f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df_group.index.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e75eb3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#p_df_out = p_df_group.reset_index().rename({0:\"significant_score\", \"index\":\"clone\", \"variable\":\"cluster\"}, axis=1)\n",
    "p_df_out = p_df_group.reset_index().rename({0:\"significant_score\" }, axis=1)\n",
    "\n",
    "p_df_out\n",
    "\n",
    "#p_df_out.set_index( )\n",
    "#p_df_out[\"cluster_condition\"] = p_df_out.apply(lambda x: f'{x[\"variable\"]}_{x[\"condition\"]}', axis=1)\n",
    "p_df_out[\"cluster_condition\"] = p_df_out.apply(lambda x: f'{x[\"variable\"]}_{x[\"condition\"]}', axis=1)\n",
    "p_df_out.sort_values([\"index\", \"cluster_condition\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6789131",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p_df_out.loc[p_df_out.duplicated([\"index\", \"cluster_condition\"], keep=False)].sort_values([\"index\", \"cluster_condition\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6446f69f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.loc[(df[\"method\"] == \"hypergeo\") & (df[\"condition\"] == \"input\")].pivot(index=\"index\", columns=\"variable\", values=\"pval\")\n",
    "# df.loc[(df[\"method\"] == \"hypergeo\") & (df[\"condition\"] == \"cultured\")].pivot(index=\"index\", columns=\"variable\", values=\"pval\")\n",
    "#p_df_out[\"clone_condition\"] = p_df_out.apply(lambda x: f'{x[\"index\"]}_{x[\"condition\"]}', axis=1)\n",
    "\n",
    "#p_df_out = p_df_out.pivot(index='index', columns=[\"variable\", \"condition\"], values=\"significant_score\").fillna(0)\n",
    "p_df_out = p_df_out.pivot(index='index', columns='cluster_condition', values=\"significant_score\").fillna(0)\n",
    "\n",
    "p_df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a9c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019438b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=p_df_group.reset_index(), x=0, hue=\"condition\")\n",
    "plt.savefig(join(outdir, \"hypergeo_sig_score_distribution.pdf\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62a8ef",
   "metadata": {},
   "source": [
    "## Save heatmap for initial hypergeo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106fe6cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clone_meta = pd.DataFrame(index=p_df_out.columns, columns = [\"condition\"])\n",
    "clone_meta[\"condition\"] = [\"input\" if \"input\" in x else \"cultured\" for x in clone_meta.index]\n",
    "clone_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ef08b",
   "metadata": {},
   "source": [
    "## Input and culture in same heatmap- show clones that were significant in i'th Input cluster label and j'th culture cluster label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b944802f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_input = df.loc[(df[\"method\"] == \"hypergeo\") & (df[\"condition\"] == \"input\")].pivot(index=\"index\", columns=\"variable\", values=\"pval\")\n",
    "b_cultured = df.loc[(df[\"method\"] == \"hypergeo\") & (df[\"condition\"] == \"cultured\")].pivot(index=\"index\", columns=\"variable\", values=\"pval\")\n",
    "merged_df, merged_count_df = cs.merge_hypergeom(a_input, b_cultured, \n",
    "                                             \"Input\", \"Cultured\", p_thresh=p_thresh,\n",
    "                                             f_save=join(outdir,f\"culture_input_clone_lineages\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffd8fd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a_input = df.loc[(df[\"method\"] == \"hypergeo\") & (df[\"condition\"] == \"input\")].pivot(index=\"index\", columns=\"variable\", values=\"pval\")\n",
    "# b_cultured = df.loc[(df[\"method\"] == \"hypergeo\") & (df[\"condition\"] == \"cultured\")].pivot(index=\"index\", columns=\"variable\", values=\"pval\")\n",
    "\n",
    "a_sig = p_df_out[clone_meta[clone_meta[\"condition\"]==\"input\"].index]\n",
    "b_sig = p_df_out[clone_meta[clone_meta[\"condition\"]==\"cultured\"].index]\n",
    "a_sig.columns = [x.replace(\"_cultured\",\"\").replace(\"_input\",\"\") for x in a_sig.columns]\n",
    "b_sig.columns = [x.replace(\"_cultured\",\"\").replace(\"_input\",\"\") for x in b_sig.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3f8829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df, merged_count_df = cs.merge_hypergeom(1/(1+a_sig), 1/(1+b_sig), \n",
    "                                               \"Input\", \"Cultured\", p_thresh=0.25,\n",
    "                                                title=\"Clones sig in a cluster in both the input and culture (score=4/4)\",\n",
    "                                                f_save=join(outdir,f\"sig_score4_culture_input_clone_lineages\"))\n",
    "\n",
    "\n",
    "merged_df, merged_count_df = cs.merge_hypergeom(1/(1+a_sig), 1/(1+b_sig), \n",
    "                                                \"Input\", \"Cultured\", p_thresh=0.33,\n",
    "                                                title=\"Clones sig in a cluster in both the input and culture (score=3/4)\",\n",
    "                                                f_save=join(outdir,f\"sig_score3_culture_input_clone_lineages\"))\n",
    "\n",
    "\n",
    "merged_df, merged_count_df = cs.merge_hypergeom(1/(1+a_sig), 1/(1+b_sig), \n",
    "                                             \"Input\", \"Cultured\", p_thresh=0.5,\n",
    "                                             title=\"Clones sig in a cluster in both the input and culture (score=2/4)\",\n",
    "                                             f_save=join(outdir,f\"sig_score2_culture_input_clone_lineages\"))\n",
    "\n",
    "\n",
    "merged_df, merged_count_df = cs.merge_hypergeom(1/(1+a_sig), 1/(1+b_sig), \n",
    "                                             \"Input\", \"Cultured\", p_thresh=1,\n",
    "                                             title=\"Clones sig in a cluster in both the input and culture (score=1/4)\",\n",
    "                                             f_save=join(outdir,f\"sig_score1_culture_input_clone_lineages\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot sig score for Input hypergeo and plot cultured on same clone-axis.\n",
    "\n",
    "# g = sns.clustermap(p_df_out[clone_meta[clone_meta[\"condition\"]==\"input\"].index])\n",
    "\n",
    "# inds = g.dendrogram_row.dendrogram[\"leaves\"]\n",
    "# plt.savefig(join(outdir, \"input_sigScore.pdf\"))\n",
    "# #cols = g.dendrogram_col.dendrogram[\"leaves\"]\n",
    "# #row_meta = row_meta.iloc[inds]\n",
    "\n",
    "# sns.clustermap(p_df_out[clone_meta[clone_meta[\"condition\"]==\"cultured\"].index].iloc[inds], \n",
    "#                row_cluster=False)\n",
    "\n",
    "# plt.savefig(join(outdir, \"cultured_sigScore.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a603c6",
   "metadata": {},
   "source": [
    "## Get the minimum of each clone shift. This will be used for rankigng later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3539ba9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_df = df.groupby([\"index\", \"method\", \"condition\"]).min()[\"pval\"].reset_index()\n",
    "min_df\n",
    "\n",
    "min_df_wide = min_df.pivot(index=\"index\", values=\"pval\", columns=[\"method\", \"condition\"])\n",
    "min_df_wide.columns = ['_'.join(col).strip() for col in min_df_wide.columns.values] # flatten to 1D columns\n",
    "min_df_wide\n",
    "ncells_df[\"ncells\"] = ncells_df.sum(axis=1)\n",
    "min_df_wide = pd.concat((min_df_wide,ncells_df), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f433f",
   "metadata": {},
   "source": [
    "# *Get the clone order based on the ncells \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fcf37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if is_mt:\n",
    "    print(\"removing donor specific variants\")\n",
    "    print(min_df_wide.shape)\n",
    "    clone_order_keep = []\n",
    "    cells_meta = pd.read_csv(cells_meta_f, sep=\"\\t\", index_col=0)\n",
    "    kept_clones = []\n",
    "    kept_clones_cells = []\n",
    "    \n",
    "    for x in cells_meta.columns:\n",
    "        if \"cloneID_\" in x:\n",
    "            kept_clones_cells.append(x)\n",
    "            kept_clones.append(x.replace(\"cloneID_\", \"\"))\n",
    "    \n",
    "    min_df_wide = min_df_wide.loc[min_df_wide.index.isin(kept_clones)]\n",
    "    print(\"after removal\")\n",
    "    print(min_df_wide.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ca264",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df_wide = min_df_wide.fillna(0)\n",
    "min_df_wide = min_df_wide.sort_values(\"ncells\", ascending=False)\n",
    "min_df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eed74f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rank_df = pd.merge(min_df_wide.drop(\"ncells\", axis=1).apply(lambda x: rankdata(x, method='max'), axis=0),\n",
    "                   min_df_wide[[\"ncells\"]].apply(lambda x: rankdata(x, method='min'), axis=0), \n",
    "                   left_index=True, right_index=True)\n",
    "#rank_df = min_df_wide.apply(lambda x: rankdata(x, method='max'), axis=0)\n",
    "# gmean_ser = rank_df.apply(gmean, axis=1)\n",
    "# gmean_ser = gmean_ser.sort_values()\n",
    "rank_df = rank_df.sort_values(\"ncells\")[::-1]\n",
    "rank_df\n",
    "#for c in clone_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4972e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## Get the clone order based on the mean of the rankings\n",
    "clone_order = rank_df.index\n",
    "min_df_wide = min_df_wide.loc[clone_order]\n",
    "rank_df = rank_df.loc[clone_order]\n",
    "rank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ca285",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_df_wide.loc[clone_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee9836",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_clone_meta = pd.DataFrame(index=min_df_wide.columns, columns = [\"condition\"])\n",
    "min_clone_meta[\"condition\"] = [\"input\" if \"input\" in x else \"cultured\" for x in min_clone_meta.index]\n",
    "min_clone_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bbc43a",
   "metadata": {},
   "source": [
    "## Plot rankings ordered by clone, annd save output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbbff17",
   "metadata": {},
   "source": [
    "## Save:\n",
    "a) cloneID_rank.png  \n",
    "b) cloneID_order.txt - line-delimited text file with cloneID on each line  \n",
    "c) cloneID_rank.csv  - csv file of the ranking for each category  \n",
    "d) all_pvals: all p-values for for each clone-method-cluster-condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ecaa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clone_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(outdir, \"cloneID_rank_ncells.txt\"), 'w') as f:\n",
    "    f.write('\\n'.join(clone_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420cb540",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df.to_csv(join(outdir, \"cloneID_rank_ncells_df.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bcd5ea",
   "metadata": {},
   "source": [
    "## Plot the rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c51138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be4db9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = ch.plot_cluster(rank_df, to_row_clust=False, to_col_clust=False, col_meta=min_clone_meta[[\"condition\"]])\n",
    "g.fig.suptitle(\"Ranking of each method across clones. Top is best-ranked clone\")\n",
    "plt.savefig(join(outdir, \"cloneID_rank_sizes.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9123885f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.clustermap(p_df_out[clone_meta[clone_meta[\"condition\"]==\"input\"].index].loc[clone_order], row_cluster=False)\n",
    "plt.savefig(join(outdir, \"input_sigScore_cloneOrder.pdf\"))\n",
    "#inds = g.dendrogram_row.dendrogram[\"leaves\"]\n",
    "\n",
    "#cols = g.dendrogram_col.dendrogram[\"leaves\"]\n",
    "#row_meta = row_meta.iloc[inds]\n",
    "\n",
    "sns.clustermap(p_df_out[clone_meta[clone_meta[\"condition\"]==\"cultured\"].index].loc[clone_order], \n",
    "               row_cluster=False)\n",
    "\n",
    "plt.savefig(join(outdir, \"cultured_sigScore_cloneOrder.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2f51a6",
   "metadata": {},
   "source": [
    "## Convert p-vals into * or shapes (a. hypergeo sig. b. hyper+global all c. hyper+global all + clone min d. hyper+global all + clone min + global min"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
