{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec027fb",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "indir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/clonal_shifts/variants_init/donors/donor1/mt_as_clones/af.0.1_othaf.0.1_cov.10_othcov.10_ncells.10_othncells.0.25_mean.0/\"\n",
    "outdir = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/single_clones/donor1/cloneMethod_variants_init_mt_bestparams_af.0.1_othaf.0.1_cov.10_othcov.10_ncells.10_othncells.0.25_mean.0/clonalShift_method_mt_as_clones/top/\"\n",
    "cloneID_f = \"/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/single_clones/donor1/cloneMethod_variants_init_mt_bestparams_af.0.1_othaf.0.1_cov.10_othcov.10_ncells.10_othncells.0.25_mean.0/clonalShift_method_mt_as_clones/cloneIDs.txt\"\n",
    "\n",
    "ntop_clones = 10\n",
    "p_thresh = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f2cc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fig_utils from mplh\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join, exists\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import hypergeom, fisher_exact\n",
    "from statsmodels.stats import multitest \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from src import clonal_shifts as cs\n",
    "from icecream import ic\n",
    "from mplh import cluster_help as ch\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0545ed48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/single_clones/donor1/cloneMethod_variants_init_mt_bestparams_af.0.1_othaf.0.1_cov.10_othcov.10_ncells.10_othncells.0.25_mean.0/clonalShift_method_mt_as_clones/cloneIDs.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2712612/2126879945.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloneID_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcloneIDs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcloneIDs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcloneIDs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcloneIDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/Mito_Trace/output/pipeline/v02/CHIP_b1/MTBlacklist_A2/data/merged/MT/cellr_True/numread_200/filters/minC10_minR50_topN0_hetT0.001_hetC10_hetCount5_bq20/mgatk/vireoIn/single_clones/donor1/cloneMethod_variants_init_mt_bestparams_af.0.1_othaf.0.1_cov.10_othcov.10_ncells.10_othncells.0.25_mean.0/clonalShift_method_mt_as_clones/cloneIDs.txt'"
     ]
    }
   ],
   "source": [
    "with open(cloneID_f, \"r\") as f:\n",
    "    cloneIDs = f.readlines()\n",
    "cloneIDs = [x.strip() for x in cloneIDs]\n",
    "cloneIDs\n",
    "\n",
    "top_cloneIDs = cloneIDs[:ntop_clones]\n",
    "top_cloneIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8817e294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cells_meta = pd.read_csv(cells_meta_f, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b353a6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10397G</td>\n",
       "      <td>CLP</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>global_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10463C</td>\n",
       "      <td>CLP</td>\n",
       "      <td>0.753804</td>\n",
       "      <td>global_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10559G</td>\n",
       "      <td>CLP</td>\n",
       "      <td>0.754929</td>\n",
       "      <td>global_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10589A</td>\n",
       "      <td>CLP</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>global_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11251G</td>\n",
       "      <td>CLP</td>\n",
       "      <td>0.754929</td>\n",
       "      <td>global_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>8461T</td>\n",
       "      <td>neutrophil B</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clone_min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>8697A</td>\n",
       "      <td>neutrophil B</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clone_min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>8860G</td>\n",
       "      <td>neutrophil B</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clone_min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>930A</td>\n",
       "      <td>neutrophil B</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clone_min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>9899C</td>\n",
       "      <td>neutrophil B</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>clone_min</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3584 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      variable     value      method\n",
       "0    10397G           CLP  0.000705  global_all\n",
       "1    10463C           CLP  0.753804  global_all\n",
       "2    10559G           CLP  0.754929  global_all\n",
       "3    10589A           CLP  0.000839  global_all\n",
       "4    11251G           CLP  0.754929  global_all\n",
       "..      ...           ...       ...         ...\n",
       "891   8461T  neutrophil B  1.000000   clone_min\n",
       "892   8697A  neutrophil B  1.000000   clone_min\n",
       "893   8860G  neutrophil B  1.000000   clone_min\n",
       "894    930A  neutrophil B  1.000000   clone_min\n",
       "895   9899C  neutrophil B  0.872000   clone_min\n",
       "\n",
       "[3584 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noInput_hyper = pd.read_csv(join(indir, \"noInput_hypergeo_pvals.csv\"),  index_col=0)\n",
    "noIn_shuffle_df = pd.read_csv(join(indir, \"noInput_shuffle_results_pvals.csv\"), index_col=0)\n",
    "\n",
    "input_hyper = pd.read_csv(join(indir, \"input_hypergeo_pvals.csv\"), index_col=0)\n",
    "input_shuffle_df = pd.read_csv(join(indir, \"input_shuffle_results_pvals.csv\"), index_col=0)\n",
    "\n",
    "input_shuffle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35aa1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pval(clone_d, hyper_key, shuffle_key, clustIDs):\n",
    "    pval_df = pd.DataFrame(columns = [\"hypergeo\", \"global_min\", \"clone_min\", \"clone_all\", \"global_all\"],\n",
    "                           index=clustIDs)\n",
    "    if clone_d[shuffle_key] is None:\n",
    "        if clone_d[hyper_key] is not None:\n",
    "            pval_df.loc[clone_d[hyper_key].index, \"hypergeo\"] = clone_d[hyper_key]\n",
    "            print('pval_df')\n",
    "        else:\n",
    "            print(\"no sig\")\n",
    "    else:\n",
    "        shuff_df = clone_d[shuffle_key].pivot(index=\"variable\", columns=\"method\", values=\"value\")\n",
    "        shuff_df\n",
    "        pval_df.loc[shuff_df.index, shuff_df.columns] = shuff_df\n",
    "\n",
    "        if clone_d[hyper_key] is not None:\n",
    "            pval_df.loc[clone_d[hyper_key].index, \"hypergeo\"] = clone_d[hyper_key]\n",
    "    \n",
    "    #pval_df.fillna(1)     \n",
    "    return pval_df\n",
    "\n",
    "\n",
    "def run_ind_clone(clone_id):\n",
    "    print('clone_id', clone_id)\n",
    "    clone_d = {}\n",
    "    if clone_id in noInput_hyper.index:\n",
    "        clone_d[\"noIn_hyper\"] = noInput_hyper.loc[clone_id]\n",
    "    else: \n",
    "        clone_d[\"noIn_hyper\"] = None\n",
    "    \n",
    "    if clone_id in noIn_shuffle_df[\"index\"].values:\n",
    "        clone_d[\"noIn_shuffle\"] = noIn_shuffle_df.loc[noIn_shuffle_df[\"index\"]==clone_id]\n",
    "    else:\n",
    "        clone_d[\"noIn_shuffle\"] = None\n",
    "        \n",
    "        \n",
    "    if clone_id in input_hyper.index:\n",
    "        clone_d[\"input_hyper\"] = input_hyper.loc[clone_id]\n",
    "    else: \n",
    "        clone_d[\"input_hyper\"] = None\n",
    "            \n",
    "    if clone_id in input_shuffle_df[\"index\"].values:\n",
    "        clone_d[\"input_shuffle\"] = input_shuffle_df.loc[input_shuffle_df[\"index\"]==clone_id]\n",
    "    else:\n",
    "        clone_d[\"input_shuffle\"] = None\n",
    "            \n",
    "    \n",
    "    clone_d['noIn_shuffle']\n",
    "    clone_d['noIn_hyper']\n",
    "    \n",
    "    set_input_hyper = clone_d['input_hyper'].index if clone_d['input_hyper'] is not None else set()\n",
    "    set_noInput_hyper = clone_d['noIn_hyper'].index if clone_d['noIn_hyper'] is not None else set()\n",
    "\n",
    "    set_input_shuffle = clone_d['input_shuffle'][\"variable\"].values if clone_d['input_shuffle'] is not None else set()\n",
    "    set_noInput_shuffle = clone_d['noIn_shuffle'][\"variable\"].values if clone_d['noIn_shuffle'] is not None else set()\n",
    "\n",
    "    \n",
    "    clustIDs = set(set_input_hyper).union(set_noInput_hyper)\n",
    "    clustIDs = clustIDs.union(set_noInput_shuffle).union(set_input_shuffle)\n",
    "    \n",
    "    noIn_pval_df = create_pval(clone_d, hyper_key=\"noIn_hyper\",shuffle_key=\"noIn_shuffle\", clustIDs=clustIDs)\n",
    "    input_pval_df = create_pval(clone_d, hyper_key=\"input_hyper\",shuffle_key=\"input_shuffle\", clustIDs=clustIDs)\n",
    "    pval_df = pd.merge(input_pval_df, noIn_pval_df, left_index=True, right_index=True, \n",
    "                       how=\"outer\", suffixes=(\"_Input\", \"_Cultured\"))\n",
    "\n",
    "    ## Sort clusters by global_min, hypergeo, \n",
    "    pval_df = pval_df.fillna(1).sort_values([\"global_min_Input\", \"hypergeo_Input\", \"clone_min_Input\",\"global_min_Cultured\", \"hypergeo_Cultured\",  \"clone_min_Cultured\"])\n",
    "#     plt.close()\n",
    "    return pval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "931b51d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_cloneIDs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2712612/4216911565.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpval_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mc_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_cloneIDs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpval_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_ind_clone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'top_cloneIDs' is not defined"
     ]
    }
   ],
   "source": [
    "pval_d = {}\n",
    "for c_id in top_cloneIDs:\n",
    "    pval_d[c_id] = run_ind_clone(c_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41598fe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sig_input_d = []\n",
    "sig_cultured_d = []\n",
    "\n",
    "for i in pval_d:\n",
    "    print(i)\n",
    "    curr_input_cols = pval_d[i].columns[pval_d[i].columns.str.contains(\"_Input\")]\n",
    "    curr_cultured_cols = pval_d[i].columns[pval_d[i].columns.str.contains(\"_Cultured\")]\n",
    "    curr_cultured_cols\n",
    "\n",
    "    pval_bin = (pval_d[i]<p_thresh)\n",
    "    \n",
    "    curr_sig_input = pd.Series(index=pval_bin.index, name=i)\n",
    "    curr_sig_input.loc[:] = 0\n",
    "    curr_sig_input.loc[pval_bin[\"hypergeo_Input\"]==True] = 1\n",
    "    curr_sig_input.loc[pval_bin[\"global_all_Input\"]==True] += 1\n",
    "    curr_sig_input.loc[pval_bin[\"clone_min_Input\"]==True] += 1\n",
    "    curr_sig_input.loc[pval_bin[\"global_min_Input\"]==True] += 1\n",
    "\n",
    "    sig_input_d.append(pd.DataFrame(curr_sig_input))\n",
    "    \n",
    "    curr_sig_cultured = pd.Series(index=pval_bin.index, name=i)\n",
    "    curr_sig_cultured.loc[:] = 0\n",
    "    curr_sig_cultured.loc[pval_bin[\"hypergeo_Cultured\"]==True] = 1\n",
    "    curr_sig_cultured.loc[pval_bin[\"global_all_Cultured\"]==True] += 1\n",
    "    curr_sig_cultured.loc[pval_bin[\"clone_min_Cultured\"]==True] += 1\n",
    "    curr_sig_cultured.loc[pval_bin[\"global_min_Cultured\"]==True] += 1\n",
    "    sig_cultured_d.append(pd.DataFrame(curr_sig_cultured))\n",
    "\n",
    "sig_input_df = pd.concat(sig_input_d, axis=1).fillna(0)\n",
    "sig_input_df\n",
    "\n",
    "sig_cultured_df = pd.concat(sig_cultured_d, axis=1).fillna(0)\n",
    "sig_cultured_df\n",
    "\n",
    "# merge_sig_df = sig_input_df.transpose()\n",
    "# merge_sig_df\n",
    "\n",
    "melt_sig_input = sig_input_df.transpose().reset_index().melt(id_vars='index')\n",
    "melt_sig_input[\"cond\"] = \"input\"\n",
    "melt_sig_cultured = sig_cultured_df.transpose().reset_index().melt(id_vars='index')\n",
    "melt_sig_cultured[\"cond\"] = \"cultured\"\n",
    "merge_sig_df = pd.concat((melt_sig_input, melt_sig_cultured))\n",
    "merge_sig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c8ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hyper_sig(data, **kwargs):\n",
    "    #print(data.head())\n",
    "    data.pivot(index=\"variable\", columns=\"index\", values=\"value\").plot.bar(ax=plt.gca())\n",
    "    sns.heatmap(data.pivot(index=\"variable\", columns=\"index\", values=\"value\"), ax=plt.gca(),\n",
    "               vmax=4, vmin=0)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9267d54e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#figsize=(len(top_cloneIDs)*4*(4/3), len(top_cloneIDs)*4)\n",
    "g = sns.FacetGrid(data=merge_sig_df, col=\"cond\", row='index',\n",
    "                  row_order=top_cloneIDs, col_order=[\"input\", \"cultured\"],\n",
    "                  sharex=False, sharey=False, height=8, aspect=4)\n",
    "g.map_dataframe(plot_hyper_sig)\n",
    "#g.fig.savefig(fname=join(outdir, f\"top{ntop_clones}_sig_hypergeo.pdf\"), dpi=500, bbox_inches='tight', pad_inches=0.5)\n",
    "\n",
    "g.fig.savefig(fname=join(outdir, f\"top{ntop_clones}_sig_hypergeo.svg\"), bbox_inches='tight', pad_inches=0.5)\n",
    "# g = sns.FacetGrid(data=sig_input_df.reset_index().melt(id_vars='index'), col=\"variable\", col_wrap=1,\n",
    "#                  sharex=False, sharey=False, height=4, aspect=2)\n",
    "# g.map_dataframe(plot_hyper_sig)\n",
    "# g.fig.savefig(fname=join(outdir, f\"top{ntop_clones}_sig_hypergeo.pdf\"), dpi=500, bbox_inches='tight', pad_inches=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accbcfee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pval_bin = (pval_d[i]<p_thresh)\n",
    "# curr_sig_noInput = pd.Series(index=pval_bin.index)\n",
    "# curr_sig_noInput.loc[:] = 0\n",
    "# curr_sig_noInput.loc[pval_bin[\"hypergeo_Input\"]==True] = 1\n",
    "# curr_sig_noInput.loc[pval_bin[\"global_all_Input\"]==True] += 1\n",
    "# curr_sig_noInput.loc[pval_bin[\"clone_min_Input\"]==True] += 1\n",
    "# curr_sig_noInput.loc[pval_bin[\"global_min_Input\"]==True] += 1\n",
    "\n",
    "# # sig = sig.astype(int) + (x.loc[\"global_all\"]).astype(int)\n",
    "# # sig = sig.astype(int) + (x.loc[\"clone_min\"]).astype(int)\n",
    "# # sig = sig.astype(int) + (x.loc[\"global_min\"]).astype(int)\n",
    "# # sig\n",
    "# #pval_bin[\"hypergeo_Input\"]\n",
    "# curr_sig_noInput\n",
    "\n",
    "\n",
    "# def run_ind_clone(clone_id, p_thresh=0.1):\n",
    "#     print('clone_id', clone_id)\n",
    "    \n",
    "#     noIn_sig_score = pd.Series(index=noInput_hyper.columns, name=clone_id)\n",
    "#     in_sig_score = 0\n",
    "    \n",
    "    \n",
    "#     clone_d = {}\n",
    "#     if clone_id in noInput_hyper.index:\n",
    "#         clone_d[\"noIn_hyper\"] = noInput_hyper.loc[clone_id]\n",
    "#         noIn_sig_score.loc[(noInput_hyper.loc[clone_id] < p_thresh)] = 1\n",
    "# #         if noInput_hyper.loc[clone_id] < p_thresh:\n",
    "# #             noIn_sig_score += 1\n",
    "\n",
    "#     if clone_id in noInput_hyper.index:\n",
    "#         curr_noIn_shuffle = noInput_hyper.loc[clone_id]\n",
    "#         noIn_sig_score.loc[(noInput_hyper.loc[clone_id] < p_thresh)] = 1\n",
    "    \n",
    "#     if clone_id in noIn_shuffle_df[\"index\"].values:\n",
    "#         clone_d[\"noIn_shuffle\"] = noIn_shuffle_df.loc[noIn_shuffle_df[\"index\"]==clone_id]\n",
    "#     else:\n",
    "#         clone_d[\"noIn_shuffle\"] = None\n",
    "        \n",
    "        \n",
    "#     if clone_id in input_hyper.index:\n",
    "#         clone_d[\"input_hyper\"] = input_hyper.loc[clone_id]\n",
    "#     else: \n",
    "#         clone_d[\"input_hyper\"] = None\n",
    "            \n",
    "#     if clone_id in input_shuffle_df[\"index\"].values:\n",
    "#         clone_d[\"input_shuffle\"] = input_shuffle_df.loc[input_shuffle_df[\"index\"]==clone_id]\n",
    "#     else:\n",
    "#         clone_d[\"input_shuffle\"] = None\n",
    "            \n",
    "    \n",
    "#     clone_d['noIn_shuffle']\n",
    "#     clone_d['noIn_hyper']\n",
    "    \n",
    "#     set_input_hyper = clone_d['input_hyper'].index if clone_d['input_hyper'] is not None else set()\n",
    "#     set_noInput_hyper = clone_d['noIn_hyper'].index if clone_d['noIn_hyper'] is not None else set()\n",
    "\n",
    "#     set_input_shuffle = clone_d['input_shuffle'][\"variable\"].values if clone_d['input_shuffle'] is not None else set()\n",
    "#     set_noInput_shuffle = clone_d['noIn_shuffle'][\"variable\"].values if clone_d['noIn_shuffle'] is not None else set()\n",
    "\n",
    "    \n",
    "#     clustIDs = set(set_input_hyper).union(set_noInput_hyper)\n",
    "#     clustIDs = clustIDs.union(set_noInput_shuffle).union(set_input_shuffle)\n",
    "    \n",
    "#     noIn_pval_df = create_pval(clone_d, hyper_key=\"noIn_hyper\",shuffle_key=\"noIn_shuffle\", clustIDs=clustIDs)\n",
    "#     input_pval_df = create_pval(clone_d, hyper_key=\"input_hyper\",shuffle_key=\"input_shuffle\", clustIDs=clustIDs)\n",
    "#     pval_df = pd.merge(input_pval_df, noIn_pval_df, left_index=True, right_index=True, \n",
    "#                        how=\"outer\", suffixes=(\"_Input\", \"_Cultured\"))\n",
    "\n",
    "#     ## Sort clusters by global_min, hypergeo, \n",
    "#     pval_df = pval_df.fillna(1).sort_values([\"global_min_Input\", \"hypergeo_Input\", \"clone_min_Input\",\"global_min_Cultured\", \"hypergeo_Cultured\",  \"clone_min_Cultured\"])\n",
    "#     return pval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110ccc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_df = df.copy()\n",
    "# p_df[\"is_sig\"] = p_df[\"pval\"]<p_thresh\n",
    "# p_df\n",
    "\n",
    "# def check_sig(x):\n",
    "#     #print(x.head())\n",
    "#     name, clust, cond = x.name\n",
    "#     x = x.set_index(\"method\")[\"is_sig\"]\n",
    "#     assert(x.index.duplicated().sum()==0)\n",
    "#     #print('x',x )\n",
    "#     sig = x.loc[\"hypergeo\"] \n",
    "#     #print('sig', sig)\n",
    "#     sig = sig.astype(int) + (x.loc[\"global_all\"]).astype(int)\n",
    "#     sig = sig.astype(int) + (x.loc[\"clone_min\"]).astype(int)\n",
    "#     sig = sig.astype(int) + (x.loc[\"global_min\"]).astype(int)\n",
    "#     sig\n",
    "#     return sig\n",
    "\n",
    "# p_df = p_df.groupby([\"index\",\"variable\", \"condition\"]).apply(check_sig)\n",
    "# p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07336cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_df_out = p_df.reset_index().rename({0:\"significant_score\"}, axis=1)\n",
    "# #p_df_out.set_index( )\n",
    "# p_df_out[\"cluster_condition\"] = p_df_out.apply(lambda x: f'{x[\"variable\"]}_{x[\"condition\"]}', axis=1)\n",
    "# p_df_out\n",
    "\n",
    "# #p_df_out[\"clone_condition\"] = p_df_out.apply(lambda x: f'{x[\"index\"]}_{x[\"condition\"]}', axis=1)\n",
    "\n",
    "\n",
    "# p_df_out = p_df_out.pivot(index='index', columns='cluster_condition', values=\"significant_score\").fillna(0)\n",
    "\n",
    "# p_df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7665c069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a151fbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c6ded2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clone_d = {}\n",
    "# clone_d[\"noIn_hyper\"] = noInput_hyper.loc[clone_id]\n",
    "# clone_d[\"noIn_shuffle\"] = noIn_shuffle_df.loc[noIn_shuffle_df[\"index\"]==clone_id]\n",
    "\n",
    "# clone_d[\"input_hyper\"] = input_hyper.loc[clone_id]\n",
    "# clone_d[\"input_shuffle\"] = input_shuffle_df.loc[input_shuffle_df[\"index\"]==clone_id]\n",
    "\n",
    "# clone_d['noIn_shuffle']\n",
    "\n",
    "# clone_d['noIn_hyper']\n",
    "\n",
    "# clustIDs = set(clone_d['input_hyper'].index).union(set(clone_d['noIn_hyper'].index))\n",
    "# clustIDs = clustIDs.union(set(clone_d['noIn_shuffle'][\"variable\"].values).union(set(clone_d['input_shuffle'][\"variable\"].values)))\n",
    "# clustIDs\n",
    "\n",
    "# ## Create p-val table for the clone\n",
    "\n",
    "# noIn_pval_df = create_pval(clone_d, hyper_key=\"noIn_hyper\",shuffle_key=\"noIn_shuffle\")\n",
    "# input_pval_df = create_pval(clone_d, hyper_key=\"input_hyper\",shuffle_key=\"input_shuffle\")\n",
    "# pval_df = pd.merge(input_pval_df, noIn_pval_df, left_index=True, right_index=True, \n",
    "#                    how=\"outer\", suffixes=(\"_Input\", \"_Cultured\"))\n",
    "\n",
    "# ## Sort clusters by global_min, hypergeo, \n",
    "# pval_df = pval_df.fillna(1).sort_values([\"global_min_Input\", \"hypergeo_Input\", \"clone_min_Input\",\"global_min_Cultured\", \"hypergeo_Cultured\",  \"clone_min_Cultured\"])\n",
    "# clone_meta = pd.DataFrame(index=pval_df.columns, columns = [\"condition\",\"size\"])\n",
    "# clone_meta[\"condition\"] = [\"Input\" if \"Input\" in x else \"Cultured\" for x in clone_meta.index]\n",
    "# pval_df\n",
    "\n",
    "# ch.plot_cluster(pval_df, to_col_clust=False, col_meta=clone_meta[[\"condition\"]])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
